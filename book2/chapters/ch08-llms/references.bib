@article{Adetayo_Enamudu_Lawal_Odunewu_2024,
	title        = {From text to video with AI: the rise and potential of Sora in education and libraries},
	author       = {Adetayo, Adebowale Jeremy and Enamudu, Augustine I. and Lawal, Folashade Munirat and Odunewu, Abiodun Olusegun},
	year         = 2024,
	month        = {Mar},
	journal      = {Library hi tech news},
	publisher    = {Emerald},
	doi          = {10.1108/lhtn-02-2024-0028},
	issn         = {0741-9058},
	url          = {https://www.emerald.com/insight/content/doi/10.1108/lhtn-02-2024-0028/full/html},
	abstractnote = {Purpose This study investigates the transformative role of Sora in education and libraries. This study aims to explore Sora’s capabilities and potential implications for enhancing learning experiences and enriching library resources. Design/methodology/approach Using an exploratory approach, this paper analyzes Sora’s functionalities, focusing on its ability to convert textual descriptions into dynamic video content swiftly and accurately. It examines the ways in which Sora can augment learning through interactivity, personalization and accessibility, as well as its capacity to digitize cultural heritage and promote literacy in library settings. Findings Sora emerges as a potential powerful tool for education and libraries, offering opportunities for diverse learning modalities, creativity and critical thinking. Its capacity to facilitate immersive storytelling and educational gamification holds promise for engaging users and fostering community involvement. However, ethical considerations such as bias mitigation and equitable access must be addressed to maximize Sora’s benefits. Originality/value This study contributes to the understanding of artificial intelligence’s potential in education and libraries, particularly through the lens of Sora.},
	language     = {en}
}
@inproceedings{Aher_Arriaga_Kalai_2023,
	title        = {Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies},
	author       = {Aher, Gati V. and Arriaga, Rosa I. and Kalai, Adam Tauman},
	year         = {2023},
	booktitle    = {Proceedings of the 40th International Conference on Machine Learning},
	publisher    = {PMLR},
	series       = {Proceedings of Machine Learning Research},
	volume       = 202,
	pages        = {337–371},
	url          = {https://proceedings.mlr.press/v202/aher23a.html},
	abstractnote = {We introduce a new type of test, called a Turing Experiment (TE), for evaluating to what extent a given language model, such as GPT models, can simulate different aspects of human behavior. A TE can also reveal consistent distortions in a language model’s simulation of a specific human behavior. Unlike the Turing Test, which involves simulating a single arbitrary individual, a TE requires simulating a representative sample of participants in human subject research. We carry out TEs that attempt to replicate well-established findings from prior studies. We design a methodology for simulating TEs and illustrate its use to compare how well different language models are able to reproduce classic economic, psycholinguistic, and social psychology experiments: Ultimatum Game, Garden Path Sentences, Milgram Shock Experiment, and Wisdom of Crowds. In the first three TEs, the existing findings were replicated using recent models, while the last TE reveals a “hyper-accuracy distortion” present in some language models (including ChatGPT and GPT-4), which could affect downstream applications in education and the arts.},
	editor       = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
	collection   = {Proceedings of Machine Learning Research}
}
@article{Areces_Benotti_Bulgarelli_Echeveste_Finzi_2024,
	title        = {Leveraging language models and automatic summarization in online programming learning environments},
	author       = {Areces, Carlos and Benotti, Luciana and Bulgarelli, Franco and Echeveste, Emilia and Finzi, Nadia},
	year         = 2024,
	month        = {Aug},
	journal      = {Communications of the ACM},
	publisher    = {Association for Computing Machinery (ACM)},
	volume       = 67,
	number       = 8,
	pages        = {86–87},
	doi          = {10.1145/3653323},
	issn         = {0001-0782},
	url          = {https://dl.acm.org/doi/full/10.1145/3653323},
	language     = {en}
}
@inproceedings{Brown_Mann_Ryder_Subbiah_Kaplan_Dhariwal_Neelakantan_Shyam_Sastry_Askell_et_al_2020,
	title        = {Language models are few-shot learners},
	author       = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year         = 2020,
	booktitle    = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
	publisher    = {Curran Associates Inc.},
	address      = {Red Hook, NY, USA},
	series       = {NIPS ’20},
	isbn         = 9781713829546,
	abstractnote = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	collection   = {NIPS ’20}
}
@inproceedings{Cho_van_Merrienboer_Gulcehre_Bahdanau_Bougares_Schwenk_Bengio_2014,
	title        = {Learning phrase representations using RNN encoder-decoder for statistical machine translation},
	author       = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	year         = 2014,
	month        = {Jun},
	booktitle    = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	pages        = {1724–1734},
	doi          = {10.3115/v1/d14-1179},
	url          = {https://aclanthology.org/D14-1179.pdf},
	abstractnote = {In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.}
}
@unpublished{Christiano_Leike_Brown_Martic_Legg_Amodei_2017,
	title        = {Deep reinforcement learning from human preferences},
	author       = {Christiano, Paul and Leike, Jan and Brown, Tom B. and Martic, Miljan and Legg, Shane and Amodei, Dario},
	year         = 2017,
	month        = {Jun},
	journal      = {arXiv [stat.ML]},
	url          = {http://arxiv.org/abs/1706.03741},
	abstractnote = {For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent’s interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback.}
}
@unpublished{Clavié_Gal_2019,
	title        = {EduBERT: Pretrained Deep Language Models for Learning Analytics},
	author       = {Clavié, Benjamin and Gal, Kobi},
	year         = 2019,
	month        = {Dec},
	journal      = {arXiv [cs.CY]},
	url          = {http://arxiv.org/abs/1912.00690},
	abstractnote = {The use of large pretrained neural networks to create contextualized word embeddings has drastically improved performance on several natural language processing (NLP) tasks. These computationally expensive models have begun to be applied to domain-specific NLP tasks such as re-hospitalization prediction from clinical notes. This paper demonstrates that using large pretrained models produces excellent results on common learning analytics tasks. Pre-training deep language models using student forum data from a wide array of online courses improves performance beyond the state of the art on three text classification tasks. We also show that a smaller, distilled version of our model produces the best results on two of the three tasks while limiting computational cost. We make both models available to the research community at large.}
}
@inproceedings{Dai_Kritskaia_van_der_Velden_Jung_Postma_Louwerse_2022,
	title        = {Evaluating the usage of Text-To-Speech in K12 education},
	author       = {Dai, Laduona and Kritskaia, Veronika and van der Velden, Evelien and Jung, Merel M. and Postma, Marie and Louwerse, Max M.},
	year         = 2022,
	month        = {Nov},
	booktitle    = {Proceedings of the 2022 6th International Conference on Education and E-Learning},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	pages        = {182–188},
	doi          = {10.1145/3578837.3578864},
	url          = {http://dx.doi.org/10.1145/3578837.3578864}
}
@article{Drori_Teeni_2024,
	title        = {Human-in-the-loop AI reviewing: Feasibility, opportunities, and risks},
	author       = {Drori, Iddo and Te’eni, Dov},
	year         = 2024,
	journal      = {Journal of the Association for Information Systems},
	publisher    = {aisel.aisnet.org},
	volume       = 25,
	pages        = 7,
	doi          = {10.17705/1jais.00867},
	issn         = {1536-9323},
	url          = {https://aisel.aisnet.org/jais/vol25/iss1/7/},
	abstractnote = {The promise of AI for academic work is bewitching and easy to envisage, but the risks involved are often hard to detect and usually not readily exposed. In this opinion piece, we explore the feasibility, opportunities, and risks of using large language models (LLMs) for reviewing academic submissions, while keeping the human in the loop. We experiment with GPT-4 in the role of a reviewer to demonstrate the opportunities and the risks we experience and ways to mitigate them. The reviews are structured according to a conference review form with the dual purpose of evaluating submissions for editorial decisions and providing authors with constructive feedback according to predefined criteria, which include contribution, soundness, and presentation. We demonstrate feasibility by evaluating and comparing LLM reviews with human reviews, concluding that current AI-augmented reviewing is sufficiently accurate to alleviate the burden of reviewing but not completely and not for all cases. We then enumerate the opportunities of AI-augmented reviewing and present open questions. Next, we identify the risks of AI-augmented reviewing, highlighting bias, value misalignment, and misuse. We conclude with recommendations for managing these risks.}
}
@inproceedings{Fung_Wong_Tan_2023,
	title        = {Chain-of-thoughts prompting with language models for accurate math problem-solving},
	author       = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
	year         = 2023,
	month        = {Oct},
	booktitle    = {2023 IEEE MIT Undergraduate Research Technology Conference (URTC)},
	publisher    = {IEEE},
	pages        = {1–5},
	doi          = {10.1109/urtc60662.2023.10534945},
	url          = {https://ieeexplore.ieee.org/abstract/document/10534945/?casa_token=fUJt75Ht5ZcAAAAA:iECGjiOLL1ESoz9H-7KMHh9qphc-SGwHFYkfYZ-lkUWKaqOiIF3qa4OBHLDQpPr--40gf0SLI1pDXg}
}
@inbook{Goel_Sahnan_Venktesh_Sharma_Dwivedi_Mohania_2022,
	title        = {K-12BERT: BERT for K-12 Education},
	author       = {Goel, Vasu and Sahnan, Dhruv and Venktesh, V. and Sharma, Gaurav and Dwivedi, Deep and Mohania, Mukesh},
	year         = 2022,
	booktitle    = {Artificial Intelligence in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners’ and Doctoral Consortium},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	series       = {Lecture notes in computer science},
	pages        = {595–598},
	doi          = {10.1007/978-3-031-11647-6_123},
	isbn         = 9783031116469,
	issn         = {1611-3349},
	url          = {https://link.springer.com/chapter/10.1007/978-3-031-11647-6_123},
	abstractnote = {Online education platforms are powered by various NLP pipelines, which utilize models like BERT to aid in content curation. Since the inception of the pre-trained language models like BERT, there have also been many efforts toward adapting these pre-trained models to specific domains. However, there has not been a model specifically adapted for the education domain (particularly K-12) across subjects to the best of our knowledge. In this work, we propose to train a language model on a corpus of data curated by us across multiple subjects from various sources for K-12 education. We also evaluate our model, K-12BERT, on downstream tasks like hierarchical taxonomy tagging.},
	collection   = {Lecture notes in computer science},
	language     = {en}
}
@article{Hochreiter_Schmidhuber_1997,
	title        = {Long short-term memory},
	author       = {Hochreiter, S. and Schmidhuber, J.},
	year         = 1997,
	month        = {Nov},
	journal      = {Neural computation},
	publisher    = {MIT Press - Journals},
	volume       = 9,
	number       = 8,
	pages        = {1735–1780},
	doi          = {10.1162/neco.1997.9.8.1735},
	issn         = {0899-7667},
	url          = {https://direct.mit.edu/neco/article-pdf/9/8/1735/813796/neco.1997.9.8.1735.pdf},
	abstractnote = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter’s (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	language     = {en}
}
@inproceedings{Huang_Wei_Huang_2024,
	title        = {Generating educational materials with different levels of readability using LLMs},
	author       = {Huang, Chieh-Yang and Wei, Jing and Huang, Ting-Hao Kenneth},
	year         = 2024,
	month        = {May},
	booktitle    = {Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	pages        = {16–22},
	doi          = {10.1145/3690712.3690718},
	url          = {https://dl.acm.org/doi/abs/10.1145/3690712.3690718?casa_token=_O9pquyJSZkAAAAA:zWQIHoJdC3pIXthErMB2JTmucjWklS_dpKIC8bdD3YNI2bIp46kfxwhflMGFph-aDnnCh_qM2dU}
}
@article{Jeon_Lee_2023,
	title        = {Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT},
	author       = {Jeon, Jaeho and Lee, Seongyong},
	year         = 2023,
	month        = {Dec},
	journal      = {Education and information technologies},
	publisher    = {Springer Science and Business Media LLC},
	volume       = 28,
	number       = 12,
	pages        = {15873–15892},
	doi          = {10.1007/s10639-023-11834-1},
	issn         = {1360-2357},
	url          = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s10639-023-11834-1&casa_token=1t9D2PEJVmIAAAAA:lnj8Z6V3tYP8c6cCwzNWC6NlRFNPittZYHRg8vhlVJ7Ae98XLrXZv_6kBv87INoDAyQfr_9MQGkoCi8},
	language     = {en}
}
@inproceedings{Jin_Lee_Shin_Kim_2024,
	title        = {Teach AI how to code: Using large language models as teachable agents for programming education},
	author       = {Jin, Hyoungwook and Lee, Seonghee and Shin, Hyungyu and Kim, Juho},
	year         = 2024,
	month        = {May},
	booktitle    = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	volume       = 8,
	pages        = {1–28},
	doi          = {10.1145/3613904.3642349},
	url          = {https://dl.acm.org/doi/10.1145/3613904.3642349},
	language     = {en}
}
@unpublished{Kaufmann_Weng_Bengs_Hüllermeier_2023,
	title        = {A survey of reinforcement learning from human feedback},
	author       = {Kaufmann, Timo and Weng, Paul and Bengs, Viktor and Hüllermeier, Eyke},
	year         = 2023,
	month        = {Dec},
	journal      = {arXiv [cs.LG]},
	url          = {http://arxiv.org/abs/2312.14925},
	abstractnote = {Reinforcement learning from human feedback (RLHF) is a variant of reinforcement learning (RL) that learns from human feedback instead of relying on an engineered reward function. Building on prior work on the related setting of preference-based reinforcement learning (PbRL), it stands at the intersection of artificial intelligence and human-computer interaction. This positioning offers a promising avenue to enhance the performance and adaptability of intelligent systems while also improving the alignment of their objectives with human values. The training of Large Language Models (LLMs) has impressively demonstrated this potential in recent years, where RLHF played a decisive role in targeting the model’s capabilities toward human objectives. This article provides a comprehensive overview of the fundamentals of RLHF, exploring the intricate dynamics between machine agents and human input. While recent focus has been on RLHF for LLMs, our survey adopts a broader perspective, examining the diverse applications and wide-ranging impact of the technique. We delve into the core principles that underpin RLHF, shedding light on the symbiotic relationship between algorithms and human feedback, and discuss the main research trends in the field. By synthesizing the current landscape of RLHF research, this article aims to provide researchers as well as practitioners with a comprehensive understanding of this rapidly growing field of research.}
}
@unpublished{Khalil_Vadiee_Shakya_Liu_2025,
	title        = {Creating artificial students that never existed: Leveraging Large Language Models and CTGANs for synthetic data generation},
	author       = {Khalil, Mohammad and Vadiee, Farhad and Shakya, Ronas and Liu, Qinyi},
	year         = 2025,
	month        = {Jan},
	journal      = {arXiv [cs.LG]},
	url          = {http://arxiv.org/abs/2501.01793},
	abstractnote = {In this study, we explore the growing potential of AI and deep learning technologies, particularly Generative Adversarial Networks (GANs) and Large Language Models (LLMs), for generating synthetic tabular data. Access to quality students data is critical for advancing learning analytics, but privacy concerns and stricter data protection regulations worldwide limit their availability and usage. Synthetic data offers a promising alternative. We investigate whether synthetic data can be leveraged to create artificial students for serving learning analytics models. Using the popular GAN model CTGAN and three LLMs- GPT2, DistilGPT2, and DialoGPT, we generate synthetic tabular student data. Our results demonstrate the strong potential of these methods to produce high-quality synthetic datasets that resemble real students data. To validate our findings, we apply a comprehensive set of utility evaluation metrics to assess the statistical and predictive performance of the synthetic data and compare the different generator models used, specially the performance of LLMs. Our study aims to provide the learning analytics community with valuable insights into the use of synthetic data, laying the groundwork for expanding the field methodological toolbox with new innovative approaches for learning analytics data generation.}
}
@inproceedings{Kolagar_Zarcone_2024,
	title        = {HumSum: A Personalized Lecture Summarization Tool for Humanities Students Using LLMs},
	author       = {Kolagar, Zahra and Zarcone, Alessandra},
	year         = 2024,
	booktitle    = {Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024)},
	pages        = {36–70},
	url          = {https://aclanthology.org/2024.personalize-1.4.pdf},
	abstractnote = {Zahra Kolagar, Alessandra Zarcone. Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024). 2024.}
}
@inproceedings{Koutcheme_Hellas_2024,
	title        = {Propagating large language models programming feedback},
	author       = {Koutcheme, Charles and Hellas, Arto},
	year         = 2024,
	month        = {Jul},
	booktitle    = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	volume       = 1009,
	pages        = {366–370},
	doi          = {10.1145/3657604.3664665},
	url          = {http://dx.doi.org/10.1145/3657604.3664665}
}
@article{Labadze_Grigolia_Machaidze_2023,
	title        = {Role of AI chatbots in education: systematic literature review},
	author       = {Labadze, Lasha and Grigolia, Maya and Machaidze, Lela},
	year         = 2023,
	month        = {Oct},
	journal      = {International journal of educational technology in higher education},
	publisher    = {Springer Science and Business Media LLC},
	volume       = 20,
	number       = 1,
	doi          = {10.1186/s41239-023-00426-1},
	issn         = {2365-9440},
	url          = {http://dx.doi.org/10.1186/s41239-023-00426-1},
	abstractnote = {AbstractAI chatbots shook the world not long ago with their potential to revolutionize education systems in a myriad of ways. AI chatbots can provide immediate support by answering questions, offering explanations, and providing additional resources. Chatbots can also act as virtual teaching assistants, supporting educators through various means. In this paper, we try to understand the full benefits of AI chatbots in education, their opportunities, challenges, potential limitations, concerns, and prospects of using AI chatbots in educational settings. We conducted an extensive search across various academic databases, and after applying specific predefined criteria, we selected a final set of 67 relevant studies for review. The research findings emphasize the numerous benefits of integrating AI chatbots in education, as seen from both students’ and educators’ perspectives. We found that students primarily gain from AI-powered chatbots in three key areas: homework and study assistance, a personalized learning experience, and the development of various skills. For educators, the main advantages are the time-saving assistance and improved pedagogy. However, our research also emphasizes significant challenges and critical factors that educators need to handle diligently. These include concerns related to AI applications such as reliability, accuracy, and ethical considerations.},
	language     = {en}
}
@article{Lecun_Bottou_Bengio_Haffner_1998,
	title        = {Gradient-based learning applied to document recognition},
	author       = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	year         = 1998,
	journal      = {Proceedings of the IEEE. Institute of Electrical and Electronics Engineers},
	publisher    = {Institute of Electrical and Electronics Engineers (IEEE)},
	volume       = 86,
	number       = 11,
	pages        = {2278–2324},
	doi          = {10.1109/5.726791},
	issn         = {0018-9219},
	url          = {https://ieeexplore.ieee.org/document/726791},
	abstractnote = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	language     = {en}
}
@article{Lee_Jung_Jeon_Sohn_Hwang_Moon_Kim_2024,
	title        = {Few-shot is enough: exploring ChatGPT prompt engineering method for automatic question generation in english education},
	author       = {Lee, Unggi and Jung, Haewon and Jeon, Younghoon and Sohn, Younghoon and Hwang, Wonhee and Moon, Jewoong and Kim, Hyeoncheol},
	year         = 2024,
	month        = {Jun},
	journal      = {Education and information technologies},
	publisher    = {Springer Science and Business Media LLC},
	volume       = 29,
	number       = 9,
	pages        = {11483–11515},
	doi          = {10.1007/s10639-023-12249-8},
	issn         = {1360-2357},
	url          = {https://link.springer.com/article/10.1007/s10639-023-12249-8},
	abstractnote = {Through design and development research (DDR), we aimed to create a validated automatic question generation (AQG) system using large language models (LLMs) like ChatGPT, enhanced by prompting engineering techniques. While AQG has become increasingly integral to online learning for its efficiency in generating questions, issues such as inconsistent question quality and the absence of transparent and validated evaluation methods persist. Our research focused on creating a prompt engineering protocol tailored for AQG. This protocol underwent several iterations of refinement and validation to improve its performance. By gathering validation scores and qualitative feedback on the produced questions and the system’s framework, we examined the effectiveness of the system. The study findings indicate that our combined use of LLMs and prompt engineering in AQG produces questions with statistically significant validity. Our research further illuminates academic and design considerations for AQG design in English education: (a) certain question types might not be optimal for generation via ChatGPT, (b) ChatGPT sheds light on the potential for collaborative AI-teacher efforts in question generation, especially within English education.},
	language     = {en}
}
@article{Lin_Han_Thomas_Gurung_Gupta_Aleven_Koedinger_2024,
	title        = {How can I get it right? Using GPT to rephrase incorrect trainee responses},
	author       = {Lin, Jionghao and Han, Zifei and Thomas, Danielle R. and Gurung, Ashish and Gupta, Shivang and Aleven, Vincent and Koedinger, Kenneth R.},
	year         = 2024,
	month        = {Jul},
	journal      = {International journal of artificial intelligence in education},
	publisher    = {Springer Science and Business Media LLC},
	pages        = {1–27},
	doi          = {10.1007/s40593-024-00408-y},
	issn         = {1560-4292},
	url          = {https://link.springer.com/article/10.1007/s40593-024-00408-y},
	abstractnote = {AbstractOne-on-one tutoring is widely acknowledged as an effective instructional method, conditioned on qualified tutors. However, the high demand for qualified tutors remains a challenge, often necessitating the training of novice tutors (i.e., trainees) to ensure effective tutoring. Research suggests that providing timely explanatory feedback can facilitate the training process for trainees. However, it presents challenges due to the time-consuming nature of assessing trainee performance by human experts. Inspired by the recent advancements of large language models (LLMs), our study employed the GPT-4 model to build an explanatory feedback system. This system identifies trainees’ responses in binary form (i.e., correct/incorrect) and automatically provides template-based feedback with responses appropriately rephrased by the GPT-4 model. We conducted our study using the responses of 383 trainees from three training lessons (Giving Effective Praise, Reacting to Errors, and Determining What Students Know). Our findings indicate that: 1) using a few-shot approach, the GPT-4 model effectively identifies correct/incorrect trainees’ responses from three training lessons with an average F1 score of 0.84 and AUC score of 0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases incorrect trainees’ responses into desired responses, achieving performance comparable to that of human experts.},
	language     = {en}
}
@unpublished{Liu_Yin_Lee_Chen_2024,
	title        = {Scaffolding language learning via multi-modal tutoring systems with pedagogical instructions},
	author       = {Liu, Zhengyuan and Yin, Stella Xin and Lee, Carolyn and Chen, Nancy F.},
	year         = 2024,
	month        = {Apr},
	journal      = {arXiv [cs.CL]},
	url          = {http://arxiv.org/abs/2404.03429},
	abstractnote = {Intelligent tutoring systems (ITSs) that imitate human tutors and aim to provide immediate and customized instructions or feedback to learners have shown their effectiveness in education. With the emergence of generative artificial intelligence, large language models (LLMs) further entitle the systems to complex and coherent conversational interactions. These systems would be of great help in language education as it involves developing skills in communication, which, however, drew relatively less attention. Additionally, due to the complicated cognitive development at younger ages, more endeavors are needed for practical uses. Scaffolding refers to a teaching technique where teachers provide support and guidance to students for learning and developing new concepts or skills. It is an effective way to support diverse learning needs, goals, processes, and outcomes. In this work, we investigate how pedagogical instructions facilitate the scaffolding in ITSs, by conducting a case study on guiding children to describe images for language learning. We construct different types of scaffolding tutoring systems grounded in four fundamental learning theories: knowledge construction, inquiry-based learning, dialogic teaching, and zone of proximal development. For qualitative and quantitative analyses, we build and refine a seven-dimension rubric to evaluate the scaffolding process. In our experiment on GPT-4V, we observe that LLMs demonstrate strong potential to follow pedagogical instructions and achieve self-paced learning in different student groups. Moreover, we extend our evaluation framework from a manual to an automated approach, paving the way to benchmark various conversational tutoring systems.}
}
@article{Liyanage_Ranaweera_2023,
	title        = {Ethical considerations and potential risks in the deployment of large language models in diverse societal contexts},
	author       = {Liyanage, Udara Piyasena and Ranaweera, Nimnaka Dilshan},
	year         = 2023,
	month        = {Nov},
	journal      = {Journal of Computational Social Dynamics},
	publisher    = {vectoral.org},
	volume       = 8,
	number       = 11,
	pages        = {15–25},
	url          = {https://vectoral.org/index.php/JCSD/article/view/49},
	abstractnote = {The integration of large language models (LLMs) into various societal applications brings forth a plethora of ethical challenges and potential risks. One primary concern is the perpetuation and amplification of biases present in the training data of LLMs. This risk is acutely pronounced in diverse societal contexts, potentially leading to unfair or harmful outcomes, especially for marginalized groups through stereotypical or discriminatory content generation. Additionally, privacy concerns emerge due to LLMs’ potential to inadvertently memorize and disclose sensitive personal information, a significant issue in environments with varying data protection norms. Another critical risk is the use of LLMs in spreading misinformation and manipulation, with profound implications in political, social, and personal spheres, such as influencing elections or facilitating scams. The increasing dependence on LLMs for various tasks might result in human skill degradation, particularly concerning in educational and professional contexts. Accountability and transparency issues also arise, given the difficulty in pinpointing responsibility for LLM outputs and the “black box” nature of these models. Economically, LLMs pose a threat of job displacement in certain sectors due to their ability to automate tasks traditionally performed by humans, necessitating societal adjustments and new workforce training approaches. Cultural homogenization is another concern, as the dominance of specific languages and cultures in LLM training data might lead to the underrepresentation or misrepresentation of minority cultures. Furthermore, the uneven distribution of LLM benefits exacerbates the digital divide, potentially leaving individuals without advanced technology access behind. The application of LLMs in sensitive fields like healthcare, legal, or law enforcement raises unique ethical considerations, as incorrect or biased advice can have dire consequences.},
	language     = {en}
}
@inbook{López-Pernas_Misiejuk_Saqr_2025,
	title        = {Using BERT-like Language Models for Automated Discourse Coding: A Primer and Tutorial},
	author       = {López-Pernas, Sonsoles and Misiejuk, Kamila and Saqr, Mohammed},
	year         = 2025,
	booktitle    = {Advanced Learning Analytics Methods: AI, Precision and Complexity},
	publisher    = {Springer Nature Switzerland},
	address      = {Cham},
	editor       = {Saqr, Mohammed and López-Pernas, Sonsoles},
	language     = {en}
}
@inbook{López-Pernas_Oliveira_Song_Saqr_2025,
	title        = {AI, Explainable AI and Evaluative AI: An Introduction to Informed Data-Driven Decision-Making in Education},
	author       = {López-Pernas, Sonsoles and Oliveira, Eduardo and Song, Yige and Saqr, Mohammed},
	year         = 2025,
	booktitle    = {Advanced Learning Analytics Methods: AI, Precision and Complexity},
	publisher    = {Springer Nature Switzerland},
	address      = {Cham},
	editor       = {Saqr, Mohammed and López-Pernas, Sonsoles},
	language     = {en}
}
@inbook{López-Pernas_Song_Oliveira_Saqr_2025,
	title        = {LLMs for Explainable Artificial Intelligence: Automating Natural Language Explanations of Predictive Analytics Models},
	author       = {López-Pernas, Sonsoles and Song, Yige and Oliveira, Eduardo and Saqr, Mohammed},
	year         = 2025,
	booktitle    = {Advanced Learning Analytics Methods: AI, Precision and Complexity},
	publisher    = {Springer Nature Switzerland},
	address      = {Cham},
	editor       = {Saqr, Mohammed and López-Pernas, Sonsoles},
	language     = {en}
}
@article{Lundqvist_Liyanagunawardena_Starkey_2020,
	title        = {Evaluation of student feedback within a MOOC using sentiment analysis and target groups},
	author       = {Lundqvist, Karsten and Liyanagunawardena, Tharindu and Starkey, Louise},
	year         = 2020,
	month        = {May},
	journal      = {The International Review of Research in Open and Distributed Learning},
	publisher    = {Athabasca University Press},
	volume       = 21,
	number       = 3,
	pages        = {140–156},
	doi          = {10.19173/irrodl.v21i3.4783},
	issn         = {1492-3831},
	url          = {https://www.irrodl.org/index.php/irrodl/article/view/4783},
	abstractnote = {Many course designers trying to evaluate the experience of participants in a MOOC will find it difficult to track and analyse the online actions and interactions of students because there may be thousands of learners enrolled in courses that sometimes last only a few weeks. This study explores the use of automated sentiment analysis in assessing student experience in a beginner computer programming MOOC. A dataset of more than 25,000 online posts made by participants during the course was analysed and compared to student feedback. The results were further analysed by grouping participants according to their prior knowledge of the subject: beginner, experienced, and unknown. In this study, the average sentiment expressed through online posts reflected the feedback statements. Beginners, the target group for the MOOC, were more positive about the course than experienced participants, largely due to the extra assistance they received. Many experienced participants had expected to learn about topics that were beyond the scope of the MOOC. The results suggest that MOOC designers should consider using sentiment analysis to evaluate student feedback and inform MOOC design.}
}
@article{Misiejuk_Kaliisa_Scianna_2024,
	title        = {Augmenting assessment with AI coding of online student discourse: A question of reliability},
	author       = {Misiejuk, Kamila and Kaliisa, Rogers and Scianna, Jennifer},
	year         = 2024,
	month        = {Jun},
	journal      = {Computers and Education: Artificial Intelligence},
	publisher    = {Elsevier BV},
	volume       = 6,
	number       = 100216,
	pages        = 100216,
	doi          = {10.1016/j.caeai.2024.100216},
	issn         = {2666-920X},
	url          = {https://www.sciencedirect.com/science/article/pii/S2666920X24000171?dgcid=rss_sd_all},
	language     = {en}
}
@article{Mistry_Saeed_Rafique_Le_Obaid_Adams_2024,
	title        = {Large language models as tools to generate radiology board-style multiple-choice questions},
	author       = {Mistry, Neel P. and Saeed, Huzaifa and Rafique, Sidra and Le, Thuy and Obaid, Haron and Adams, Scott J.},
	year         = 2024,
	month        = {Sep},
	journal      = {Academic radiology},
	publisher    = {Elsevier BV},
	volume       = 31,
	number       = 9,
	pages        = {3872–3878},
	doi          = {10.1016/j.acra.2024.06.046},
	issn         = {1076-6332},
	url          = {https://www.sciencedirect.com/science/article/pii/S107663322400432X},
	abstractnote = {RATIONALE AND OBJECTIVES: To determine the potential of large language models (LLMs) to be used as tools by radiology educators to create radiology board-style multiple choice questions (MCQs), answers, and rationales. METHODS: Two LLMs (Llama 2 and GPT-4) were used to develop 104 MCQs based on the American Board of Radiology exam blueprint. Two board-certified radiologists assessed each MCQ using a 10-point Likert scale across five criteria-clarity, relevance, suitability for a board exam based on level of difficulty, quality of distractors, and adequacy of rationale. For comparison, MCQs from prior American College of Radiology (ACR) Diagnostic Radiology In-Training (DXIT) exams were also assessed using these criteria, with radiologists blinded to the question source. RESULTS: Mean scores (±standard deviation) for clarity, relevance, suitability, quality of distractors, and adequacy of rationale were 8.7 (±1.4), 9.2 (±1.3), 9.0 (±1.2), 8.4 (±1.9), and 7.2 (±2.2), respectively, for Llama 2; 9.9 (±0.4), 9.9 (±0.5), 9.9 (±0.4), 9.8 (±0.5), and 9.9 (±0.3), respectively, for GPT-4; and 9.9 (±0.3), 9.9 (±0.2), 9.9 (±0.2), 9.9 (±0.4), and 9.8 (±0.6), respectively, for ACR DXIT items (p < 0.001 for Llama 2 vs. ACR DXIT across all criteria; no statistically significant difference for GPT-4 vs. ACR DXIT). The accuracy of model-generated answers was 69% for Llama 2 and 100% for GPT-4. CONCLUSION: A state-of-the art LLM such as GPT-4 may be used to develop radiology board-style MCQs and rationales to enhance exam preparation materials and expand exam banks, and may allow radiology educators to further use MCQs as teaching and learning tools.},
	keywords     = {Artificial intelligence; Assessment; Large language models; Medical education; Multiple-choice questions},
	language     = {en}
}
@inbook{Ohashi_2024,
	title        = {AI in language education: The impact of machine translation and ChatGPT},
	author       = {Ohashi, Louise},
	year         = 2024,
	booktitle    = {Intelligent Systems Reference Library},
	publisher    = {Springer Nature Switzerland},
	address      = {Cham},
	series       = {Intelligent systems reference library},
	pages        = {289–311},
	doi          = {10.1007/978-3-031-71232-6_13},
	isbn         = 9783031712319,
	issn         = {1868-4408},
	url          = {https://link.springer.com/chapter/10.1007/978-3-031-71232-6_13},
	abstractnote = {This chapter explores the impact of artificial intelligenceArtificial intelligence (AI) (AI) within the field of language educationLanguage education. It focuses on two key areas: machine translationMachine translation (MT) and generative AIGenerative AI (GenAI) chatbot technology, the latter exemplified through ChatGPTChat generative pre-trained transformer (ChatGPT). The author positions these tools as real-world resources that teachers and institutions cannot and should not ignore. It introduces them in turn, explaining how they have evolved over time and providing a brief overview of their inner workings and capabilities. Next, empirical studies are reviewed, revealing the key strengths and weakness of these tools and casting light on teacher and student perspectives. Issues such as learning gains, perceived/actual accuracy of output, and plagiarism (or AI-based plagiarism, ‘AIgiarism’) are covered. In addition to learning-based considerations, issues such as online safety and privacy are discussed. Finally, the need for training and guidelines for teachers and students is addressed and practical activities designed to enhance language development and help with guideline formation are offered for consideration.},
	collection   = {Intelligent systems reference library},
	language     = {en}
}
@article{Perkins_2023,
	title        = {Academic Integrity considerations of AI Large Language Models in the post-pandemic era: ChatGPT and beyond},
	author       = {Perkins, Mike},
	year         = 2023,
	month        = {Jan},
	journal      = {Journal of university teaching & learning practice},
	publisher    = {Open Access Publishing Association},
	volume       = 20,
	number       = 2,
	doi          = {10.53761/1.20.02.07},
	issn         = {1449-9789},
	url          = {https://open-publishing.org/journals/index.php/jutlp/article/view/635},
	abstractnote = {This paper explores the academic integrity considerations of students’ use of Artificial Intelligence (AI) tools using Large Language Models (LLMs) such as ChatGPT in formal assessments. We examine the evolution of these tools, and highlight the potential ways that LLMs can support in the education of students in digital writing and beyond, including the teaching of writing and composition, the possibilities of co-creation between humans and AI, supporting EFL learners, and improving Automated Writing Evaluations (AWE). We describe and demonstrate the potential that these tools have in creating original, coherent text that can avoid detection by existing technological methods of detection and trained academic staff alike, demonstrating a major academic integrity concern related to the use of these tools by students. Analysing the various issues related to academic integrity that LLMs raise for both Higher Education Institutions (HEIs) and students, we conclude that it is not the student use of any AI tools that defines whether plagiarism or a breach of academic integrity has occurred, but whether any use is made clear by the student. Deciding whether any particular use of LLMs by students can be defined as academic misconduct is determined by the academic integrity policies of any given HEI, which must be updated to consider how these tools will be used in future educational environments.},
	keywords     = {Artificial Intelligence; Large Language Models; GPT-3; ChatGPT; plagiarism},
	language     = {en}
}
@inproceedings{Pinargote_Calderón_Cevallos_Carrillo_Chiluiza_Echeverria_2024,
	title        = {Automating data narratives in Learning Analytics Dashboards using GenAI},
	author       = {Pinargote, Adriano and Calderón, Eddy and Cevallos, Kevin and Carrillo, Gladys and Chiluiza, Katherine and Echeverria, Vanessa},
	year         = 2024,
	booktitle    = {2024 Joint of International Conference on Learning Analytics and Knowledge Workshops},
	publisher    = {CEUR-WS},
	pages        = {150–161},
	url          = {https://research.monash.edu/files/606148660/593895957_oa.pdf},
	keywords     = {Artificial Intelligence; Dashboards; GenAI; Narrative Storytelling},
	language     = {en}
}
@inproceedings{Pinto_Cardoso-Pereira_Monteiro_Lucena_Souza_Gama_2023,
	title        = {Large language models for education: Grading open-ended questions using ChatGPT},
	author       = {Pinto, Gustavo and Cardoso-Pereira, Isadora and Monteiro, Danilo and Lucena, Danilo and Souza, Alberto and Gama, Kiev},
	year         = 2023,
	month        = {Sep},
	booktitle    = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	pages        = {293–302},
	doi          = {10.1145/3613372.3614197},
	url          = {https://dl.acm.org/doi/abs/10.1145/3613372.3614197?casa_token=EQ7YgLsFdogAAAAA:M7CtdNC5eNEiVz9-kPtIgfVATc_azuQmIWfOATE4W40arAHt4HSV56eaX2R_SKxHCm1gpBm6WsdMKQ}
}
@article{Rani_Nabi_Kumar_Mittal_Kumar_2023,
	title        = {Self-supervised learning: A succinct review},
	author       = {Rani, Veenu and Nabi, Syed Tufael and Kumar, Munish and Mittal, Ajay and Kumar, Krishan},
	year         = 2023,
	month        = {Jan},
	journal      = {Archives of Computational Methods in Engineering. State of the Art Reviews},
	publisher    = {Springer Science and Business Media LLC},
	volume       = 30,
	number       = 4,
	pages        = {2761–2775},
	doi          = {10.1007/s11831-023-09884-2},
	issn         = {1134-3060},
	url          = {https://link.springer.com/article/10.1007/s11831-023-09884-2},
	abstractnote = {Machine learning has made significant advances in the field of image processing. The foundation of this success is supervised learning, which necessitates annotated labels generated by humans and hence learns from labelled data, whereas unsupervised learning learns from unlabeled data. Self-supervised learning (SSL) is a type of un-supervised learning that helps in the performance of downstream computer vision tasks such as object detection, image comprehension, image segmentation, and so on. It can develop generic artificial intelligence systems at a low cost using unstructured and unlabeled data. The authors of this review article have presented detailed literature on self-supervised learning as well as its applications in different domains. The primary goal of this review article is to demonstrate how images learn from their visual features using self-supervised approaches. The authors have also discussed various terms used in self-supervised learning as well as different types of learning, such as contrastive learning, transfer learning, and so on. This review article describes in detail the pipeline of self-supervised learning, including its two main phases: pretext and downstream tasks. The authors have shed light on various challenges encountered while working on self-supervised learning at the end of the article.},
	keywords     = {Contrastive learning; Machine learning; Self-supervised; Supervised learning; Un-supervised learning},
	language     = {en}
}
@unpublished{Schulman_Wolski_Dhariwal_Radford_Klimov_2017,
	title        = {Proximal Policy Optimization Algorithms},
	author       = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	year         = 2017,
	journal      = {arXiv [cs.LG]},
	doi          = {10.48550/ARXIV.1707.06347},
	url          = {http://dx.doi.org/10.48550/ARXIV.1707.06347},
	abstractnote = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a “surrogate” objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.}
}
@misc{Shen_Heacock_Elias_Hentel_Reig_Shih_Moy_2023,
	title        = {ChatGPT and other large language models are double-edged swords},
	author       = {Shen, Yiqiu and Heacock, Laura and Elias, Jonathan and Hentel, Keith D. and Reig, Beatriu and Shih, George and Moy, Linda},
	year         = 2023,
	month        = {Apr},
	journal      = {Radiology},
	publisher    = {Radiological Society of North America (RSNA)},
	volume       = 307,
	number       = 2,
	pages        = {e230163},
	doi          = {10.1148/radiol.230163},
	issn         = {0033-8419},
	url          = {https://doi.org/10.1148/radiol.230163},
	language     = {en}
}
@article{Vaiani_Cagliero_Garza_2024,
	title        = {Emotion recognition from videos using Multimodal Large Language Models},
	author       = {Vaiani, Lorenzo and Cagliero, Luca and Garza, Paolo},
	year         = 2024,
	month        = {Jul},
	journal      = {Future internet},
	publisher    = {MDPI AG},
	volume       = 16,
	number       = 7,
	pages        = 247,
	doi          = {10.3390/fi16070247},
	issn         = {1999-5903},
	url          = {http://dx.doi.org/10.3390/fi16070247},
	abstractnote = {The diffusion of Multimodal Large Language Models (MLLMs) has opened new research directions in the context of video content understanding and classification. Emotion recognition from videos aims to automatically detect human emotions such as anxiety and fear. It requires deeply elaborating multiple data modalities, including acoustic and visual streams. State-of-the-art approaches leverage transformer-based architectures to combine multimodal sources. However, the impressive performance of MLLMs in content retrieval and generation offers new opportunities to extend the capabilities of existing emotion recognizers. This paper explores the performance of MLLMs in the emotion recognition task in a zero-shot learning setting. Furthermore, it presents a state-of-the-art architecture extension based on MLLM content reformulation. The performance achieved on the Hume-Reaction benchmark shows that MLLMs are still unable to outperform the state-of-the-art average performance but, notably, are more effective than traditional transformers in recognizing emotions with an intensity that deviates from the average of the samples.},
	language     = {en}
}
@article{Vaswani_Shazeer_Parmar_Uszkoreit_Jones_Gomez_Kaiser_Polosukhin_2017,
	title        = {Attention is All you Need},
	author       = {Vaswani, Ashish and Shazeer, Noam M. and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year         = 2017,
	month        = {Jun},
	journal      = {Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 30,
	pages        = {5998–6008},
	url          = {https://papers.nips.cc/paper/7181-attention-is-all-you-need},
	abstractnote = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	editor       = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.}
}
@article{Wang_Li_Wu_Hovy_Sun_2022,
	title        = {Pre-trained language models and their applications},
	author       = {Wang, Haifeng and Li, Jiwei and Wu, Hua and Hovy, Eduard and Sun, Yu},
	year         = 2022,
	month        = {Sep},
	journal      = {Engineering (Beijing, China)},
	publisher    = {Elsevier BV},
	volume       = 25,
	pages        = {51–65},
	doi          = {10.1016/j.eng.2022.04.024},
	issn         = {2095-8099},
	url          = {https://www.sciencedirect.com/science/article/pii/S2095809922006324},
	language     = {en}
}
@inproceedings{Wang_Chen_2023,
	title        = {A review on code generation with LLMs: Application and evaluation},
	author       = {Wang, Jianxun and Chen, Yixiang},
	year         = 2023,
	month        = {Nov},
	booktitle    = {2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)},
	publisher    = {IEEE},
	pages        = {284–289},
	doi          = {10.1109/medai59581.2023.00044},
	url          = {https://ieeexplore.ieee.org/abstract/document/10403378/?casa_token=Kykb_0n6lXMAAAAA:TQaoycJe36UMmhE-yVR5FK12d8Ju4YQc-fGYOH0R8yFKhmiGaiyGSVBrtAbad5ZwngRALnjx}
}
@unpublished{Wang_Zhong_Li_Mi_Zeng_Huang_Shang_Jiang_Liu_2023,
	title        = {Aligning large Language Models with human: A survey},
	author       = {Wang, Yufei and Zhong, Wanjun and Li, Liangyou and Mi, Fei and Zeng, Xingshan and Huang, Wenyong and Shang, Lifeng and Jiang, Xin and Liu, Qun},
	year         = 2023,
	month        = {Jul},
	journal      = {arXiv [cs.CL]},
	url          = {http://arxiv.org/abs/2307.12966},
	abstractnote = {Large Language Models (LLMs) trained on extensive textual corpora have emerged as leading solutions for a broad array of Natural Language Processing (NLP) tasks. Despite their notable performance, these models are prone to certain limitations such as misunderstanding human instructions, generating potentially biased content, or factually incorrect (hallucinated) information. Hence, aligning LLMs with human expectations has become an active area of interest within the research community. This survey presents a comprehensive overview of these alignment technologies, including the following aspects. (1) Data collection: the methods for effectively collecting high-quality instructions for LLM alignment, including the use of NLP benchmarks, human annotations, and leveraging strong LLMs. (2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment. Our exploration encompasses Supervised Fine-tuning, both Online and Offline human preference training, along with parameter-efficient training mechanisms. (3) Model Evaluation: the methods for evaluating the effectiveness of these human-aligned LLMs, presenting a multifaceted approach towards their assessment. In conclusion, we collate and distill our findings, shedding light on several promising future research avenues in the field. This survey, therefore, serves as a valuable resource for anyone invested in understanding and advancing the alignment of LLMs to better suit human-oriented tasks and expectations. An associated GitHub link collecting the latest papers is available at https://github.com/GaryYufei/AlignLLMHumanSurvey.}
}
@article{Wei_2024,
	title        = {Text-to-speech technology and math performance: A comparative study of students with disabilities, English language learners, and their general education peers},
	author       = {Wei, Xin},
	year         = 2024,
	month        = {Jun},
	journal      = {Educational researcher (Washington, D.C.: 1972)},
	publisher    = {American Educational Research Association (AERA)},
	volume       = 53,
	number       = 5,
	pages        = {285–295},
	doi          = {10.3102/0013189x241232995},
	issn         = {0013-189X},
	url          = {https://journals.sagepub.com/doi/full/10.3102/0013189X241232995?casa_token=e7N4PHj2jakAAAAA%3AXqC0qY3bahIF-NLO9Lt6exgQsluKY0gNbtDJcGPV_HsAv8-UvpM5uZlq6o1U3HzuUxzwPO2Sh7NGPw},
	abstractnote = {This study investigates the relationship between text-to-speech (TTS) usage and item-by-item performance in the 2017 eighth-grade National Assessment of Educational Progress (NAEP) math assessment, focusing on students with disabilities (SWDs), English language learners (ELLs), and their general education (GE) peers. Results indicate that all students use TTS more for longer and more difficult math items as well as for multiple-choice or short-response formats. Among SWDs and GE students, lower math proficiency and higher perceived time pressure are linked to higher TTS usage. Moreover, among GE students, factors such as male gender, minority status, lower math persistence, and higher math interest and effort during testing contribute to higher TTS usage. TTS usage is positively associated with item performance for SWDs and ELLs who received extended time accommodations but not for those who did not receive such accommodations or for general education students. The study suggests that the time constraints of speeded digital assessments may limit the potential benefits of TTS for SWDs and ELLs in math problem-solving.},
	language     = {en}
}
@book{Wickham_2024,
	title        = {elmer: Call LLM APIs from R},
	author       = {Wickham, Hadley},
	year         = 2024,
	publisher    = {Github},
	url          = {https://github.com/tidyverse/elmer},
	abstractnote = {Call LLM APIs from R. Contribute to tidyverse/elmer development by creating an account on GitHub.},
	language     = {en}
}
@article{Woo_Wang_Susanto_Guo_2023,
	title        = {Understanding English as a foreign language students’ idea generation strategies for creative writing with natural language generation tools},
	author       = {Woo, David James and Wang, Yanzhi and Susanto, Hengky and Guo, Kai},
	year         = 2023,
	month        = {Dec},
	journal      = {Journal of educational computing research},
	publisher    = {SAGE Publications},
	volume       = 61,
	number       = 7,
	pages        = {1464–1482},
	doi          = {10.1177/07356331231175999},
	issn         = {0735-6331},
	url          = {http://dx.doi.org/10.1177/07356331231175999},
	abstractnote = {Natural language generation (NLG) is a process within artificial intelligence where computer systems produce human-comprehensible language texts from information. English as a foreign language (EFL) students’ use of NLG tools might facilitate their idea generation, which is fundamental to creative writing. However, little is known about how EFL students interact with NLG tools to generate ideas. This study explores strategies adopted by EFL students when searching for ideas using NLG tools, evaluating ideas generated by NLG tools and selecting NLG tools for idea generation. Four Hong Kong secondary school students attended workshops where they learned to write stories comprising their own words and words generated by NLG tools. After the workshops, they answered questions to reflect on their writing experience with NLG tools. In a thematic analysis of the written reflections, we found students may have existing ideas when searching for ideas and evaluating ideas with NLG tools. Students showed some aversion to ideas generated by NLG tools and selected NLG tools that generated a greater quantity of ideas. The findings inform our understanding of EFL students’ concerns when using NLG tools for idea generation and can inform educators’ instruction to implement NLG tools for classroom creative writing.},
	language     = {en}
}
@inbook{Wu_Henriksson_Duneld_Nouri_2023,
	title        = {Towards improving the reliability and transparency of ChatGPT for educational question answering},
	author       = {Wu, Yongchao and Henriksson, Aron and Duneld, Martin and Nouri, Jalal},
	year         = 2023,
	booktitle    = {Lecture Notes in Computer Science},
	publisher    = {Springer Nature Switzerland},
	address      = {Cham},
	series       = {Lecture notes in computer science},
	pages        = {475–488},
	doi          = {10.1007/978-3-031-42682-7_32},
	isbn         = 9783031426810,
	issn         = {1611-3349},
	url          = {https://link.springer.com/chapter/10.1007/978-3-031-42682-7_32},
	abstractnote = {Large language models (LLMs), such as ChatGPT, have shown remarkable performance on various natural language processing (NLP) tasks, including educational question answering (EQA). However, LLMs generate text entirely based on knowledge obtained during pre-training, which means they struggle with recent information or domain-specific knowledge bases. Moreover, only providing answers to questions posed to LLMs without any grounding materials makes it difficult for students to judge their validity. We therefore propose a method for integrating information retrieval systems with LLMs when developing EQA systems, which in addition to improving EQA performance grounds the answers in the educational context. Our experiments show that the proposed system outperforms vanilla ChatGPT with a significant margin of 110.9%, 67.8%, 43.3%, and 9.2% on BLEU, ROUGE, METEOR and BERTScore. In addition, we argue that the use of the retrieved educational context enhances the transparency and reliability of the EQA process, making it easier to determine the correctness of the answers.},
	collection   = {Lecture notes in computer science},
	language     = {en}
}
@inproceedings{Zhang_Liu_Ziska_Jeon_Yu_Xu_2024,
	title        = {Mathemyths: Leveraging large language models to teach mathematical language through child-AI co-creative storytelling},
	author       = {Zhang, Chao and Liu, Xuechen and Ziska, Katherine and Jeon, Soobin and Yu, Chi-Lin and Xu, Ying},
	year         = 2024,
	month        = {May},
	booktitle    = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	volume       = 33,
	pages        = {1–23},
	doi          = {10.1145/3613904.3642647},
	url          = {https://dl.acm.org/doi/abs/10.1145/3613904.3642647}
}
@unpublished{Zhang_Yu_Dong_Li_Su_Chu_Yu_2024,
	title        = {MM-LLMs: Recent advances in MultiModal Large Language Models},
	author       = {Zhang, Duzhen and Yu, Yahan and Dong, Jiahua and Li, Chenxing and Su, Dan and Chu, Chenhui and Yu, Dong},
	year         = 2024,
	month        = {Jan},
	journal      = {arXiv [cs.CL]},
	url          = {http://arxiv.org/abs/2401.13601},
	abstractnote = {In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Initially, we outline general design formulations for model architecture and training pipeline. Subsequently, we introduce a taxonomy encompassing 126 MM-LLMs, each characterized by its specific formulations. Furthermore, we review the performance of selected MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs. Finally, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field. We hope that this survey contributes to the ongoing advancement of the MM-LLMs domain.}
}
@unpublished{Zytek_Pidò_Veeramachaneni_2024,
	title        = {LLMs for XAI: Future Directions for Explaining Explanations},
	author       = {Zytek, Alexandra and Pidò, Sara and Veeramachaneni, Kalyan},
	year         = 2024,
	month        = {May},
	journal      = {arXiv [cs.AI]},
	url          = {http://arxiv.org/abs/2405.06064},
	abstractnote = {In response to the demand for Explainable Artificial Intelligence (XAI), we investigate the use of Large Language Models (LLMs) to transform ML explanations into natural, human-readable narratives. Rather than directly explaining ML models using LLMs, we focus on refining explanations computed using existing XAI algorithms. We outline several research directions, including defining evaluation metrics, prompt design, comparing LLM models, exploring further training methods, and integrating external data. Initial experiments and user study suggest that LLMs offer a promising way to enhance the interpretability and usability of XAI.}
}

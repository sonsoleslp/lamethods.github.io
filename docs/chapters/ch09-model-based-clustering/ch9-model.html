<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Luca Scrucca">
<meta name="author" content="Mohammed Saqr">
<meta name="author" content="Sonsoles López-Pernas">
<meta name="author" content="Keefe Murphy">
<meta name="keywords" content="Gaussian mixture model, latent profile analysis, model-based clustering, learning analytics">

<title>Learning analytics methods and tutorials - 9&nbsp; An Introduction and R Tutorial to Model-based Clustering in Education via Latent Profile Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/ch10-sequence-analysis/ch10-seq.html" rel="next">
<link href="../../chapters/ch08-clustering/ch8-clus.html" rel="prev">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y4VBV3J9WD"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y4VBV3J9WD', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  

<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Learning analytics methods and tutorials - 9&nbsp; An Introduction and R Tutorial to Model-based Clustering in Education via Latent Profile Analysis">
<meta name="twitter:description" content="Heterogeneity has been a hot topic in recent educational literature.">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="[9]{.chapter-number}&nbsp; [An Introduction and R Tutorial to Model-based Clustering in Education via Latent Profile Analysis]{.chapter-title}">
<meta name="citation_abstract" content="Heterogeneity has been a hot topic in recent educational literature. Several calls have been voiced to adopt methods that capture different patterns or subgroups within students’ behavior or functioning. Assuming that there is “an average” pattern that represents the entirety of student populations requires the measured construct to have the same causal mechanism, same development pattern, and affect students in exactly the same way.  Using a person-centered method (finite Gaussian mixture model or latent profile analysis), the present tutorial shows how to uncover the heterogeneity within engagement data by identifying three latent or unobserved clusters. This chapter offers an introduction to the model-based clustering that includes the principles of the methods, a guide to choice of number of clusters, evaluation of clustering results and a detailed guide with code and a real-life dataset. The discussion elaborates on the interpretation of the results, the advantages of model-based clustering as well as how it compares with other methods.">
<meta name="citation_keywords" content="Gaussian mixture model, latent profile analysis, model-based clustering, learning analytics">
<meta name="citation_author" content="Luca Scrucca">
<meta name="citation_author" content="Mohammed Saqr">
<meta name="citation_author" content="Sonsoles López-Pernas">
<meta name="citation_author" content="Keefe Murphy">
<meta name="citation_fulltext_html_url" content="https://lamethods.github.io/ch9-model.html">
<meta name="citation_doi" content="10.1007/978-3-031-54464-4_9">
<meta name="citation_language" content="en">
<meta name="citation_firstpage" content="285">
<meta name="citation_lastpage" content="317">
<meta name="citation_reference" content="citation_title=Sequence analysis in education: Principles, technique, and tutorial with r;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Satu Helske;,citation_author=Marion Durand;,citation_author=Keefe Murphy;,citation_author=Matthias Studer;,citation_author=Gilbert Ritschard;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using R;">
<meta name="citation_reference" content="citation_title=A modern approach to transition analysis and process mining with markov models: A tutorial with R;,citation_author=Jouni Helske;,citation_author=Satu Helske;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Keefe Murphy;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using R;">
<meta name="citation_reference" content="citation_title=Model-based Gaussian and non-Gaussian clustering;,citation_author=J. Banfield;,citation_author=Adrian E. Raftery;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_issue=3;,citation_doi=10.2307/2532201;,citation_volume=49;,citation_journal_title=Biometrics;">
<meta name="citation_reference" content="citation_title=Latent variable models and factor analysis: A unified approach;,citation_author=David J Bartholomew;,citation_author=Martin Knott;,citation_author=Irini Moustaki;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=904;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=Standard errors of fitted component means of normal mixtures;,citation_author=K E Basford;,citation_author=D R Greenway;,citation_author=G J McLachlan;,citation_author=D Peel;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=1;,citation_volume=12;,citation_journal_title=Computational Statistics;,citation_publisher=Citeseer;">
<meta name="citation_reference" content="citation_title=Assessing a mixture model for clustering with the integrated completed likelihood;,citation_author=Christophe Biernacki;,citation_author=Gilles Celeux;,citation_author=Gérard Govaert;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=7;,citation_volume=22;,citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence;">
<meta name="citation_reference" content="citation_title=Latent Dirichlet allocation;,citation_author=David M Blei;,citation_author=Andrew Y Ng;,citation_author=Michael I Jordan;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=3;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Gaussian parsimonious clustering models;,citation_author=Gilles Celeux;,citation_author=Gérard Govaert;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_issue=5;,citation_doi=10.1016/0031-3203(94)00125-6;,citation_volume=28;,citation_journal_title=Pattern Recognition;">
<meta name="citation_reference" content="citation_title=An entropy criterion for assessing the number of clusters in a mixture model;,citation_author=Gilles Celeux;,citation_author=Gilda Soromenho;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=2;,citation_volume=13;,citation_journal_title=Journal of Classification;">
<meta name="citation_reference" content="citation_title=Elements of information theory;,citation_author=Thomas M Cover;,citation_author=Joy A Thomas;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=20;,citation_series_title=Wiley series in telecommunications and signal processing;">
<meta name="citation_reference" content="citation_title=Maximum likelihood from incomplete data via the EM algorithm (with discussion);,citation_author=A. P. Dempster;,citation_author=N. M. Laird;,citation_author=D. B. Rubin;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=1;,citation_doi=10.1111/j.2517-6161.1977.tb01600.x;,citation_volume=39;,citation_journal_title=Journal of the Royal Statistical Society: Series B (Statistical Methodology);">
<meta name="citation_reference" content="citation_title=Bootstrap methods: Another look at the jackknife;,citation_author=Bradley Efron;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=1;,citation_volume=7;,citation_journal_title=The Annals of Statistics;">
<meta name="citation_reference" content="citation_title=Cluster Analysis;,citation_author=B. S. Everitt;,citation_author=S. Landau;,citation_author=M. Leese;,citation_author=D. Stahl;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=848;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=Model-based clustering, discriminant analysis, and density estimation;,citation_author=Chris Fraley;,citation_author=Adrian E. Raftery;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=458;,citation_doi=10.1198/016214502760047131;,citation_volume=97;,citation_journal_title=Journal of the American Statistical Association;">
<meta name="citation_reference" content="citation_title=Bayesian regularization for normal mixture estimation and model-based clustering;,citation_author=Chris Fraley;,citation_author=Adrian E. Raftery;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=24;,citation_journal_title=Journal of Classification;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=What are the true clusters?;,citation_author=C. Hennig;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_volume=64;,citation_journal_title=Pattern Recognition Letters;">
<meta name="citation_reference" content="citation_title=mclust: Gaussian mixture modelling for model-based clustering, classification, and density estimation;,citation_author=Chris Fraley;,citation_author=Adrian E. Raftery;,citation_author=Luca Scrucca;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=mclust;">
<meta name="citation_reference" content="citation_title=A general method for analysis of covariance structures;,citation_author=Karl G Jöreskog;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_issue=2;,citation_volume=57;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=The EM algorithm and extensions;,citation_author=G. J. McLachlan;,citation_author=T. Krishnan;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=382;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=Finite mixture models;,citation_author=G. J. McLachlan;,citation_author=D. Peel;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_volume=299;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=Approximate bayesian inference with the weighted likelihood bootstrap (with discussion);,citation_author=Michael A Newton;,citation_author=Adrian E Raftery;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=1;,citation_volume=56;,citation_journal_title=Journal of the Royal Statistical Society: Series B (Statistical Methodology);">
<meta name="citation_reference" content="citation_title=Ten frequently asked questions about latent class analysis;,citation_author=K. Nylund-Gibson;,citation_author=A. Y. Choi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=4;,citation_journal_title=Translational Issues in Psychological Science;">
<meta name="citation_reference" content="citation_title=Investigation of parameter uncertainty in clustering using a Gaussian mixture model via jackknife, bootstrap and weighted likelihood bootstrap;,citation_author=Adrian O’Hagan;,citation_author=Thomas Brendan Murphy;,citation_author=Luca Scrucca;,citation_author=Isobel Claire Gormley;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=4;,citation_doi=10.1007/s00180-019-00897-9;,citation_volume=34;,citation_journal_title=Computational Statistics;">
<meta name="citation_reference" content="citation_title=R: A language and environment for statistical computing;,citation_author=R Core Team;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://www.R-project.org/;">
<meta name="citation_reference" content="citation_title=The Bayesian bootstrap;,citation_author=Donald B Rubin;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=1;,citation_volume=9;,citation_journal_title=The Annals of Statistics;">
<meta name="citation_reference" content="citation_title=Estimating the dimension of a model;,citation_author=G. Schwarz;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=2;,citation_doi=10.1214/aos/1176344136;,citation_volume=6;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=mclust 5: Clustering, classification and density estimation using Gaussian finite mixture models;,citation_author=Luca Scrucca;,citation_author=Michael Fop;,citation_author=T. Brendan Murphy;,citation_author=Adrian E. Raftery;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=https://journal.r-project.org/archive/2016-1/scrucca-fop-murphy-etal.pdf;,citation_issue=1;,citation_doi=10.32614/RJ-2016-021;,citation_issn=2073-4859;,citation_volume=8;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=Model-based clustering, classification, and density estimation using mclust in R;,citation_author=Luca Scrucca;,citation_author=Chris Fraley;,citation_author=T. Brendan Murphy;,citation_author=Adrian E. Raftery;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_doi=10.1201/9781003277965;,citation_isbn=978-1032234953;,citation_series_title=The R series;">
<meta name="citation_reference" content="citation_title=Algorithms for model-based Gaussian hierarchical clustering;,citation_author=Chris Fraley;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=1;,citation_doi=10.1137/S1064827596311451;,citation_volume=20;,citation_journal_title=SIAM Journal on Scientific Computing;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=TidyLPA: An R package to easily carry out latent profile analysis (LPA) using open-source or commercial software;,citation_author=Joshua M. Rosenberg;,citation_author=Patrick N. Beymer;,citation_author=Daniel J. Anderson;,citation_author=Caspar J. Van Lissa;,citation_author=Jennifer A. Schmidt;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://joss.theoj.org/papers/10.21105/joss.00978;,citation_issue=30;,citation_doi=10.21105/joss.00978;,citation_volume=3;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=“General Intelligence,” objectively determined and measured;,citation_author=C. Spearman;,citation_publication_date=1904;,citation_cover_date=1904;,citation_year=1904;,citation_issue=2;,citation_doi=10.2307/1412107;,citation_volume=15;,citation_journal_title=The American Journal of Psychology;">
<meta name="citation_reference" content="citation_title=Hidden Markov models for time series: An introduction using R;,citation_author=Walter Zucchini;,citation_author=Iain L MacDonald;,citation_author=Roland Langrock;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=105;,citation_series_title=Monographs on statistics and applied probability;">
<meta name="citation_reference" content="citation_title=Latent Markov models for longitudinal data;,citation_author=Francesco Bartolucci;,citation_author=Alessio Farcomeni;,citation_author=Fulvia Pennoni;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_isbn=9780429102578;">
<meta name="citation_reference" content="citation_title=Combining latent profile analysis and programming traces to understand novices’ differences in debugging;,citation_author=Yingbin Zhang;,citation_author=Luc Paquette;,citation_author=Juan D Pinto;,citation_author=Qianhui Liu;,citation_author=Aysa Xuemo Fan;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=4;,citation_doi=10.1007/s10639-022-11343-7;,citation_issn=1573-7608;,citation_volume=28;,citation_journal_title=Education and Information Technologies;">
<meta name="citation_reference" content="citation_title=A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning;,citation_author=Törmänen;,citation_author=Järvenoja;,citation_author=Saqr;,citation_author=Malmberg;,citation_author=others;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_doi=10.3389/feduc.2022.866612;,citation_issn=2504-284X;,citation_volume=7;,citation_journal_title=Frontiers in Education;">
<meta name="citation_reference" content="citation_title=Engineering students’ noncognitive and affective factors: Group differences from cluster analysis;,citation_author=Matthew Scheidt;,citation_author=Allison Godwin;,citation_author=Edward Berger;,citation_author=John Chen;,citation_author=Brian P Self;,citation_author=James M Widmann;,citation_author=Ann Q Gates;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=2;,citation_doi=10.1002/jee.20386;,citation_issn=1069-4730, 2168-9830;,citation_volume=110;,citation_journal_title=Journal of Engineering Education;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Logs or Self-Reports? Misalignment between behavioral trace data and surveys when modeling learner achievement goal orientation;,citation_author=Heeryung Choi;,citation_author=Philip H Winne;,citation_author=Christopher Brooks;,citation_author=Warren Li;,citation_author=Kerby Shedden;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_doi=10.1145/3576050.3576052;,citation_isbn=9781450398657;,citation_conference_title=LAK23: 13th international learning analytics and knowledge conference;,citation_conference=Association for Computing Machinery;,citation_series_title=LAK2023;">
<meta name="citation_reference" content="citation_title=Investigating students’ emotional self-efficacy profiles and their relations to self-regulation, motivation, and academic performance in online learning contexts: A person-centered approach;,citation_author=Jianhui Yu;,citation_author=Changqin Huang;,citation_author=Tao He;,citation_author=Xizhe Wang;,citation_author=Linjie Zhang;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=8;,citation_doi=10.1007/s10639-022-11099-0;,citation_issn=1573-7608;,citation_volume=27;,citation_journal_title=Education and Information Technologies;">
<meta name="citation_reference" content="citation_title=Variable-Centered, Person-Centered, and Person-Specific approaches: Where theory meets the method;,citation_author=Matt C. Howard;,citation_author=Michael E. Hoffman;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_doi=10.1177/1094428117744021;,citation_volume=21;,citation_journal_title=Organizational Research Methods;">
<meta name="citation_reference" content="citation_title=Informative tools for characterizing individual differences in learning: Latent class, latent profile, and latent transition analysis;,citation_author=Marian Hickendorff;,citation_author=Peter A Edelsbrunner;,citation_author=Jake McMullen;,citation_author=Michael Schneider;,citation_author=Kelly Trezise;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.1016/j.lindif.2017.11.001;,citation_issn=1041-6080, 1873-3425;,citation_volume=66;,citation_journal_title=Learning and Individual Differences;">
<meta name="citation_reference" content="citation_title=Investigating patterns of study persistence on Self-Assessment platform of programming Problem-Solving;,citation_author=Cheng-Yu Chung;,citation_author=I-Han Hsiao;,citation_publication_date=2020-02;,citation_cover_date=2020-02;,citation_year=2020;,citation_doi=10.1145/3328778.3366827;,citation_isbn=9781450367936;,citation_conference_title=Proceedings of the 51st ACM technical symposium on computer science education;,citation_conference=Association for Computing Machinery;,citation_series_title=SIGCSE ’20;">
<meta name="citation_reference" content="citation_title=Transitioning from school to university: A person-oriented approach to understanding first-year students’ classroom engagement in higher education;,citation_author=Vo Ngoc Hoi;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_doi=10.1080/00131911.2022.2159935;,citation_issn=0013-1911;,citation_journal_title=Educational Review;,citation_publisher=Routledge;">
<meta name="citation_reference" content="citation_title=The longitudinal trajectories of online engagement over a full program;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_fulltext_html_url=https://doi.org/10.1016/j.compedu.2021.104325;,citation_doi=10.1016/j.compedu.2021.104325;,citation_volume=175;,citation_journal_title=Computers &amp;amp;amp; Education;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=The longitudinal association between engagement and achievement varies by time, students’ subgroups, and achievement state: A full program study;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Satu Helske;,citation_author=Stefan Hrastinski;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_doi=10.1016/j.compedu.2023.104787;,citation_issn=0360-1315;,citation_volume=199;,citation_journal_title=Computers &amp;amp;amp; Education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Trajectory patterns of academic engagement among elementary school students: The implicit theory of intelligence and academic self-efficacy matters;,citation_author=Rui Zhen;,citation_author=Ru-De Liu;,citation_author=Ming-Te Wang;,citation_author=Yi Ding;,citation_author=Ronghuan Jiang;,citation_author=Xinchen Fu;,citation_author=Yan Sun;,citation_publication_date=2019-10;,citation_cover_date=2019-10;,citation_year=2019;,citation_fulltext_html_url=https://doi.org/10.1111/bjep.12320;,citation_issue=3;,citation_doi=10.1111/bjep.12320;,citation_volume=90;,citation_journal_title=British Journal of Educational Psychology;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Joint trajectories of behavioral, affective, and cognitive engagement in elementary school;,citation_author=Isabelle Archambault;,citation_author=Véronique Dupéré;,citation_publication_date=2016-09;,citation_cover_date=2016-09;,citation_year=2016;,citation_fulltext_html_url=https://doi.org/10.1080/00220671.2015.1060931;,citation_issue=2;,citation_doi=10.1080/00220671.2015.1060931;,citation_volume=110;,citation_journal_title=The Journal of Educational Research;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Data-Driven validation of pedagogical model - A case of blended LCM model;,citation_author=Hiroyuki Kuromiya;,citation_author=Rwiajit Majumdar;,citation_author=Jayakrishnan Warriem;,citation_author=Hiroaki Ogata;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_doi=10.1109/T4E.2019.00016;,citation_conference_title=Proceedings of the 2019 IEEE tenth international conference on technology for education (T4E);">
<meta name="citation_reference" content="citation_title=How CSCL roles emerge, persist, transition, and evolve over time: A four-year longitudinal study;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_doi=10.1016/j.compedu.2022.104581;,citation_issn=0360-1315;,citation_volume=189;,citation_journal_title=Computers &amp;amp;amp; Education;">
<meta name="citation_reference" content="citation_title=Profiles of vocational college students’ achievement emotions in online learning environments: Antecedents and outcomes;,citation_author=Shonn Cheng;,citation_author=Jui-Chieh Huang;,citation_author=Waneta Hebert;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_doi=10.1016/j.chb.2022.107452;,citation_issn=0747-5632;,citation_volume=138;,citation_journal_title=Computers in Human Behaviour;">
<meta name="citation_reference" content="citation_title=Clustering longitudinal life-course sequences using mixtures of exponential-distance models;,citation_author=Keefe Murphy;,citation_author=Thomas Brendan Murphy;,citation_author=Raffaella Piccarreta;,citation_author=Isobel Claire Gormley;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssa.12712;,citation_issue=4;,citation_doi=10.1111/rssa.12712;,citation_volume=184;,citation_journal_title=Journal of the Royal Statistical Society: Series A (Statistics in Society);">
<meta name="citation_reference" content="citation_title=Mixture hidden Markov models for sequence data: The seqHMM package in R;,citation_author=S. Helske;,citation_author=J. Helske;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=3;,citation_volume=88;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Model based clustering for mixed data: clustMD;,citation_author=D. McParland;,citation_author=I. C. Gormley;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=2;,citation_volume=10;,citation_journal_title=Advances in Data Analysis and Classification;">
<meta name="citation_reference" content="citation_title=Methods for merging Gaussian mixture components;,citation_author=C. Hennig;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=1;,citation_volume=4;,citation_journal_title=Advances in Data Analysis and Classification;">
<meta name="citation_reference" content="citation_title=mixture: Mixture models for clustering and classification;,citation_author=Nik Pocuca;,citation_author=Ryan P. Browne;,citation_author=Paul D. McNicholas;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=mixture;">
<meta name="citation_reference" content="citation_title=The EM algorithm for mixtures of factor analyzers;,citation_author=Z. Ghahramani;,citation_author=G. E. Hinton;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_technical_report_institution=Department of Computer Science, University of Toronto;">
<meta name="citation_reference" content="citation_title=Modelling high-dimensional data by mixtures of factor analyzers;,citation_author=G. J. McLachlan;,citation_author=D. Peel;,citation_author=R. W. Bean;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=41;,citation_journal_title=Computational Statistics &amp;amp;amp; Data Analysis;">
<meta name="citation_reference" content="citation_title=Parsimonious Gaussian mixture models;,citation_author=P. D. McNicholas;,citation_author=T. B. Murphy;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=18;,citation_journal_title=Statistics and Computing;">
<meta name="citation_reference" content="citation_title=Infinite mixtures of infinite factor analysers;,citation_author=Keefe Murphy;,citation_author=Cinzia Viroli;,citation_author=I. Claire Gormley;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=3;,citation_volume=15;,citation_journal_title=Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=Concomitant-variable latent-class models;,citation_author=C. M. Dayton;,citation_author=G. B. Macready;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=401;,citation_volume=83;,citation_journal_title=Journal of the American Statistical Association;">
<meta name="citation_reference" content="citation_title=Gaussian parsimonious clustering models with covariates and a noise component;,citation_author=Keefe Murphy;,citation_author=Thomas Brendan Murphy;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://doi.org/10.1007/s11634-019-00373-8;,citation_issue=2;,citation_doi=10.1007/s11634-019-00373-8;,citation_volume=14;,citation_journal_title=Advances in Data Analysis and Classification;">
<meta name="citation_reference" content="citation_title=Behavioural science is unlikely to change the world without a heterogeneity revolution;,citation_author=Christopher J. Bryan;,citation_author=Elizabeth Tipton;,citation_author=David S. Yeager;,citation_publication_date=2021-07;,citation_cover_date=2021-07;,citation_year=2021;,citation_fulltext_html_url=https://doi.org/10.1038/s41562-021-01143-3;,citation_issue=8;,citation_doi=10.1038/s41562-021-01143-3;,citation_volume=5;,citation_journal_title=Nature Human Behaviour;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Modelling within-person idiographic variance could help explain and individualize learning;,citation_author=Mohammed Saqr;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_journal_title=British Journal of Educational Technology;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=A broad collection of datasets for educational research training and application;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_author=Javier Conde;,citation_author=Laura Del-Río-Carazo;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using R;">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">An Introduction and R Tutorial to Model-based Clustering in Education via Latent Profile Analysis</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Learning analytics methods and tutorials</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/lamethods/labook-code/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contributors.html" class="sidebar-item-text sidebar-link">Contributors</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../foreword_dg.html" class="sidebar-item-text sidebar-link">Foreword by Dragan Gašević</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../foreword_rb.html" class="sidebar-item-text sidebar-link">Foreword by Ryan Baker</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch01-intro/intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Getting started</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch02-data/ch2-data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch03-intro-r/ch3-intor.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Intro to R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch04-data-cleaning/ch4-datacleaning.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data cleaning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch05-basic-stats/ch5-stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Basic statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch06-data-visualization/ch6-viz.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data visualization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Machine Learning</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch07-prediction/ch7-pred.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Predictive modeling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch08-clustering/ch8-clus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Dissimilarity-based Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch09-model-based-clustering/ch9-model.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Model-based clustering</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Temporal methods</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch10-sequence-analysis/ch10-seq.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequence analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch11-vasstra/ch11-vasstra.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">VaSSTra</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch12-markov/ch12-markov.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Markov models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch13-multichannel/ch13-multi.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multi-channel sequences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch14-process-mining/ch14-process.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Process mining</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Network analysis</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch15-sna/ch15-sna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Social Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch16-community/ch16-comm.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Community detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch17-temporal-networks/ch17-tna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Temporal Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch18-ena-ona/ch18-ena.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Epistemic Network Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Psychometrics</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch19-psychological-networks/ch19-psych.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Psychological networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch20-factor-analysis/ch20-factor.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Factor analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch21-sem/ch21-sem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Structured Equation Modeling</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch22-conclusion/ch22-conclusion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Future of LA</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">1</span>  Introduction</a></li>
  <li><a href="#literature-review" id="toc-literature-review" class="nav-link" data-scroll-target="#literature-review"><span class="toc-section-number">2</span>  Literature review</a>
  <ul class="collapse">
  <li><a href="#sec-LPA" id="toc-sec-LPA" class="nav-link" data-scroll-target="#sec-LPA"><span class="toc-section-number">2.1</span>  Latent variable models</a></li>
  <li><a href="#finite-gaussian-mixture-models" id="toc-finite-gaussian-mixture-models" class="nav-link" data-scroll-target="#finite-gaussian-mixture-models"><span class="toc-section-number">2.2</span>  Finite Gaussian mixture models</a></li>
  </ul></li>
  <li><a href="#gaussian-parsimonious-clustering-models" id="toc-gaussian-parsimonious-clustering-models" class="nav-link" data-scroll-target="#gaussian-parsimonious-clustering-models"><span class="toc-section-number">3</span>  Gaussian parsimonious clustering models</a>
  <ul class="collapse">
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection"><span class="toc-section-number">3.1</span>  Model selection</a></li>
  <li><a href="#mclust-r-package" id="toc-mclust-r-package" class="nav-link" data-scroll-target="#mclust-r-package"><span class="toc-section-number">3.2</span>  mclust R package</a></li>
  <li><a href="#other-practical-issues-and-extensions" id="toc-other-practical-issues-and-extensions" class="nav-link" data-scroll-target="#other-practical-issues-and-extensions"><span class="toc-section-number">3.3</span>  Other practical issues and extensions</a></li>
  </ul></li>
  <li><a href="#application-school-engagement-academic-achievement-and-self-regulated-learning" id="toc-application-school-engagement-academic-achievement-and-self-regulated-learning" class="nav-link" data-scroll-target="#application-school-engagement-academic-achievement-and-self-regulated-learning"><span class="toc-section-number">4</span>  Application: School engagement, academic achievement, and self-regulated learning</a>
  <ul class="collapse">
  <li><a href="#preparing-the-data" id="toc-preparing-the-data" class="nav-link" data-scroll-target="#preparing-the-data"><span class="toc-section-number">4.1</span>  Preparing the data</a></li>
  <li><a href="#model-estimation-and-model-selection" id="toc-model-estimation-and-model-selection" class="nav-link" data-scroll-target="#model-estimation-and-model-selection"><span class="toc-section-number">4.2</span>  Model estimation and model selection</a></li>
  <li><a href="#examining-model-output" id="toc-examining-model-output" class="nav-link" data-scroll-target="#examining-model-output"><span class="toc-section-number">4.3</span>  Examining model output</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="toc-section-number">5</span>  Discussion</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
</nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<p><a href="https://github.com/lamethods/code" target="_blank"> <button class="btn btn-outline-dark"> <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 496 512" style="width: 22px;vertical-align: text-top;margin-right: 9px;"> <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" style="width: 24px;"> </path> </svg>Download code </button> </a> <br> <br> <small>© 2023 The authors</small></p>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">An Introduction and R Tutorial to Model-based Clustering in Education via Latent Profile Analysis</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Luca Scrucca </p>
             <p>Mohammed Saqr </p>
             <p>Sonsoles López-Pernas </p>
             <p>Keefe Murphy </p>
          </div>
  </div>
    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    Heterogeneity has been a hot topic in recent educational literature. Several calls have been voiced to adopt methods that capture different patterns or subgroups within students’ behavior or functioning. Assuming that there is “an average” pattern that represents the entirety of student populations requires the measured construct to have the same causal mechanism, same development pattern, and affect students in exactly the same way. Using a person-centered method (finite Gaussian mixture model or latent profile analysis), the present tutorial shows how to uncover the heterogeneity within engagement data by identifying three latent or unobserved clusters. This chapter offers an introduction to the model-based clustering that includes the principles of the methods, a guide to choice of number of clusters, evaluation of clustering results and a detailed guide with code and a real-life dataset. The discussion elaborates on the interpretation of the results, the advantages of model-based clustering as well as how it compares with other methods.
  </div>
</div>

</header>

<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Education research is commonly performed with variable-centered methods (e.g., correlation, regression, comparison of means e.g., t-test) using a sample from the population to devise or compare central tendency measures or an “average” (i.e., mean or median). The average is assumed to represent the population under study and therefore could be generalised to the population at large <span class="citation" data-cites="Howard2018-iv Hickendorff2018-kt">[<a href="#ref-Howard2018-iv" role="doc-biblioref">1</a>, <a href="#ref-Hickendorff2018-kt" role="doc-biblioref">2</a>]</span>. Put another way, the statistical findings of variable-centered methods are thought to apply to all learners in the same way. In doing so, variable-centered methods ignore the individual differences that are universal across all domains of human function <span class="citation" data-cites="Saqr2023-if">[<a href="#ref-Saqr2023-if" role="doc-biblioref">3</a>]</span>. Learners are not an exception; students vary in their behavior, attitude, and dispositions, and they rarely —if at all— conform to a common pattern or an average behavior <span class="citation" data-cites="Hickendorff2018-kt Tormanen2022-ux">[<a href="#ref-Hickendorff2018-kt" role="doc-biblioref">2</a>, <a href="#ref-Tormanen2022-ux" role="doc-biblioref">4</a>]</span>. An “average” is thus a poor simplification of learners’ heterogeneity; consequently, methods to capture individual differences have started to gain popularity with the increasing attention to patterns and differences among students. Our focus in this chapter is on such person-centered methods <span class="citation" data-cites="Howard2018-iv Hickendorff2018-kt Saqr2023-if saqr2023modelling">[<a href="#ref-Howard2018-iv" role="doc-biblioref">1</a>–<a href="#ref-Saqr2023-if" role="doc-biblioref">3</a>, <a href="#ref-saqr2023modelling" role="doc-biblioref">5</a>]</span>.</p>
<p>Person-centered methods can be broadly grouped into two categories; i) heuristic, dissimilarity-based clustering algorithms (e.g., agglomerative hierarchical clustering, and partitional clustering algorithms like <span class="math inline">\(k\)</span>-means) on one hand and ii) <em>model-based</em> clustering (MBC) approaches (e.g., finite Gaussian mixture models) on the other. Though we focus here on the MBC paradigm, we note that —contrary to variable-centered methods— person-centered methods are generally concerned with capturing heterogeneity by uncovering the latent (e.g., unobserved or hidden) patterns within data into subgroups of “clusters” or “profiles”, which are assumed to be homogeneous <span class="citation" data-cites="Howard2018-iv Hickendorff2018-kt">[<a href="#ref-Howard2018-iv" role="doc-biblioref">1</a>, <a href="#ref-Hickendorff2018-kt" role="doc-biblioref">2</a>]</span>. Modelling the unobserved patterns within the data could reveal the qualitative differences between learners. For instance, where students may have different patterns of approaching their learning, capturing such patterns would make sense as each different approach may benefit from a certain course design, set of instructional methods, or scaffolding approach <span class="citation" data-cites="Hickendorff2018-kt">[<a href="#ref-Hickendorff2018-kt" role="doc-biblioref">2</a>]</span>. Similarly, dispositions such as engagement, motivation, and achievement are multidimensional and vary across students; capturing such differences requires a method that could handle such nonlinear multidimensional dispositions and identify the different patterns.</p>
<p>This chapter deals with one of the person-centered methods; namely, latent profile analysis (from the perspective of model-based clustering via finite Gaussian mixture models). To clarify, we note that the terms finite mixture models and latent profile analysis can be used interchangeably, with the former being more common in the statistical literature and the latter being more common in the education literature and social sciences literature more broadly. The equivalence of both terminologies is further elaborated in <a href="#sec-LPA"><span>Section&nbsp;9.2.1</span></a>. In any case, this framework represents a <em>probabilistic</em> approach to statistical unsupervised learning that aims at discovering clusters of observations in a data set <span class="citation" data-cites="Fraley:Raftery:2002">[<a href="#ref-Fraley:Raftery:2002" role="doc-biblioref">6</a>]</span>. In other words, the MBC paradigm is referred to as model-based by virtue of being based on a generative probabilistic model, unlike heuristic clustering algorithms based on dissimilarity criteria.</p>
<p>We also offer a walkthrough tutorial for the analysis of a data set on school engagement, academic achievement, and self-regulated learning using the popular <code>mclust</code> package <span class="citation" data-cites="Rpkg:mclust">[<a href="#ref-Rpkg:mclust" role="doc-biblioref">7</a>]</span> for R <span class="citation" data-cites="Rstat">[<a href="#ref-Rstat" role="doc-biblioref">8</a>]</span> which implements the approach. Whereas mixture models and <code>mclust</code> have received growing attention within social science, they have not garnered widespread utilisation in the field of educational research and their adoption in learning analytics research has been relatively slow.</p>
</section>
<section id="literature-review" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="literature-review"><span class="header-section-number">2</span> Literature review</h2>
<p>Examples of mixture models being applied in educational research settings are relatively few compared to other methods of clustering. Some notable examples exist which address patterns in students’ online learning <span class="citation" data-cites="Saqr2021">[<a href="#ref-Saqr2021" role="doc-biblioref">9</a>]</span> or patterns in students’ disposition <span class="citation" data-cites="Yu2022-fr">[<a href="#ref-Yu2022-fr" role="doc-biblioref">10</a>]</span> or collaborative roles <span class="citation" data-cites="Saqr2022-fp">[<a href="#ref-Saqr2022-fp" role="doc-biblioref">11</a>]</span>. Most studies in education research that applied mixture models used latent profile analysis (LPA) to identify students’ profiles from self-reported data. For example, <span class="citation" data-cites="Yu2022-fr">[<a href="#ref-Yu2022-fr" role="doc-biblioref">10</a>]</span> performed LPA on a data set of 318 students’ survey responses about emotional self-efficacy, motivation, self-regulation, and academic performance, and identified four profiles: “low”, “average”, “above average with a low ability to handle the emotions of others”, and “high emotional self-efficacy”. In the work by <span class="citation" data-cites="Cheng2023-fc">[<a href="#ref-Cheng2023-fc" role="doc-biblioref">12</a>]</span>, the authors analyzed 615 vocational education students’ achievement emotions in online learning environments, and found three profiles: “blends of negative emotions”, “nonemotional”, and “pure positive emotion”. <span class="citation" data-cites="Hoi2023-sz">[<a href="#ref-Hoi2023-sz" role="doc-biblioref">13</a>]</span> employed LPA on self-report data on classroom engagement from 413 first-year university students in Vietnam and found three profiles: “highly engaged”, “moderately engaged”, and “minimally engaged”. <span class="citation" data-cites="Scheidt2021-sg">[<a href="#ref-Scheidt2021-sg" role="doc-biblioref">14</a>]</span> collected survey responses from 2,339 engineering undergraduates about 28 noncognitive and affective factors using a survey instrument and using Gaussian mixture models found four very distinct profiles of students.</p>
<p>The analysis of online trace log data —which is at the core of learning analytics data— with mixture models is even less common. In the study by <span class="citation" data-cites="Zhang2023-zt">[<a href="#ref-Zhang2023-zt" role="doc-biblioref">15</a>]</span>, the authors applied LPA to variables related to debugging derived from students’ programming problems submission traces. They found a profile with higher debugging accuracy and coding speed, another profile with lower debugging performance in runtime and logic errors, and a third profile with lower performance in syntactic errors who tended to make big changes in every submission. Studies covering online collaborative learning are even more scarce. A rare example is the study by <span class="citation" data-cites="Saqr2022-fp">[<a href="#ref-Saqr2022-fp" role="doc-biblioref">11</a>]</span>, in which the authors used latent profile analysis to identify students’ roles in collaboration based on their centrality measures. The mixture models identified three collaborative roles that represented a distinct pattern of collaboration: leaders, who contribute the most to the discussion, whose arguments are more likely to spread; mediators, who bridge others and moderate the discussions; as well as isolates, who are socially idle and do not contribute to the discussion.</p>
<p>A considerable number of studies that applied mixture models further investigate the association between profile membership and academic achievement. For example, in the aforementioned study by <span class="citation" data-cites="Yu2022-fr">[<a href="#ref-Yu2022-fr" role="doc-biblioref">10</a>]</span>, students with high emotional self-efficacy had higher academic performance than the other profiles. In the study by <span class="citation" data-cites="Zhang2023-zt">[<a href="#ref-Zhang2023-zt" role="doc-biblioref">15</a>]</span>, the authors found that higher debugging accuracy was related to higher scores in all exams, whereas there were no differences between the two other identified profiles. By the same token, researchers have attempted to find reasons why a certain profile emerged, or what are the variables that are more associated with one profile more than the other. For example, <span class="citation" data-cites="Hoi2023-sz">[<a href="#ref-Hoi2023-sz" role="doc-biblioref">13</a>]</span> found that peer support, provision of choice, and task relevance are the factors more likely to predict classroom engagement profile membership. <span class="citation" data-cites="Yu2022-fr">[<a href="#ref-Yu2022-fr" role="doc-biblioref">10</a>]</span> found that self-regulation and motivation played significant roles in determining profile membership.</p>
<p>Clearly, there are plenty of opportunities for further exploration and investigation in this area that could augment our knowledge of learning, learners’ behavior, and the variabilities of learning processes <span class="citation" data-cites="Hickendorff2018-kt">[<a href="#ref-Hickendorff2018-kt" role="doc-biblioref">2</a>]</span>. This is especially true given the numerous advantages of the MBC paradigm over more traditional, heuristic clustering algorithms, which we imminently describe. Subsequently, in the rest of this chapter we elaborate on the theoretical underpinnings of the family of Gaussian parsimonious clustering models implemented in the <code>mclust</code> R package and additionally explore some advanced features of the package, which we employ in an analysis of a real educational research application thereafter. Finally, we conclude with a brief discussion.</p>
<p>##Model-based clustering As stated above, clustering methods, in a general sense, are used to uncover group structure in heterogeneous populations and identify patterns in a data set which may represent distinct subpopulations. While there is no universally applicable definition of what constitutes a cluster <span class="citation" data-cites="Hennig2015">[<a href="#ref-Hennig2015" role="doc-biblioref">16</a>]</span>, it is commonly assumed that clusters should be well separated from each other and cohesive in an ideal analysis <span class="citation" data-cites="Everitt2011">[<a href="#ref-Everitt2011" role="doc-biblioref">17</a>]</span>. Conversely, objects within a cluster should be more similar to each other in some sense, in such a way that an observation has a defined relationship with observations in the same cluster, but not with observations from other clusters.</p>
<p>Traditional clustering approaches, like the aforementioned <span class="math inline">\(k\)</span>-means algorithm, and agglomerative hierarchical clustering, use dissimilarity-based heuristics to ultimately produce a “hard” partition of cases into groups, such that each observation is associated with exactly one cluster only. As such approaches are not underpinned by a statistical model, assessment of the optimal number of clusters is often a fraught task, lacking the guidance of principled statistical model selection criteria. However, we note that <span class="math inline">\(k\)</span>-means can be recasted as a clustering model assuming a Gaussian mixture with equal proportions and diagonal equal covariance matrix across groups. Moreover, some (but not all) agglomerative hierarchical clustering models can be rooted in a statistical model also, as discussed in <span class="citation" data-cites="Fraley:1998">[<a href="#ref-Fraley:1998" role="doc-biblioref">18</a>]</span>.</p>
<p>Conversely, the MBC paradigm typically assumes that data arise from a (usually finite) mixture of probability distributions, whereby each observation is assumed to be generated from a specific cluster, characterised by an associated distribution in the mixture <span class="citation" data-cites="McLachlan:Peel:2000">[<a href="#ref-McLachlan:Peel:2000" role="doc-biblioref">19</a>]</span>. Ideally, mixtures of distributions are supposed to provide a good model for the heterogeneity in a data set; that is, once an observation has been assigned to a cluster, it is assumed to be well-represented by the associated distribution. As such, MBC methods are based on a formal likelihood and seek to estimate parameters (e.g., means, variances, and covariances, which may or may not differ across groups) which best characterise the different distributions. Rather than yielding only a “hard” partition, each observation is assigned a probability of being associated with each mixture component —such that observations can have non-negative association with more than one cluster— from which a hard partition can be constructed. These probabilities are treated as weights when estimating the component parameters, which brings the advantages of minimising the effect of observations lying near the boundary of two natural clusters (e.g., a student with an ambiguous learning profile) and being able to quantity the uncertainty in the cluster assignment of a particular observation to provide a sense of cases for which further investigation may be warranted. Compared to other approaches, the other main advantages of this statistical modelling framework are its ability to use statistical model selection criteria and inferential procedures for evaluating and assessing the results obtained.</p>
<p>Inference for finite mixture models is routinely achieved by means of the expectation-maximisation (EM) algorithm <span class="citation" data-cites="Dempster:Laird:Rubin:1977">[<a href="#ref-Dempster:Laird:Rubin:1977" role="doc-biblioref">20</a>]</span>, under which each observation’s component membership is treated as a “missing” latent variable which must be estimated. This formulation assumes that the data are <em>conditionally</em> independent and identically distributed, where the conditioning is with respect to a latent variable representation of the data in which the latent variable indicates cluster membership. Given the relative familiarity of latent class and latent profile terminology in the social sciences, we now explicitly cast MBC methods in the framework of latent variable modelling.</p>
<section id="sec-LPA" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sec-LPA"><span class="header-section-number">2.1</span> Latent variable models</h3>
<p>Latent variable models are statistical models that aim to explain the relationships between observed variables by introducing one or more unobserved or latent variables. The idea behind latent variable models is that some of the underlying constructs or concepts we are interested in cannot be measured directly, but only through their effects on observable variables. Latent variable modelling has a relatively long history, dating back from the measure of general intelligence by factor analysis <span class="citation" data-cites="Spearman:1904">[<a href="#ref-Spearman:1904" role="doc-biblioref">21</a>]</span>, to the structural equation modelling approach <span class="citation" data-cites="Joreskog:1970">[<a href="#ref-Joreskog:1970" role="doc-biblioref">22</a>]</span>, from topic modelling, such as the latent Dirichlet allocation algorithm <span class="citation" data-cites="Blei:Ng:Jordan:2003">[<a href="#ref-Blei:Ng:Jordan:2003" role="doc-biblioref">23</a>]</span>, to hidden Markov models for time series <span class="citation" data-cites="Zucchini:MacDonald:Langrock:2016">[<a href="#ref-Zucchini:MacDonald:Langrock:2016" role="doc-biblioref">24</a>]</span> and longitudinal data <span class="citation" data-cites="Bartolucci:Farcomeni:Pennoni:2012">[<a href="#ref-Bartolucci:Farcomeni:Pennoni:2012" role="doc-biblioref">25</a>]</span>. Latent variable models are widely used in various fields, including psychology, sociology, economics, and biology, to name a few. They are particularly useful when dealing with complex phenomena that cannot be easily measured or when trying to understand the underlying mechanisms that drive the observed data.</p>
<p>When discussing latent variable modelling, it is useful to consider the <em>taxonomy</em> presented by <span class="citation" data-cites="Bartholomew:Knott:Moustaki:2011">[<a href="#ref-Bartholomew:Knott:Moustaki:2011" role="doc-biblioref">26</a>]</span>. This can be particularly helpful, as the same models are sometimes referred to by different names in different scientific disciplines. <span class="citation" data-cites="Bartholomew:Knott:Moustaki:2011">[<a href="#ref-Bartholomew:Knott:Moustaki:2011" role="doc-biblioref">26</a>, Table 1.3]</span> considered a cross-classification of latent variable methods based on the type of variable (manifest or latent) and its nature (metrical or categorical). If both the manifest and latent variables are metrical, the model is called a <strong>factor analysis model</strong>. If the manifest variables are categorical and the latent variables are metrical, the model is called a <strong>latent trait model</strong> or <strong>item response theory model</strong>. If the manifest variables are metrical and the latent variables are categorical, the model is called a <strong>latent profile analysis model</strong>. If both the manifest and latent variables are categorical, the model is called a <strong>latent class model</strong>.</p>
<p>In this scheme, finite Gaussian mixture models described in this chapter assume that the observed variables are continuous and normally distributed, while the latent variable, which represents the cluster membership of each observation, is categorical. Therefore, Gaussian mixtures belong to the family of latent profile analysis models. This connection is made apparent by the <code>tidyLPA</code> R package <span class="citation" data-cites="Rosenberg:Beymer:Anderson:VanLissa:Schmidt:2018">[<a href="#ref-Rosenberg:Beymer:Anderson:VanLissa:Schmidt:2018" role="doc-biblioref">27</a>]</span>, which leverages this equivalence to provide an interface to the well-known <code>mclust</code> R package <span class="citation" data-cites="Rpkg:mclust">[<a href="#ref-Rpkg:mclust" role="doc-biblioref">7</a>]</span> used throughout this chapter, using tidyverse syntax and terminology which is more familiar in the LPA literature.</p>
</section>
<section id="finite-gaussian-mixture-models" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="finite-gaussian-mixture-models"><span class="header-section-number">2.2</span> Finite Gaussian mixture models</h3>
<p>As described above, finite mixture models (FMMs) provide the statistical framework for model-based clustering and allow for the modelling of complex data by combining simpler distributions. Specifically, a FMM assumes that the observed data are generated from a finite mixture of underlying distributions, each of which corresponds to a distinct subgroup or cluster within the data. Gaussian mixture models (GMMs) are a particularly widespread variant of FMMs which specifically assume that each of the underlying distributions is a (multivariate) Gaussian distribution. This means that the data within each cluster are normally distributed, but with potentially different means and covariance matrices. The relevance of GMMs stems from the well-established fact that mixtures of Gaussians can provide an accurate approximation to any continuous density.</p>
<p>In FMMs, the latent variable represents the cluster assignment for each observation in the data. It is a categorical variable assuming one of a finite set of possible values that correspond to different clusters. Alternatively, it can be encoded using a set of indicator variables, which take the value of 1 for the cluster to which the observation belongs, and 0 for all other clusters.</p>
<p>To estimate the parameters of a GMM with the associated latent variable for cluster membership, a likelihood-based approach is typically used. The likelihood function expresses the probability of observing the data, given the parameter values and the latent variable. The maximum likelihood estimation (MLE) method is commonly used to estimate the parameters and the latent variable which maximise the likelihood function. Usually, the number of clusters in a GMM is also unknown, and it is determined through a process known as model selection, which involves comparing models with different numbers of clusters and parameterisations and selecting the one which best fits the data.</p>
<p>In summary, model-based clustering from the perspective of latent variable modelling assumes that the data is generated from a probabilistic model with a specific number of clusters. A likelihood-based approach can be used to estimate the parameters of the model and the latent variable that represents the cluster assignment for each observation in the data, and guide the selection of the number of clusters. A GMM is a common framework for model-based clustering which assumes the data in each cluster is generated from a Gaussian distribution.</p>
</section>
</section>
<section id="gaussian-parsimonious-clustering-models" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="gaussian-parsimonious-clustering-models"><span class="header-section-number">3</span> Gaussian parsimonious clustering models</h2>
<p>For a continuous feature vector <span class="math inline">\(\boldsymbol{x}\in \mathbb{R}^{d}\)</span>, the general form of the density function of a Gaussian mixture model (GMM) with <span class="math inline">\(K\)</span> components can be written as <span id="eq-gmm"><span class="math display">\[
f(\boldsymbol{x}) = \sum_{k=1}^K \pi_k \phi_d(\boldsymbol{x};\boldsymbol{\mu}_k,\boldsymbol{\Sigma}_k),
\tag{1}\]</span></span> where <span class="math inline">\(\pi_k\)</span> represents the mixing probabilities, i.e., the marginal probability of belonging to the <span class="math inline">\(k\)</span>-th cluster, such that <span class="math inline">\(\pi_k &gt; 0\)</span> and <span class="math inline">\(\sum_{k=1}^K\pi_k=1\)</span>, and <span class="math inline">\(\phi_d(\cdot)\)</span> is the <span class="math inline">\(d\)</span>-dimensional multivariate Gaussian density with parameters <span class="math inline">\((\boldsymbol{\mu}_k,\boldsymbol{\Sigma}_k)\)</span> for <span class="math inline">\(k=1,\ldots,K\)</span>. Clusters described by such a GMM are ellipsoidal, centered at the means <span class="math inline">\(\boldsymbol{\mu}_k\)</span>, and with other geometric characteristics (namely volume, shape, and orientation) determined by the covariance matrices <span class="math inline">\(\boldsymbol{\Sigma}_1, \ldots, \boldsymbol{\Sigma}_K\)</span>. Parsimonious parameterisations of covariance matrices can be controlled by imposing some constraints on the covariance matrices through the following eigen-decomposition <span class="citation" data-cites="Banfield:Raftery:1993 Celeux:Govaert:1995">[<a href="#ref-Banfield:Raftery:1993" role="doc-biblioref">28</a>, <a href="#ref-Celeux:Govaert:1995" role="doc-biblioref">29</a>]</span>: <span id="eq-eigendecomp"><span class="math display">\[
\boldsymbol{\Sigma}_k = \lambda_k \boldsymbol{U}_k \boldsymbol{\Delta}_k \boldsymbol{U}{}^{\!\top}_k,
\tag{2}\]</span></span> where <span class="math inline">\(\lambda_k = \lvert\boldsymbol{\Sigma}_k\rvert^{1/d}\)</span> is a scalar which controls the <em>volume</em>, <span class="math inline">\(\boldsymbol{\Delta}_k\)</span> is a diagonal matrix whose entries are the normalised eigenvalues of <span class="math inline">\(\boldsymbol{\Sigma}_k\)</span> in decreasing order, such that <span class="math inline">\(\lvert\boldsymbol{\Delta}_k\rvert = 1\)</span>, which controls the <em>shape</em> of the density contours, and <span class="math inline">\(\boldsymbol{U}_k\)</span> is an orthogonal matrix whose columns are the eigenvectors of <span class="math inline">\(\boldsymbol{\Sigma}_k\)</span>, which controls the <em>orientation</em> of the corresponding ellipsoid. The size of a cluster is distinct from its volume and is proportional to <span class="math inline">\(\pi_k\)</span> <span class="citation" data-cites="Celeux:Govaert:1995">[<a href="#ref-Celeux:Govaert:1995" role="doc-biblioref">29</a>]</span>.</p>
<p>GMMs with unconstrained covariance matrices are quite flexible, but require the estimation of several parameters. To obtain a balance between model complexity and accuracy of parameter estimates, a parsimonious model parameterisation can be adopted. Constraining the geometric characteristics of cluster covariances to be equal across clusters can greatly reduce the number of estimable parameters, and is the means by which GMMs obtain intermediate covariance matrices between homoscedasticity and heteroscedasticity. A list of the 14 resulting parameterisations available in the <code>mclust</code> package <span class="citation" data-cites="Rpkg:mclust">[<a href="#ref-Rpkg:mclust" role="doc-biblioref">7</a>]</span> for R <span class="citation" data-cites="Rstat">[<a href="#ref-Rstat" role="doc-biblioref">8</a>]</span> is included in Table 2.1 of <span class="citation" data-cites="mclust:book:2023">[<a href="#ref-mclust:book:2023" role="doc-biblioref">30</a>]</span>. Of particular note is the nomenclature adopted by <code>mclust</code> whereby each model has a three-letter name with each letter pertaining to the volume, shape, and orientation, respectively, denoting whether the given component is equal (<code>E</code>) or free to vary (<code>V</code>) across clusters. Some model names also use the letter <code>I</code> in the third position to indicate that the covariance matrices are diagonal and two particularly parsimonious models have the letter <code>I</code> in the second position to indicate that the covariance matrices are isotropic. Thus, as examples, the fully unconstrained <code>VVV</code> model is one for which the volume, shape, and orientation are all free to vary across clusters, the <code>EVE</code> model constrains the clusters to have equal volume and orientation but varying shape, and the <code>VII</code> model assumes isotropic covariance matrices with cluster-specific volumes. The flexibility to model clusters with different geometric characteristics by modelling correlations according to various parameterisations represents another advantage over heuristic clustering algorithms. Taking the <span class="math inline">\(k\)</span>-means algorithm as an example, a larger number of circular, Euclidean distance-based clusters may be required to fit the data well, rather than a more parsimonious and easily interpretable mixture model with fewer non-spherical components.</p>
<p>Given a random sample of observations <span class="math inline">\(\{ \boldsymbol{x}_1, \boldsymbol{x}_2, \ldots, \boldsymbol{x}_n \}\)</span> in <span class="math inline">\(d\)</span> dimensions, the log-likelihood of a GMM with <span class="math inline">\(K\)</span> components is given by <span id="eq-loglik"><span class="math display">\[
\ell(\boldsymbol{\theta}) = \sum_{i=1}^n \log\left\{ \sum_{k=1}^K \pi_k \phi_d(\boldsymbol{x}_i ; \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k) \right\},
\tag{3}\]</span></span> where <span class="math inline">\(\boldsymbol{\theta}= (\pi_1, \ldots, \pi_{K-1}, \boldsymbol{\mu}_1, \ldots, \boldsymbol{\mu}_K, \boldsymbol{\Sigma}_1, \ldots, \boldsymbol{\Sigma}_K)\)</span> denotes the collection of parameters to be estimated.</p>
<p>Maximizing the log-likelihood function in <a href="#eq-loglik">Equation&nbsp;<span>9.3</span></a> directly is often complicated, so maximum likelihood estimation (MLE) of <span class="math inline">\(\boldsymbol{\theta}\)</span> is usually performed using the EM algorithm <span class="citation" data-cites="Dempster:Laird:Rubin:1977">[<a href="#ref-Dempster:Laird:Rubin:1977" role="doc-biblioref">20</a>]</span> by including the component membership as a latent variable. The EM algorithm consists of two steps: the E-step (Expectation step) and the M-step (Maximisation step). In the E-step, the algorithm calculates the expected membership probabilities of each data point to each of the mixture components based on the current estimates of the model parameters. Thus, though the latent variable indicating cluster membership is assumed to be categorical and represented by indicator variables taking the values <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>, the model estimates assignment probabilities in the range <span class="math inline">\([0,1]\)</span> at this step. In the M-step, the algorithm updates the model parameters by maximizing the likelihood of the observed data given the estimated membership probabilities. These two steps are repeated until convergence or a maximum number of iterations is reached. Details on the use of EM algorithm in finite mixture modelling is provided by <span class="citation" data-cites="McLachlan:Peel:2000">[<a href="#ref-McLachlan:Peel:2000" role="doc-biblioref">19</a>]</span>, while a thorough treatment and further extensions can be found in <span class="citation" data-cites="McLachlan:Krishnan:2008">[<a href="#ref-McLachlan:Krishnan:2008" role="doc-biblioref">31</a>]</span>. For the GMM case, see Sec. 2.2 of <span class="citation" data-cites="mclust:book:2023">[<a href="#ref-mclust:book:2023" role="doc-biblioref">30</a>]</span>.</p>
<p>Following the fitting of a GMM and the determination of the MLEs of parameters, the maximum a posteriori (MAP) procedure can be used to assign the observations into the most likely cluster and recover a “hard” partition. For an observation <span class="math inline">\(\boldsymbol{x}_i\)</span> the posterior conditional probability of coming from the mixture component <span class="math inline">\(k\)</span> is given by <span id="eq-postcondprob"><span class="math display">\[
\widehat{p}_{ik} = \frac{\widehat{\pi}_k \phi_d(\boldsymbol{x}_i; \widehat{\boldsymbol{\mu}}_k, \widehat{\boldsymbol{\Sigma}}_k)}{\displaystyle\sum_{g=1}^K \widehat{\pi}_g \phi_d(\boldsymbol{x}; \widehat{\boldsymbol{\mu}}_g, \widehat{\boldsymbol{\Sigma}}_g)}.
\tag{4}\]</span></span> Then, an observation is assigned to the cluster with the largest posterior conditional probability, i.e., <span class="math inline">\(\boldsymbol{x}_i \in \mathcal{C}_{k^\star}\)</span> with <span class="math inline">\(k^\star = \mathop{\mathrm{arg\,max}}_k \widehat{p}_{ik}\)</span>.</p>
<section id="model-selection" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="model-selection"><span class="header-section-number">3.1</span> Model selection</h3>
<p>Given that a wide variety of GMMs in <a href="#eq-gmm">Equation&nbsp;<span>9.1</span></a> can be estimated by varying the number of mixture components and the covariance decompositions in <a href="#eq-eigendecomp">Equation&nbsp;<span>9.2</span></a>, selecting the appropriate model represents a crucial decision. A popular option consists in choosing the “best” model using the Bayesian information criterion <span class="citation" data-cites="Schwarz:1978">[BIC, <a href="#ref-Schwarz:1978" role="doc-biblioref">32</a>]</span>, which, for a given model <span class="math inline">\(\mathcal{M}\)</span>, is defined as <span class="math display">\[
\text{BIC}_{\mathcal{M}} = 2\ell_{\mathcal{M}}(\widehat{\boldsymbol{\theta}}) - \nu_{\mathcal{M}} \log(n),
\]</span> where <span class="math inline">\(\ell_{\mathcal{M}}(\widehat{\boldsymbol{\theta}})\)</span> stands for the maximised log-likelihood of the data sample of size <span class="math inline">\(n\)</span> under model <span class="math inline">\(\mathcal{M}\)</span>, and <span class="math inline">\(\nu_{\mathcal{M}}\)</span> for the number of independent parameters to be estimated. Another option available in clustering is the Integrated Complete Likelihood <span class="citation" data-cites="Biernacki:Celeux:Govaert:2000">[ICL, <a href="#ref-Biernacki:Celeux:Govaert:2000" role="doc-biblioref">33</a>]</span> criterion given by <span class="math display">\[
\text{ICL}_{\mathcal{M}} = \text{BIC}_{\mathcal{M}} + 2 \sum_{i=1}^n\sum_{k=1}^K c_{ik} \log(\widehat{p}_{ik}),
\]</span> where <span class="math inline">\(\widehat{p}_{ik}\)</span> is the conditional probability that <span class="math inline">\(\boldsymbol{x}_i\)</span> arises from the <span class="math inline">\(k\)</span>-th mixture component from <a href="#eq-postcondprob">Equation&nbsp;<span>9.4</span></a>, and <span class="math inline">\(c_{ik} = 1\)</span> if the <span class="math inline">\(i\)</span>-th observation is assigned to cluster <span class="math inline">\(\mathcal{C}_k\)</span> and 0 otherwise.</p>
<p>Both criteria evaluate the fit of a GMM to a given set of data by considering both the likelihood of the data given the model and the complexity of the model itself, represented by the number of parameters to be estimated. Compared to the BIC, the ICL introduces a further entropy-based penalisation for the overlap of the clusters. For this reason, the ICL tends to select models with well-separated clusters.</p>
<p>Whereas there is no consensus of a standard criteria for choosing the best model, there are guidelines that the researcher could rely on. To decide on the optimal model, examining the fit indices (such as the BIC and ICL), model interpretability, and conformance to theory can be of great help. The literature recommends estimating a 1-cluster solution for each model that serves as a comparative baseline and then increasing the number of clusters one by one, evaluating if adding another cluster yields a better solution in both statistical and conceptual terms <span class="citation" data-cites="NylundGibsonChoi2018">[<a href="#ref-NylundGibsonChoi2018" role="doc-biblioref">34</a>]</span>. Among all fit indices, lower BIC values seems to be the preferred method for selecting the best model. However, examining other indices (e.g., AIC, ICL) is also useful. Oftentimes, fit indices do not converge to a certain model. In such cases, the interrelation between the selected models, such as whether one model is an expanded version of another, should also be taken into consideration, as well as the stability of the different models, including the relative sizes of the emergent profiles (each profile should comprise more than 5-8% of the sample) <span class="citation" data-cites="NylundGibsonChoi2018">[<a href="#ref-NylundGibsonChoi2018" role="doc-biblioref">34</a>]</span>. Furthermore, the elbow method could be helpful in cases where no clear number of clusters can be easily determined from the fit indices (e.g., the BIC continues to decrease consistently when increasing the number of clusters). This entails plotting the BIC values and finding an elbow shape where a drop in BIC is less noticeable with increasing numbers of clusters or roughly an elbow followed by a relatively flat line. The choice of the best number of clusters can and probably should be guided by theory; that is, in cases where previous research reported a certain number of clusters or profiles, it is recommended to take this guidance into account. For instance, research on engagement has repeatedly reported three levels of engagement. Once we have chosen the most suitable model, it is suggested to compute model diagnostics (e.g., entropy and average posterior probability) to evaluate the selected model. These diagnostics are covered in <a href="#sec-entropy"><span>Section&nbsp;9.3.3.3</span></a>.</p>
</section>
<section id="mclust-r-package" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="mclust-r-package"><span class="header-section-number">3.2</span> mclust R package</h3>
<p><code>mclust</code> is an R package <span class="citation" data-cites="Rstat">[<a href="#ref-Rstat" role="doc-biblioref">8</a>]</span> for model-based cluster analysis, classification, and density estimation using Gaussian finite mixture models <span class="citation" data-cites="Scrucca:etal:2016 mclust:book:2023">[<a href="#ref-mclust:book:2023" role="doc-biblioref">30</a>, <a href="#ref-Scrucca:etal:2016" role="doc-biblioref">35</a>]</span>. It is widely used in statistics, machine learning, data science, and pattern recognition. One of the key features of <code>mclust</code> is its flexibility in modelling quantitative data with several covariance structures and different numbers of mixture components. Additionally, the package provides extensive graphical representations, model selection criteria, initialisation strategies for the EM algorithm, bootstrap-based inference, and Bayesian regularisation, among other prominent features. <code>mclust</code> also represents a valuable tool in educational settings because it provides a powerful set of models that allows students and researchers to quickly and easily perform clustering and classification analyses on their data. We focus here on the use of <code>mclust</code> as a tool for unsupervised model-based clustering, though the package does also provide functions for supervised model-based classification.</p>
<p>The main function implementing model-based clustering is called <code>Mclust()</code>, which requires a user to provide at least the data set to analyze. In the one-dimensional case, the data set can be a vector, while in the multivariate case, it can be a matrix or a data frame. In the latter case, the rows correspond to observations, and the columns correspond to variables.</p>
<p>The <code>Mclust()</code> function allows for further arguments, including the optional argument <code>G</code> to specify the number of mixture components or clusters, and <code>modelNames</code> to specify the covariance decomposition. If both <code>G</code> and <code>modelNames</code> are not provided, <code>Mclust()</code> will fit all possible models obtained using a number of mixture components from 1 to 9 and all 14 available covariance decompositions, and it will select the model with the largest BIC. Notably, if the data set is univariate, only 2 rather than 14 models governing the scalar variance parameters are returned; that they are equal or unequal across components. Finally, computing the BIC and ICL criteria can be done by invoking the functions <code>mclustBIC()</code> and <code>mclustICL()</code>, respectively.</p>
</section>
<section id="other-practical-issues-and-extensions" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="other-practical-issues-and-extensions"><span class="header-section-number">3.3</span> Other practical issues and extensions</h3>
<p>Prior to commencing the cluster analysis of a data set on school engagement, academic achievement, and self-regulated learning measures, we first provide some theoretical background on some extensions of practical interest which will be explored in the analysis.</p>
<section id="bayesian-regularisation" class="level4" data-number="3.3.1">
<h4 data-number="3.3.1" class="anchored" data-anchor-id="bayesian-regularisation"><span class="header-section-number">3.3.1</span> Bayesian regularisation</h4>
<p>Including a prior distribution over the mixture parameters is an effective way to avoid singularities and degeneracies in maximum likelihood estimation. Furthermore, this can help to prevent overfitting and improve model performance. In situations where the variables of interest are discrete or take on only a few integer values, including a prior distribution can help to regularise the model.</p>
<p><span class="citation" data-cites="Fraley:Raftery:2007a">[<a href="#ref-Fraley:Raftery:2007a" role="doc-biblioref">36</a>]</span> proposed using weekly informative conjugate priors to regularise the estimation process. The EM algorithm can still be used for model fitting, but maximum likelihood estimates (MLEs) are replaced by maximum a posteriori (MAP) estimates. A slightly modified version of BIC can be used for model selection, with the maximised log-likelihood replaced by the log-likelihood evaluated at the MAP or posterior mode.</p>
<p>The prior distributions proposed by <span class="citation" data-cites="Fraley:Raftery:2007a">[<a href="#ref-Fraley:Raftery:2007a" role="doc-biblioref">36</a>]</span> are:</p>
<ul>
<li><p>a uniform prior on the simplex for the mixture weights <span class="math inline">\((\pi_1, \ldots, \pi_K)\)</span>;</p></li>
<li><p>a Gaussian prior on the mean vector (conditional on the covariance matrix), i.e., <span class="math display">\[\begin{align}
\boldsymbol{\mu}\mid \boldsymbol{\Sigma}
&amp; \sim \mathcal{N}(\boldsymbol{\mu}_{\scriptscriptstyle \mathcal{P}}, \boldsymbol{\Sigma}/\kappa_{\scriptscriptstyle \mathcal{P}}) \\
&amp; \propto
\left|\boldsymbol{\Sigma}\right|^{-1/2}
\exp\left\{ -\frac{\kappa_{\scriptscriptstyle \mathcal{P}}}{2}
            \mathop{\mathrm{tr}}\left(\left(\boldsymbol{\mu}- \boldsymbol{\mu}_{\scriptscriptstyle \mathcal{P}}\right){}^{\!\top}
                     \boldsymbol{\Sigma}^{-1}
                     \left(\boldsymbol{\mu}- \boldsymbol{\mu}_{\scriptscriptstyle \mathcal{P}}\right)
                \right)
    \right\},
\label{eqn:multivariatePriorMean}
\end{align}\]</span> with <span class="math inline">\(\boldsymbol{\mu}_{\scriptscriptstyle \mathcal{P}}\)</span> and <span class="math inline">\(\kappa_{\scriptscriptstyle \mathcal{P}}\)</span> being the hyperparameters controlling, respectively, the mean vector and the amount of shrinkage applied;</p></li>
<li><p>an inverse Wishart prior on the covariance matrix, i.e., <span class="math display">\[\begin{align}
\boldsymbol{\Sigma}
&amp; \sim \mathcal{IW}(\nu_{\scriptscriptstyle \mathcal{P}}, \boldsymbol{\Lambda}_{\scriptscriptstyle \mathcal{P}})
\nonumber\\
&amp; \propto
\left|\boldsymbol{\Sigma}\right|^{-(\nu_{\scriptscriptstyle \mathcal{P}}+d+1)/2}
\exp\left\{ -\frac{1}{2}
            \mathop{\mathrm{tr}}\left(\boldsymbol{\Sigma}^{-1} \boldsymbol{\Lambda}_{\scriptscriptstyle \mathcal{P}}^{-1}
               \right)
    \right\},
\label{eqn:multivariatePriorVar}
\end{align}\]</span> with the hyperparameters <span class="math inline">\(\nu_{\scriptscriptstyle \mathcal{P}}\)</span> and the matrix <span class="math inline">\(\boldsymbol{\Lambda}_{\scriptscriptstyle \mathcal{P}}\)</span> controlling the degrees of freedom and scale of the prior distribution, respectively.</p></li>
</ul>
<p>Adding a prior to GMMs estimated using the <code>mclust</code> R package is easily obtained by adding an optional <code>prior</code> argument when calling some of the fitting functions, such as <code>mclustBIC()</code> and <code>Mclust()</code>. Specifically, setting <code>prior = priorControl(functionName = "defaultPrior")</code> allows to adopt the conjugate priors described above with the following default values for the hyperparameters:</p>
<ul>
<li><p>mean vector <span class="math inline">\(\boldsymbol{\mu}_{\scriptscriptstyle \mathcal{P}}= \bar{\boldsymbol{x}}\)</span>, the sample mean of each variable;</p></li>
<li><p>shrinkage <span class="math inline">\(\kappa_{\scriptscriptstyle \mathcal{P}}= 0.1\)</span>;</p></li>
<li><p>degrees of freedom <span class="math inline">\(\nu_{\scriptscriptstyle \mathcal{P}}= d+2\)</span>;</p></li>
<li><p>scale matrix <span class="math inline">\(\boldsymbol{\Lambda}_{\scriptscriptstyle \mathcal{P}}= \boldsymbol{S}/(K^{2/d})\)</span>, where <span class="math inline">\(\boldsymbol{S}\)</span> is the sample covariance matrix.</p></li>
</ul>
<p>Rationale for the above default values for the prior hyperparameters, together with the corresponding MAP estimates of the GMM parameters, can be found in <span class="citation" data-cites="Fraley:Raftery:2007a">[<a href="#ref-Fraley:Raftery:2007a" role="doc-biblioref">36</a>, Table 2]</span>. These values should suffice for most applications, but experienced users who want to tune the hyperparameters can refer to the documentation available in the help pages for <code>priorControl</code> and <code>defaultPrior()</code>. Further details about specifying different hyperparameter values can be found in <span class="citation" data-cites="mclust:book:2023">[<a href="#ref-mclust:book:2023" role="doc-biblioref">30</a>]</span>.</p>
</section>
<section id="bootstrap-inference" class="level4" data-number="3.3.2">
<h4 data-number="3.3.2" class="anchored" data-anchor-id="bootstrap-inference"><span class="header-section-number">3.3.2</span> Bootstrap inference</h4>
<p>Likelihood-based inference in mixture models is complicated because asymptotic theory applied to mixture models require a very large sample size <span class="citation" data-cites="McLachlan:Peel:2000">[<a href="#ref-McLachlan:Peel:2000" role="doc-biblioref">19</a>]</span>, and standard errors derived from the expected or the observed information matrix tend to be unstable <span class="citation" data-cites="Basford:Greenway:McLachlan:Peel:1997">[<a href="#ref-Basford:Greenway:McLachlan:Peel:1997" role="doc-biblioref">37</a>]</span>. For these reasons, resampling approaches based on the bootstrap are often employed <span class="citation" data-cites="OHagan:Murphy:Scrucca:Gormley:2019">[<a href="#ref-OHagan:Murphy:Scrucca:Gormley:2019" role="doc-biblioref">38</a>]</span>.</p>
<p>The <em>bootstrap</em> <span class="citation" data-cites="Efron:1979">[<a href="#ref-Efron:1979" role="doc-biblioref">39</a>]</span> is a general, widely applicable, powerful technique for obtaining an approximation to the sampling distribution of a statistic of interest. The bootstrap distribution is approximated by drawing a large number of samples, called <em>bootstrap samples</em>, from the empirical distribution. This can be obtained by resampling with replacement from the observed data (<em>nonparametric bootstrap</em>), or from a parametric distribution with unknown parameters substituted by the corresponding estimates (<em>parametric bootstrap</em>). A Bayesian version of the bootstrap, introduced by <span class="citation" data-cites="Rubin:1981">[<a href="#ref-Rubin:1981" role="doc-biblioref">40</a>]</span>, allows posterior samples to be obtained by resampling with weights for each observation drawn from a uniform Dirichlet distribution. A strictly related technique is the <em>weighted likelihood bootstrap</em> <span class="citation" data-cites="Newton:Raftery:1994">[<a href="#ref-Newton:Raftery:1994" role="doc-biblioref">41</a>]</span>, where a statistical model is repeatedly fitted using weighted maximum likelihood with weights obtained as in Bayesian bootstrap.</p>
<p>Let <span class="math inline">\(\widehat{\boldsymbol{\theta}}\)</span> be the estimate of a set of GMM parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> for a given model <span class="math inline">\(\mathcal{M}\)</span>, determined by the adopted covariance parameterisation and number of mixture components. The bootstrap distribution for the parameters of interest is obtained as follows:</p>
<ul>
<li><p>draw a bootstrap sample of size <span class="math inline">\(n\)</span> using one of the resampling techniques described above to form the bootstrap sample <span class="math inline">\((\boldsymbol{x}^\star_1, \ldots, \boldsymbol{x}^\star_n)\)</span>;</p></li>
<li><p>fit a the GMM <span class="math inline">\(\mathcal{M}\)</span> to get the bootstrap estimates <span class="math inline">\(\widehat{\boldsymbol{\theta}}^\star\)</span>;</p></li>
<li><p>replicate the previous steps a large number of times, say <span class="math inline">\(B\)</span>.</p></li>
</ul>
<p>The bootstrap distribution for the parameters of interest, <span class="math inline">\(\widehat{\boldsymbol{\theta}}^\star_1, \widehat{\boldsymbol{\theta}}^\star_2, \ldots, \widehat{\boldsymbol{\theta}}^\star_B\)</span>, can then be used for computing the bootstrap standard errors (as the square root of the diagonal elements of the bootstrap covariance matrix) or the bootstrap percentile confidence intervals. More details can be found in <span class="citation" data-cites="mclust:book:2023">[<a href="#ref-mclust:book:2023" role="doc-biblioref">30</a>]</span>.</p>
<p>From a practical point of view, bootstrap resampling can be conducted in <code>mclust</code> by means of the function <code>MclustBootstrap()</code>. This function takes as arguments the fitted model object returned from e.g., <code>Mclust()</code> or <code>mclustBIC()</code>, the optional argument <code>type</code>, which allows to specify the type of bootstrap samples to draw (<code>"bs"</code> for nonparametric bootstrap, <code>"pb"</code> for parametric bootstrap, and <code>"wlbs"</code> for weighted likelihood bootstrap), and the optional argument <code>nboot</code>, which sets the number of bootstrap samples. At least <span class="math inline">\(999\)</span> samples should be drawn if confidence intervals are needed.</p>
</section>
<section id="sec-entropy" class="level4" data-number="3.3.3">
<h4 data-number="3.3.3" class="anchored" data-anchor-id="sec-entropy"><span class="header-section-number">3.3.3</span> Entropy and average posterior probabilities</h4>
<p>The definition of entropy in information theory <span class="citation" data-cites="Cover:Thomas:2006">[<a href="#ref-Cover:Thomas:2006" role="doc-biblioref">42</a>]</span> refers to the average amount of information provided by a random variable. Following this definition, <span class="citation" data-cites="Celeux:Soromenho:1996">[<a href="#ref-Celeux:Soromenho:1996" role="doc-biblioref">43</a>]</span> defines the entropy of a finite mixture model as follows <span class="math display">\[
E_{\text{FMM}} = - \sum_{i=1}^n \sum_{k=1}^K \widehat{p}_{ik} \log(\widehat{p}_{ik}),
\]</span> where <span class="math inline">\(\widehat{p}_{ik}\)</span> is the estimated posterior probability of case <span class="math inline">\(i\)</span> to belong to cluster <span class="math inline">\(k\)</span> (see <a href="#eq-postcondprob">Equation&nbsp;<span>9.4</span></a>). If the mixture components are well separated, <span class="math inline">\(\widehat{p}_{ik} \approx 1\)</span> for the assigned cluster <span class="math inline">\(\mathcal{C}_k\)</span> and <span class="math inline">\(0\)</span> otherwise. Consequently, the entropy of the mixture model in this case is <span class="math inline">\(E_{\text{FMM}} = 0\)</span> (note that <span class="math inline">\(0\log(0)=0\)</span> by convention). On the contrary, in the case of maximal assignment uncertainty, <span class="math inline">\(\widehat{p}_{ik} = 1/K\)</span> for all clusters <span class="math inline">\(\mathcal{C}_k\)</span> (<span class="math inline">\(k=1,\ldots,K\)</span>). As a result, the entropy of the mixture model is <span class="math inline">\(E_{\text{FMM}} = n\log(K)\)</span>.</p>
<p>In latent class and latent profile analysis, a slightly different definition of entropy is used as a diagnostic statistic to assess how well the fitted model assigns individuals to the identified clusters based on their response patterns. Thus, a normalised version of the entropy is defined as follows <span class="math display">\[
E = 1 - \frac{E_{\text{FMM}}}{n \log(K)} = 1 + \dfrac{\sum_{i=1}^n \sum_{k=1}^K \widehat{p}_{ik} \log(\widehat{p}_{ik})}{n \log(K)}.
\]</span> Entropy takes values on the range <span class="math inline">\([0,1]\)</span>, with higher entropy values indicating that the model has less uncertainty in assigning cases to their respective latent classes/profiles. Thus, high entropy values typically indicate a better model which is able to distinguish between the latent components and that the components are relatively distinct. An entropy value close to 1 is ideal, while values above <span class="math inline">\(0.6\)</span> are considered acceptable, although there is no agreed upon optimal cutoff for entropy.</p>
<p>The contribution of each observation to the overall total entropy can be defined as <span class="math display">\[
E_i = 1 + \frac{\sum_{k=1}^K \widehat{p}_{ik} \log(\widehat{p}_{ik})}{\log(K)},
\]</span> so that the overall total entropy is obtained by averaging over the individual contributions, i.e., <span class="math inline">\(E = \sum_{i=1}^n E_i/n\)</span>. The individual contributions <span class="math inline">\(E_i\)</span> can also be used to compute the average entropy of each latent component, which indicates how accurately the model defines components. Average posterior probabilities (AvePP) are a closely related performance assessment measure, given by the average posterior membership probabilities <span class="math inline">\(\widehat{p}_{ik}\)</span> for each component for the observations most probably assigned to that component, for which a cutoff of <span class="math inline">\(0.8\)</span> has been suggested to indicate acceptably high assignment certainty and well-separated clusters <span class="citation" data-cites="NylundGibsonChoi2018">[<a href="#ref-NylundGibsonChoi2018" role="doc-biblioref">34</a>]</span>. The analysis below presents the necessary code to calculate entropies and average posterior probabilities thusly from a fitted <code>mclust</code> model.</p>
</section>
</section>
</section>
<section id="application-school-engagement-academic-achievement-and-self-regulated-learning" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="application-school-engagement-academic-achievement-and-self-regulated-learning"><span class="header-section-number">4</span> Application: School engagement, academic achievement, and self-regulated learning</h2>
<p>A group of 717 primary school students from northern Spain were evaluated in terms of their school engagement, self-regulation, and academic performance through the use of various measures. The school engagement measure (SEM) was employed to assess their engagement, while their self-regulation was evaluated with the self-regulation strategy inventory—self-report. The measure for academic achievement was based on the students’ self-reported grades in Spanish and mathematics, which were rated on a scale of 1 to 5. This data set can be used to identify clusters of students based on their engagement and self-regulation. These clusters would represent distinct patterns or “profiles” of engagement. Finding such profiles would allow us to understand individual differences but more importantly to stratify support according to different engagement profiles.</p>
<section id="preparing-the-data" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="preparing-the-data"><span class="header-section-number">4.1</span> Preparing the data</h3>
<p>We start by loading the packages required for the analysis. We note in particular that version 6.0.0 of <code>mclust</code> is employed here, the latest release at the time of writing.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggridges)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mclust)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rio)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, we read the data set from an online comma-separated-value (CSV) file, followed by some data cleaning and formatting to prepare the data for subsequent analysis. Note that the CSV file to be read is not in standard format, so we have to explicitly set the separator field using the optional argument <code>sep = ";"</code>.</p>
<!--
\tiny

::: {.cell}

```{.r .cell-code}
# read the data
url <- "https://github.com/lamethods/data/raw/main/3_engSRLach/Manuscript_School%20Engagment.csv"
data <- import(url, sep = ";")
```
:::

\normalsize
-->
<div class="cell">

</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read the data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">"https://github.com/lamethods/data/raw/main/3_engSRLach/</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="st">               Manuscript_School%20Engagment.csv"</span>, </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">sep =</span> <span class="st">";"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># select the variables to be analyzed</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"PRE_ENG_COND"</span>, <span class="st">"PRE_ENG_COGN"</span>, <span class="st">"PRE_ENG_EMOC"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">select</span>(data, <span class="fu">all_of</span>(vars)) <span class="sc">|&gt;</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">|&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">"BehvEngmnt"</span> <span class="ot">=</span> <span class="st">"PRE_ENG_COND"</span>,  <span class="co"># Behavioral engagement</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>         <span class="st">"CognEngmnt"</span> <span class="ot">=</span> <span class="st">"PRE_ENG_COGN"</span>,  <span class="co"># Cognitive engagement</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>         <span class="st">"EmotEngmnt"</span> <span class="ot">=</span> <span class="st">"PRE_ENG_EMOC"</span>)  <span class="co"># Emotional engagement</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print the data set used in the subsequent analysis</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["BehvEngmnt"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["CognEngmnt"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["EmotEngmnt"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"3.750000","2":"3.142857","3":"4.400000"},{"1":"4.000000","2":"3.714286","3":"2.000000"},{"1":"4.250000","2":"3.857143","3":"4.000000"},{"1":"3.750000","2":"2.571429","3":"3.000000"},{"1":"4.250000","2":"3.000000","3":"4.000000"},{"1":"4.000000","2":"3.714286","3":"3.800000"},{"1":"3.500000","2":"2.142857","3":"3.200000"},{"1":"4.750000","2":"3.571429","3":"1.600000"},{"1":"3.250000","2":"2.714286","3":"3.000000"},{"1":"5.000000","2":"4.428571","3":"4.800000"},{"1":"4.750000","2":"3.571429","3":"4.800000"},{"1":"4.000000","2":"2.571429","3":"2.800000"},{"1":"4.000000","2":"2.428571","3":"3.200000"},{"1":"4.250000","2":"3.857143","3":"4.200000"},{"1":"4.250000","2":"2.857143","3":"2.400000"},{"1":"3.750000","2":"3.285714","3":"3.600000"},{"1":"4.000000","2":"3.714286","3":"4.400000"},{"1":"4.000000","2":"3.142857","3":"4.000000"},{"1":"4.500000","2":"2.916458","3":"4.000000"},{"1":"4.000000","2":"2.428571","3":"3.000000"},{"1":"4.750000","2":"3.285714","3":"4.400000"},{"1":"4.000000","2":"2.142857","3":"1.800000"},{"1":"3.500000","2":"3.142857","3":"3.000000"},{"1":"4.500000","2":"3.571429","3":"4.000000"},{"1":"4.750000","2":"2.916458","3":"4.400000"},{"1":"4.750000","2":"2.714286","3":"2.200000"},{"1":"4.250000","2":"3.000000","3":"3.600000"},{"1":"4.171053","2":"3.714286","3":"4.800000"},{"1":"5.000000","2":"4.571429","3":"4.600000"},{"1":"3.000000","2":"2.714286","3":"2.400000"},{"1":"4.000000","2":"2.916458","3":"3.609792"},{"1":"4.250000","2":"3.571429","3":"2.600000"},{"1":"4.250000","2":"2.857143","3":"3.200000"},{"1":"4.750000","2":"3.000000","3":"3.400000"},{"1":"4.171053","2":"2.285714","3":"3.000000"},{"1":"5.000000","2":"3.428571","3":"3.600000"},{"1":"4.171053","2":"2.916458","3":"2.200000"},{"1":"3.750000","2":"1.714286","3":"3.400000"},{"1":"5.000000","2":"3.857143","3":"4.400000"},{"1":"4.500000","2":"1.857143","3":"2.000000"},{"1":"4.000000","2":"2.285714","3":"4.800000"},{"1":"3.000000","2":"2.714286","3":"3.400000"},{"1":"4.250000","2":"3.857143","3":"4.800000"},{"1":"4.750000","2":"4.428571","3":"5.000000"},{"1":"4.500000","2":"3.428571","3":"4.200000"},{"1":"4.500000","2":"3.571429","3":"3.800000"},{"1":"4.000000","2":"2.571429","3":"3.600000"},{"1":"3.750000","2":"2.714286","3":"4.000000"},{"1":"3.750000","2":"3.142857","3":"4.200000"},{"1":"4.500000","2":"3.714286","3":"4.400000"},{"1":"3.750000","2":"2.428571","3":"4.400000"},{"1":"5.000000","2":"3.428571","3":"5.000000"},{"1":"4.000000","2":"3.142857","3":"4.800000"},{"1":"4.750000","2":"3.285714","3":"5.000000"},{"1":"5.000000","2":"5.000000","3":"5.000000"},{"1":"5.000000","2":"4.714286","3":"5.000000"},{"1":"4.250000","2":"2.916458","3":"3.400000"},{"1":"3.750000","2":"3.000000","3":"2.600000"},{"1":"3.750000","2":"2.857143","3":"3.800000"},{"1":"4.750000","2":"3.714286","3":"4.600000"},{"1":"3.250000","2":"1.714286","3":"1.800000"},{"1":"5.000000","2":"3.000000","3":"4.400000"},{"1":"4.250000","2":"2.916458","3":"4.800000"},{"1":"3.000000","2":"2.916458","3":"4.000000"},{"1":"2.750000","2":"3.142857","3":"4.000000"},{"1":"4.000000","2":"3.000000","3":"4.200000"},{"1":"4.250000","2":"2.428571","3":"4.200000"},{"1":"3.250000","2":"2.285714","3":"4.600000"},{"1":"4.750000","2":"3.571429","3":"4.200000"},{"1":"4.750000","2":"3.714286","3":"4.200000"},{"1":"2.750000","2":"2.285714","3":"4.200000"},{"1":"3.250000","2":"1.000000","3":"4.600000"},{"1":"4.250000","2":"4.857143","3":"5.000000"},{"1":"5.000000","2":"3.714286","3":"2.800000"},{"1":"5.000000","2":"5.000000","3":"5.000000"},{"1":"4.750000","2":"4.285714","3":"5.000000"},{"1":"2.500000","2":"1.857143","3":"2.600000"},{"1":"4.750000","2":"2.285714","3":"2.800000"},{"1":"4.250000","2":"4.142857","3":"5.000000"},{"1":"4.250000","2":"4.571429","3":"4.800000"},{"1":"4.250000","2":"2.428571","3":"1.000000"},{"1":"4.000000","2":"2.857143","3":"3.600000"},{"1":"3.750000","2":"2.916458","3":"3.400000"},{"1":"4.000000","2":"2.714286","3":"4.000000"},{"1":"4.750000","2":"3.285714","3":"5.000000"},{"1":"4.750000","2":"3.714286","3":"4.800000"},{"1":"4.171053","2":"3.428571","3":"4.400000"},{"1":"2.250000","2":"2.142857","3":"5.000000"},{"1":"3.250000","2":"3.714286","3":"4.400000"},{"1":"3.750000","2":"3.285714","3":"4.000000"},{"1":"4.000000","2":"3.000000","3":"4.000000"},{"1":"4.750000","2":"3.857143","3":"3.400000"},{"1":"4.250000","2":"2.285714","3":"5.000000"},{"1":"5.000000","2":"5.000000","3":"5.000000"},{"1":"4.171053","2":"4.000000","3":"2.800000"},{"1":"5.000000","2":"3.571429","3":"4.000000"},{"1":"4.000000","2":"1.714286","3":"4.000000"},{"1":"3.750000","2":"4.285714","3":"3.000000"},{"1":"3.750000","2":"3.714286","3":"3.400000"},{"1":"3.000000","2":"2.428571","3":"2.200000"},{"1":"5.000000","2":"4.000000","3":"4.800000"},{"1":"3.750000","2":"3.285714","3":"1.800000"},{"1":"4.000000","2":"2.857143","3":"4.000000"},{"1":"5.000000","2":"3.714286","3":"4.600000"},{"1":"4.500000","2":"3.142857","3":"4.200000"},{"1":"3.750000","2":"1.857143","3":"3.600000"},{"1":"4.500000","2":"4.142857","3":"3.609792"},{"1":"4.250000","2":"3.285714","3":"4.200000"},{"1":"4.000000","2":"2.714286","3":"3.600000"},{"1":"4.750000","2":"3.285714","3":"4.400000"},{"1":"4.750000","2":"3.571429","3":"4.000000"},{"1":"3.500000","2":"2.000000","3":"5.000000"},{"1":"2.500000","2":"2.857143","3":"3.200000"},{"1":"4.250000","2":"3.714286","3":"5.000000"},{"1":"4.750000","2":"4.142857","3":"3.800000"},{"1":"4.000000","2":"3.142857","3":"3.800000"},{"1":"5.000000","2":"5.000000","3":"5.000000"},{"1":"3.000000","2":"2.916458","3":"1.400000"},{"1":"3.250000","2":"2.916458","3":"4.400000"},{"1":"3.750000","2":"3.000000","3":"3.600000"},{"1":"3.750000","2":"3.571429","3":"3.609792"},{"1":"4.250000","2":"2.000000","3":"3.800000"},{"1":"3.250000","2":"1.714286","3":"2.800000"},{"1":"4.250000","2":"2.285714","3":"2.200000"},{"1":"4.500000","2":"2.142857","3":"3.200000"},{"1":"3.000000","2":"3.000000","3":"3.600000"},{"1":"4.750000","2":"4.428571","3":"5.000000"},{"1":"4.500000","2":"3.428571","3":"4.800000"},{"1":"3.500000","2":"2.571429","3":"1.800000"},{"1":"3.500000","2":"3.285714","3":"3.609792"},{"1":"3.000000","2":"2.142857","3":"4.600000"},{"1":"3.750000","2":"3.571429","3":"3.800000"},{"1":"3.250000","2":"1.857143","3":"3.400000"},{"1":"3.500000","2":"2.571429","3":"3.800000"},{"1":"3.000000","2":"2.000000","3":"3.609792"},{"1":"3.500000","2":"2.142857","3":"3.000000"},{"1":"4.500000","2":"3.142857","3":"4.600000"},{"1":"5.000000","2":"2.916458","3":"4.200000"},{"1":"4.500000","2":"2.000000","3":"3.600000"},{"1":"4.750000","2":"3.571429","3":"3.200000"},{"1":"4.250000","2":"3.714286","3":"4.200000"},{"1":"5.000000","2":"3.285714","3":"3.200000"},{"1":"4.000000","2":"2.857143","3":"4.400000"},{"1":"4.250000","2":"3.428571","3":"4.000000"},{"1":"4.750000","2":"1.428571","3":"1.400000"},{"1":"4.250000","2":"1.857143","3":"1.400000"},{"1":"4.250000","2":"3.571429","3":"2.800000"},{"1":"4.000000","2":"2.714286","3":"3.609792"},{"1":"4.500000","2":"2.857143","3":"4.600000"},{"1":"4.500000","2":"3.285714","3":"2.800000"},{"1":"3.750000","2":"2.571429","3":"3.400000"},{"1":"4.750000","2":"3.428571","3":"4.600000"},{"1":"3.750000","2":"1.285714","3":"1.000000"},{"1":"3.500000","2":"2.000000","3":"2.800000"},{"1":"4.250000","2":"3.428571","3":"3.200000"},{"1":"3.750000","2":"2.000000","3":"3.609792"},{"1":"4.500000","2":"4.714286","3":"4.600000"},{"1":"4.000000","2":"2.857143","3":"3.000000"},{"1":"4.171053","2":"1.428571","3":"3.000000"},{"1":"4.250000","2":"3.285714","3":"2.800000"},{"1":"3.000000","2":"3.000000","3":"3.400000"},{"1":"4.500000","2":"2.142857","3":"4.200000"},{"1":"3.750000","2":"2.285714","3":"3.609792"},{"1":"3.500000","2":"2.916458","3":"3.609792"},{"1":"4.750000","2":"3.142857","3":"4.200000"},{"1":"5.000000","2":"4.000000","3":"4.200000"},{"1":"3.750000","2":"2.571429","3":"3.800000"},{"1":"4.750000","2":"2.428571","3":"3.609792"},{"1":"4.171053","2":"2.142857","3":"3.200000"},{"1":"4.500000","2":"3.000000","3":"4.400000"},{"1":"4.250000","2":"3.285714","3":"4.400000"},{"1":"4.171053","2":"2.916458","3":"3.200000"},{"1":"4.500000","2":"2.916458","3":"3.800000"},{"1":"4.500000","2":"2.428571","3":"3.800000"},{"1":"4.500000","2":"3.714286","3":"4.800000"},{"1":"4.500000","2":"3.285714","3":"3.609792"},{"1":"4.000000","2":"2.428571","3":"3.609792"},{"1":"4.750000","2":"2.714286","3":"4.600000"},{"1":"4.750000","2":"2.285714","3":"4.400000"},{"1":"4.000000","2":"2.571429","3":"3.000000"},{"1":"5.000000","2":"3.428571","3":"3.400000"},{"1":"4.750000","2":"4.285714","3":"5.000000"},{"1":"4.000000","2":"2.571429","3":"4.800000"},{"1":"4.500000","2":"2.428571","3":"3.800000"},{"1":"4.250000","2":"3.285714","3":"4.000000"},{"1":"5.000000","2":"4.428571","3":"4.800000"},{"1":"3.250000","2":"3.571429","3":"2.200000"},{"1":"4.500000","2":"3.714286","3":"4.400000"},{"1":"5.000000","2":"1.571429","3":"2.800000"},{"1":"4.500000","2":"3.142857","3":"4.800000"},{"1":"5.000000","2":"3.285714","3":"3.609792"},{"1":"4.750000","2":"2.916458","3":"3.800000"},{"1":"4.000000","2":"3.714286","3":"2.800000"},{"1":"4.750000","2":"2.285714","3":"4.000000"},{"1":"4.171053","2":"2.916458","3":"3.609792"},{"1":"5.000000","2":"3.857143","3":"5.000000"},{"1":"3.750000","2":"3.714286","3":"3.600000"},{"1":"4.750000","2":"3.714286","3":"4.600000"},{"1":"4.000000","2":"2.916458","3":"3.609792"},{"1":"4.750000","2":"1.857143","3":"3.400000"},{"1":"3.750000","2":"2.428571","3":"3.000000"},{"1":"4.500000","2":"2.000000","3":"3.609792"},{"1":"3.000000","2":"3.285714","3":"3.200000"},{"1":"3.000000","2":"2.916458","3":"3.000000"},{"1":"4.250000","2":"2.714286","3":"3.800000"},{"1":"5.000000","2":"3.714286","3":"4.600000"},{"1":"4.250000","2":"2.428571","3":"2.200000"},{"1":"5.000000","2":"4.142857","3":"4.800000"},{"1":"4.171053","2":"2.428571","3":"3.200000"},{"1":"4.250000","2":"1.142857","3":"2.200000"},{"1":"5.000000","2":"2.000000","3":"2.800000"},{"1":"5.000000","2":"2.000000","3":"2.000000"},{"1":"3.500000","2":"3.285714","3":"4.400000"},{"1":"3.000000","2":"3.285714","3":"3.600000"},{"1":"5.000000","2":"3.571429","3":"4.200000"},{"1":"5.000000","2":"3.428571","3":"4.800000"},{"1":"4.000000","2":"3.285714","3":"2.600000"},{"1":"4.750000","2":"2.428571","3":"3.000000"},{"1":"4.750000","2":"3.285714","3":"4.400000"},{"1":"3.750000","2":"2.571429","3":"3.000000"},{"1":"4.000000","2":"2.857143","3":"2.000000"},{"1":"4.500000","2":"2.428571","3":"3.000000"},{"1":"4.500000","2":"2.571429","3":"3.600000"},{"1":"3.500000","2":"2.857143","3":"3.200000"},{"1":"3.000000","2":"3.285714","3":"2.600000"},{"1":"4.000000","2":"3.000000","3":"4.400000"},{"1":"4.250000","2":"2.916458","3":"2.800000"},{"1":"5.000000","2":"3.857143","3":"4.200000"},{"1":"3.250000","2":"3.000000","3":"3.609792"},{"1":"4.000000","2":"3.428571","3":"3.400000"},{"1":"3.750000","2":"1.285714","3":"1.400000"},{"1":"3.750000","2":"3.142857","3":"3.600000"},{"1":"4.750000","2":"3.571429","3":"3.400000"},{"1":"4.000000","2":"3.428571","3":"3.400000"},{"1":"5.000000","2":"3.285714","3":"4.600000"},{"1":"4.500000","2":"3.857143","3":"3.600000"},{"1":"2.750000","2":"1.571429","3":"2.800000"},{"1":"4.250000","2":"1.857143","3":"2.000000"},{"1":"5.000000","2":"3.571429","3":"4.800000"},{"1":"4.500000","2":"4.000000","3":"4.200000"},{"1":"5.000000","2":"2.428571","3":"3.400000"},{"1":"4.250000","2":"3.000000","3":"2.400000"},{"1":"4.500000","2":"3.142857","3":"4.200000"},{"1":"3.750000","2":"2.428571","3":"1.400000"},{"1":"5.000000","2":"2.142857","3":"3.400000"},{"1":"4.000000","2":"1.571429","3":"3.200000"},{"1":"3.750000","2":"2.571429","3":"3.400000"},{"1":"4.750000","2":"3.000000","3":"3.609792"},{"1":"4.750000","2":"1.857143","3":"3.609792"},{"1":"4.750000","2":"4.285714","3":"4.800000"},{"1":"4.171053","2":"2.916458","3":"3.609792"},{"1":"4.500000","2":"3.285714","3":"3.800000"},{"1":"3.000000","2":"2.285714","3":"3.609792"},{"1":"4.000000","2":"3.428571","3":"4.000000"},{"1":"4.500000","2":"2.285714","3":"4.200000"},{"1":"4.500000","2":"3.000000","3":"1.600000"},{"1":"4.171053","2":"3.142857","3":"3.000000"},{"1":"4.750000","2":"3.714286","3":"4.400000"},{"1":"5.000000","2":"2.285714","3":"4.800000"},{"1":"4.500000","2":"3.571429","3":"4.400000"},{"1":"4.500000","2":"3.857143","3":"4.000000"},{"1":"2.500000","2":"1.571429","3":"3.800000"},{"1":"3.250000","2":"3.000000","3":"3.609792"},{"1":"4.250000","2":"1.428571","3":"2.800000"},{"1":"4.500000","2":"3.714286","3":"4.000000"},{"1":"3.250000","2":"2.142857","3":"3.600000"},{"1":"5.000000","2":"3.571429","3":"4.200000"},{"1":"4.750000","2":"3.000000","3":"5.000000"},{"1":"4.750000","2":"2.285714","3":"4.200000"},{"1":"3.250000","2":"1.857143","3":"3.609792"},{"1":"4.250000","2":"3.428571","3":"2.400000"},{"1":"4.250000","2":"2.571429","3":"3.800000"},{"1":"4.000000","2":"2.428571","3":"3.600000"},{"1":"1.000000","2":"1.000000","3":"1.000000"},{"1":"3.000000","2":"3.285714","3":"3.600000"},{"1":"4.750000","2":"3.142857","3":"3.600000"},{"1":"4.500000","2":"1.714286","3":"3.800000"},{"1":"4.500000","2":"3.285714","3":"3.800000"},{"1":"4.500000","2":"3.857143","3":"4.800000"},{"1":"4.000000","2":"2.000000","3":"2.600000"},{"1":"5.000000","2":"2.571429","3":"4.200000"},{"1":"4.500000","2":"3.000000","3":"3.000000"},{"1":"5.000000","2":"3.000000","3":"3.400000"},{"1":"5.000000","2":"2.571429","3":"2.600000"},{"1":"4.500000","2":"3.142857","3":"4.000000"},{"1":"4.750000","2":"3.714286","3":"4.800000"},{"1":"4.500000","2":"3.571429","3":"4.800000"},{"1":"5.000000","2":"3.571429","3":"3.609792"},{"1":"4.500000","2":"2.285714","3":"1.600000"},{"1":"3.250000","2":"2.428571","3":"4.200000"},{"1":"4.750000","2":"2.857143","3":"3.600000"},{"1":"4.250000","2":"3.000000","3":"4.200000"},{"1":"4.171053","2":"4.571429","3":"4.200000"},{"1":"5.000000","2":"4.000000","3":"4.200000"},{"1":"4.500000","2":"3.142857","3":"4.800000"},{"1":"4.250000","2":"2.571429","3":"3.200000"},{"1":"5.000000","2":"4.285714","3":"5.000000"},{"1":"4.250000","2":"4.857143","3":"5.000000"},{"1":"4.750000","2":"3.857143","3":"4.800000"},{"1":"4.750000","2":"2.714286","3":"4.400000"},{"1":"4.171053","2":"4.428571","3":"4.600000"},{"1":"3.250000","2":"1.000000","3":"1.000000"},{"1":"5.000000","2":"4.000000","3":"3.600000"},{"1":"4.750000","2":"2.285714","3":"2.800000"},{"1":"4.750000","2":"3.285714","3":"3.600000"},{"1":"5.000000","2":"3.428571","3":"4.800000"},{"1":"5.000000","2":"3.571429","3":"4.800000"},{"1":"4.750000","2":"2.000000","3":"3.400000"},{"1":"2.000000","2":"1.428571","3":"3.200000"},{"1":"3.000000","2":"3.285714","3":"2.800000"},{"1":"4.000000","2":"2.857143","3":"2.400000"},{"1":"3.750000","2":"2.285714","3":"2.400000"},{"1":"5.000000","2":"4.000000","3":"4.600000"},{"1":"5.000000","2":"3.428571","3":"4.800000"},{"1":"3.000000","2":"2.285714","3":"2.400000"},{"1":"5.000000","2":"3.000000","3":"2.800000"},{"1":"5.000000","2":"2.714286","3":"4.000000"},{"1":"4.000000","2":"3.000000","3":"4.000000"},{"1":"3.250000","2":"3.714286","3":"4.200000"},{"1":"3.250000","2":"2.714286","3":"3.200000"},{"1":"3.750000","2":"2.142857","3":"3.600000"},{"1":"3.000000","2":"1.571429","3":"2.200000"},{"1":"4.250000","2":"4.142857","3":"4.600000"},{"1":"3.000000","2":"3.000000","3":"3.000000"},{"1":"4.500000","2":"3.142857","3":"4.000000"},{"1":"4.000000","2":"2.428571","3":"3.600000"},{"1":"5.000000","2":"2.571429","3":"3.400000"},{"1":"4.750000","2":"4.428571","3":"3.600000"},{"1":"3.750000","2":"2.142857","3":"3.400000"},{"1":"3.750000","2":"1.142857","3":"1.000000"},{"1":"4.000000","2":"4.571429","3":"4.600000"},{"1":"4.750000","2":"3.000000","3":"5.000000"},{"1":"4.750000","2":"3.428571","3":"3.800000"},{"1":"3.250000","2":"1.857143","3":"2.600000"},{"1":"4.250000","2":"2.714286","3":"4.600000"},{"1":"3.750000","2":"2.285714","3":"4.200000"},{"1":"3.750000","2":"3.285714","3":"3.400000"},{"1":"3.750000","2":"3.571429","3":"3.600000"},{"1":"4.500000","2":"3.142857","3":"5.000000"},{"1":"5.000000","2":"4.142857","3":"4.600000"},{"1":"4.250000","2":"2.714286","3":"3.400000"},{"1":"3.000000","2":"2.000000","3":"3.600000"},{"1":"4.250000","2":"2.714286","3":"2.800000"},{"1":"4.000000","2":"1.857143","3":"3.000000"},{"1":"4.500000","2":"4.000000","3":"4.600000"},{"1":"3.500000","2":"1.857143","3":"3.800000"},{"1":"3.250000","2":"2.285714","3":"2.200000"},{"1":"3.000000","2":"1.571429","3":"2.800000"},{"1":"3.750000","2":"1.857143","3":"3.600000"},{"1":"4.750000","2":"3.714286","3":"4.400000"},{"1":"4.500000","2":"3.857143","3":"4.600000"},{"1":"3.750000","2":"4.142857","3":"3.400000"},{"1":"4.171053","2":"2.428571","3":"5.000000"},{"1":"3.750000","2":"3.428571","3":"3.400000"},{"1":"5.000000","2":"3.571429","3":"4.000000"},{"1":"3.250000","2":"3.142857","3":"3.600000"},{"1":"4.500000","2":"2.916458","3":"4.800000"},{"1":"4.000000","2":"2.571429","3":"2.200000"},{"1":"4.250000","2":"3.571429","3":"3.609792"},{"1":"4.750000","2":"2.857143","3":"3.600000"},{"1":"4.000000","2":"2.571429","3":"3.609792"},{"1":"4.750000","2":"3.285714","3":"2.800000"},{"1":"1.500000","2":"2.571429","3":"3.000000"},{"1":"4.000000","2":"2.857143","3":"3.600000"},{"1":"4.750000","2":"3.571429","3":"3.800000"},{"1":"3.750000","2":"2.428571","3":"4.400000"},{"1":"3.500000","2":"3.714286","3":"2.600000"},{"1":"4.250000","2":"3.571429","3":"4.600000"},{"1":"5.000000","2":"2.714286","3":"2.600000"},{"1":"4.750000","2":"3.285714","3":"3.200000"},{"1":"4.500000","2":"2.000000","3":"4.200000"},{"1":"3.000000","2":"2.714286","3":"2.600000"},{"1":"4.750000","2":"3.428571","3":"3.800000"},{"1":"1.500000","2":"1.000000","3":"1.000000"},{"1":"3.000000","2":"1.428571","3":"1.800000"},{"1":"1.750000","2":"2.714286","3":"1.800000"},{"1":"4.000000","2":"3.428571","3":"4.800000"},{"1":"3.500000","2":"2.142857","3":"4.000000"},{"1":"4.000000","2":"2.285714","3":"2.800000"},{"1":"4.250000","2":"2.142857","3":"1.000000"},{"1":"5.000000","2":"3.857143","3":"4.400000"},{"1":"3.750000","2":"3.857143","3":"3.600000"},{"1":"4.750000","2":"3.428571","3":"3.400000"},{"1":"4.750000","2":"2.714286","3":"4.400000"},{"1":"4.000000","2":"2.857143","3":"2.000000"},{"1":"3.500000","2":"2.714286","3":"4.400000"},{"1":"5.000000","2":"4.000000","3":"3.000000"},{"1":"4.750000","2":"2.571429","3":"4.400000"},{"1":"5.000000","2":"4.428571","3":"3.800000"},{"1":"3.000000","2":"1.285714","3":"1.000000"},{"1":"4.000000","2":"2.428571","3":"3.200000"},{"1":"4.250000","2":"2.857143","3":"3.600000"},{"1":"5.000000","2":"5.000000","3":"5.000000"},{"1":"4.500000","2":"2.857143","3":"3.000000"},{"1":"4.000000","2":"1.714286","3":"4.200000"},{"1":"4.000000","2":"2.428571","3":"3.800000"},{"1":"4.750000","2":"1.428571","3":"2.200000"},{"1":"4.750000","2":"3.571429","3":"5.000000"},{"1":"5.000000","2":"3.142857","3":"3.800000"},{"1":"4.250000","2":"2.857143","3":"4.600000"},{"1":"4.750000","2":"1.285714","3":"2.600000"},{"1":"4.171053","2":"2.916458","3":"3.200000"},{"1":"4.000000","2":"2.714286","3":"4.400000"},{"1":"4.171053","2":"3.571429","3":"2.400000"},{"1":"4.000000","2":"2.142857","3":"3.400000"},{"1":"4.000000","2":"2.571429","3":"3.800000"},{"1":"4.000000","2":"3.714286","3":"4.200000"},{"1":"4.000000","2":"2.714286","3":"3.800000"},{"1":"4.000000","2":"1.714286","3":"4.600000"},{"1":"3.000000","2":"3.000000","3":"3.000000"},{"1":"4.500000","2":"1.428571","3":"4.000000"},{"1":"4.750000","2":"2.142857","3":"2.600000"},{"1":"4.500000","2":"3.428571","3":"4.800000"},{"1":"4.500000","2":"1.714286","3":"2.200000"},{"1":"4.250000","2":"3.285714","3":"3.400000"},{"1":"3.250000","2":"2.571429","3":"3.400000"},{"1":"4.250000","2":"1.714286","3":"1.800000"},{"1":"5.000000","2":"2.142857","3":"3.800000"},{"1":"5.000000","2":"2.714286","3":"4.200000"},{"1":"4.750000","2":"3.857143","3":"4.400000"},{"1":"3.750000","2":"3.000000","3":"3.600000"},{"1":"4.750000","2":"3.428571","3":"4.600000"},{"1":"5.000000","2":"3.142857","3":"3.400000"},{"1":"3.500000","2":"2.857143","3":"3.000000"},{"1":"3.750000","2":"2.428571","3":"3.000000"},{"1":"3.250000","2":"3.428571","3":"3.200000"},{"1":"5.000000","2":"2.142857","3":"4.600000"},{"1":"2.500000","2":"2.857143","3":"3.800000"},{"1":"3.500000","2":"2.714286","3":"3.000000"},{"1":"3.750000","2":"2.428571","3":"3.200000"},{"1":"4.171053","2":"2.916458","3":"4.000000"},{"1":"5.000000","2":"2.714286","3":"3.800000"},{"1":"3.750000","2":"3.571429","3":"3.200000"},{"1":"4.000000","2":"3.714286","3":"5.000000"},{"1":"5.000000","2":"2.571429","3":"4.400000"},{"1":"4.171053","2":"2.916458","3":"3.609792"},{"1":"4.250000","2":"3.142857","3":"3.800000"},{"1":"3.750000","2":"3.000000","3":"4.000000"},{"1":"4.171053","2":"3.714286","3":"4.000000"},{"1":"4.500000","2":"1.714286","3":"2.800000"},{"1":"4.500000","2":"2.857143","3":"3.800000"},{"1":"4.500000","2":"3.285714","3":"3.400000"},{"1":"4.000000","2":"2.916458","3":"3.609792"},{"1":"3.500000","2":"3.428571","3":"3.609792"},{"1":"4.500000","2":"2.000000","3":"3.400000"},{"1":"4.500000","2":"1.428571","3":"2.200000"},{"1":"4.250000","2":"3.428571","3":"4.600000"},{"1":"4.000000","2":"2.000000","3":"3.200000"},{"1":"4.500000","2":"2.714286","3":"3.400000"},{"1":"4.171053","2":"2.714286","3":"4.200000"},{"1":"3.750000","2":"3.000000","3":"3.609792"},{"1":"4.171053","2":"2.857143","3":"3.800000"},{"1":"3.750000","2":"3.142857","3":"4.800000"},{"1":"3.250000","2":"1.571429","3":"3.000000"},{"1":"4.171053","2":"2.428571","3":"3.609792"},{"1":"4.500000","2":"3.571429","3":"4.200000"},{"1":"3.750000","2":"2.714286","3":"4.000000"},{"1":"4.750000","2":"2.571429","3":"3.200000"},{"1":"4.250000","2":"3.142857","3":"3.200000"},{"1":"4.500000","2":"2.428571","3":"2.600000"},{"1":"4.500000","2":"3.571429","3":"3.200000"},{"1":"3.000000","2":"1.857143","3":"3.800000"},{"1":"4.000000","2":"2.571429","3":"4.200000"},{"1":"3.750000","2":"2.857143","3":"3.400000"},{"1":"4.500000","2":"3.142857","3":"3.000000"},{"1":"3.500000","2":"3.000000","3":"2.400000"},{"1":"4.250000","2":"2.285714","3":"4.000000"},{"1":"4.000000","2":"2.428571","3":"3.200000"},{"1":"4.750000","2":"3.142857","3":"3.400000"},{"1":"4.750000","2":"3.714286","3":"3.400000"},{"1":"5.000000","2":"3.142857","3":"3.200000"},{"1":"4.171053","2":"2.916458","3":"3.609792"},{"1":"4.500000","2":"3.142857","3":"3.609792"},{"1":"4.000000","2":"2.000000","3":"2.800000"},{"1":"4.500000","2":"1.571429","3":"2.000000"},{"1":"4.750000","2":"2.142857","3":"4.400000"},{"1":"4.250000","2":"3.000000","3":"3.200000"},{"1":"4.250000","2":"2.857143","3":"4.200000"},{"1":"3.750000","2":"2.714286","3":"3.200000"},{"1":"4.500000","2":"3.142857","3":"3.800000"},{"1":"4.250000","2":"3.000000","3":"5.000000"},{"1":"4.250000","2":"1.857143","3":"3.600000"},{"1":"4.500000","2":"3.000000","3":"4.200000"},{"1":"4.750000","2":"3.285714","3":"4.800000"},{"1":"4.250000","2":"3.142857","3":"5.000000"},{"1":"4.500000","2":"3.000000","3":"3.609792"},{"1":"4.500000","2":"3.428571","3":"3.400000"},{"1":"4.500000","2":"3.571429","3":"4.600000"},{"1":"4.000000","2":"2.285714","3":"2.600000"},{"1":"4.750000","2":"2.285714","3":"2.800000"},{"1":"4.500000","2":"2.571429","3":"4.400000"},{"1":"3.250000","2":"2.857143","3":"1.200000"},{"1":"4.000000","2":"2.857143","3":"4.600000"},{"1":"4.250000","2":"3.285714","3":"4.800000"},{"1":"5.000000","2":"5.000000","3":"5.000000"},{"1":"4.500000","2":"3.000000","3":"3.400000"},{"1":"4.250000","2":"2.916458","3":"4.000000"},{"1":"3.750000","2":"3.714286","3":"3.600000"},{"1":"5.000000","2":"3.428571","3":"4.200000"},{"1":"4.500000","2":"3.428571","3":"4.400000"},{"1":"4.250000","2":"3.285714","3":"4.000000"},{"1":"3.250000","2":"1.714286","3":"2.600000"},{"1":"3.500000","2":"1.714286","3":"3.200000"},{"1":"5.000000","2":"2.428571","3":"4.800000"},{"1":"4.750000","2":"2.571429","3":"5.000000"},{"1":"4.750000","2":"3.285714","3":"4.000000"},{"1":"4.000000","2":"3.428571","3":"3.609792"},{"1":"2.500000","2":"2.428571","3":"2.600000"},{"1":"4.000000","2":"4.142857","3":"4.200000"},{"1":"4.500000","2":"2.571429","3":"4.400000"},{"1":"3.250000","2":"1.285714","3":"1.200000"},{"1":"3.250000","2":"3.000000","3":"4.600000"},{"1":"4.250000","2":"3.142857","3":"5.000000"},{"1":"4.000000","2":"3.285714","3":"4.200000"},{"1":"4.171053","2":"3.857143","3":"4.200000"},{"1":"4.250000","2":"1.714286","3":"3.400000"},{"1":"4.000000","2":"2.571429","3":"4.200000"},{"1":"4.000000","2":"2.857143","3":"4.800000"},{"1":"4.250000","2":"3.000000","3":"4.600000"},{"1":"4.500000","2":"2.857143","3":"3.400000"},{"1":"4.500000","2":"3.428571","3":"3.400000"},{"1":"3.500000","2":"4.142857","3":"4.600000"},{"1":"4.500000","2":"2.142857","3":"3.800000"},{"1":"4.250000","2":"3.714286","3":"4.400000"},{"1":"4.000000","2":"2.571429","3":"3.609792"},{"1":"3.000000","2":"2.000000","3":"2.000000"},{"1":"3.750000","2":"4.000000","3":"3.600000"},{"1":"5.000000","2":"2.428571","3":"2.600000"},{"1":"3.500000","2":"2.428571","3":"2.200000"},{"1":"4.500000","2":"4.285714","3":"4.800000"},{"1":"4.750000","2":"2.714286","3":"3.800000"},{"1":"2.750000","2":"2.571429","3":"1.000000"},{"1":"3.500000","2":"3.000000","3":"2.200000"},{"1":"4.000000","2":"2.142857","3":"4.600000"},{"1":"4.000000","2":"2.571429","3":"3.800000"},{"1":"4.500000","2":"2.428571","3":"3.200000"},{"1":"2.500000","2":"1.714286","3":"2.800000"},{"1":"3.750000","2":"1.571429","3":"4.600000"},{"1":"4.750000","2":"3.571429","3":"3.600000"},{"1":"3.750000","2":"4.000000","3":"3.800000"},{"1":"4.000000","2":"3.285714","3":"4.000000"},{"1":"4.750000","2":"4.285714","3":"4.400000"},{"1":"4.171053","2":"2.571429","3":"1.800000"},{"1":"5.000000","2":"4.142857","3":"3.609792"},{"1":"4.171053","2":"3.428571","3":"4.000000"},{"1":"3.750000","2":"4.142857","3":"4.200000"},{"1":"4.250000","2":"3.142857","3":"3.800000"},{"1":"5.000000","2":"4.428571","3":"5.000000"},{"1":"4.500000","2":"2.714286","3":"3.200000"},{"1":"4.500000","2":"4.142857","3":"4.400000"},{"1":"4.000000","2":"2.285714","3":"4.800000"},{"1":"4.500000","2":"2.714286","3":"3.200000"},{"1":"5.000000","2":"3.857143","3":"4.600000"},{"1":"4.750000","2":"2.714286","3":"3.800000"},{"1":"3.000000","2":"3.714286","3":"3.600000"},{"1":"4.000000","2":"1.000000","3":"1.000000"},{"1":"4.000000","2":"1.714286","3":"3.200000"},{"1":"4.000000","2":"3.142857","3":"3.800000"},{"1":"4.000000","2":"4.142857","3":"4.000000"},{"1":"3.750000","2":"2.916458","3":"3.000000"},{"1":"3.750000","2":"3.142857","3":"4.600000"},{"1":"4.000000","2":"1.571429","3":"2.400000"},{"1":"4.750000","2":"3.142857","3":"3.800000"},{"1":"4.000000","2":"2.142857","3":"3.400000"},{"1":"4.500000","2":"3.428571","3":"3.200000"},{"1":"4.250000","2":"3.714286","3":"4.400000"},{"1":"4.250000","2":"2.571429","3":"4.600000"},{"1":"4.750000","2":"3.428571","3":"4.000000"},{"1":"3.250000","2":"3.428571","3":"3.600000"},{"1":"4.171053","2":"2.428571","3":"3.400000"},{"1":"3.500000","2":"2.428571","3":"2.600000"},{"1":"4.000000","2":"3.142857","3":"3.609792"},{"1":"4.750000","2":"2.571429","3":"4.800000"},{"1":"4.000000","2":"1.571429","3":"2.800000"},{"1":"4.750000","2":"2.857143","3":"2.800000"},{"1":"3.500000","2":"1.571429","3":"2.800000"},{"1":"4.500000","2":"3.000000","3":"3.609792"},{"1":"4.750000","2":"4.142857","3":"4.600000"},{"1":"3.500000","2":"2.571429","3":"3.000000"},{"1":"2.750000","2":"2.714286","3":"2.400000"},{"1":"4.250000","2":"2.857143","3":"3.800000"},{"1":"4.250000","2":"2.142857","3":"2.000000"},{"1":"4.750000","2":"3.571429","3":"2.800000"},{"1":"3.000000","2":"1.571429","3":"3.000000"},{"1":"4.171053","2":"1.857143","3":"1.400000"},{"1":"4.171053","2":"2.000000","3":"3.600000"},{"1":"4.000000","2":"2.571429","3":"3.200000"},{"1":"5.000000","2":"1.571429","3":"3.800000"},{"1":"4.171053","2":"2.428571","3":"4.000000"},{"1":"4.000000","2":"2.285714","3":"3.609792"},{"1":"3.750000","2":"2.714286","3":"4.400000"},{"1":"4.750000","2":"3.000000","3":"3.000000"},{"1":"4.750000","2":"2.285714","3":"3.600000"},{"1":"4.500000","2":"1.857143","3":"1.600000"},{"1":"3.250000","2":"3.714286","3":"3.400000"},{"1":"4.250000","2":"2.428571","3":"4.600000"},{"1":"4.000000","2":"2.428571","3":"3.200000"},{"1":"5.000000","2":"2.857143","3":"3.600000"},{"1":"4.250000","2":"3.285714","3":"3.600000"},{"1":"5.000000","2":"3.142857","3":"4.600000"},{"1":"4.250000","2":"2.000000","3":"2.600000"},{"1":"4.000000","2":"1.857143","3":"1.800000"},{"1":"4.750000","2":"2.428571","3":"4.800000"},{"1":"4.250000","2":"2.857143","3":"3.200000"},{"1":"3.500000","2":"3.000000","3":"2.600000"},{"1":"3.250000","2":"1.571429","3":"2.200000"},{"1":"5.000000","2":"3.714286","3":"4.800000"},{"1":"4.000000","2":"3.000000","3":"2.200000"},{"1":"4.500000","2":"2.285714","3":"3.200000"},{"1":"4.250000","2":"3.428571","3":"3.200000"},{"1":"4.500000","2":"4.428571","3":"3.800000"},{"1":"3.250000","2":"1.714286","3":"2.400000"},{"1":"4.250000","2":"2.142857","3":"3.400000"},{"1":"3.750000","2":"2.142857","3":"4.000000"},{"1":"3.250000","2":"2.916458","3":"2.600000"},{"1":"4.250000","2":"2.857143","3":"3.000000"},{"1":"3.750000","2":"1.285714","3":"3.000000"},{"1":"4.500000","2":"1.857143","3":"3.800000"},{"1":"4.750000","2":"2.285714","3":"3.000000"},{"1":"5.000000","2":"3.142857","3":"4.800000"},{"1":"4.750000","2":"2.857143","3":"4.400000"},{"1":"4.250000","2":"3.000000","3":"3.200000"},{"1":"4.250000","2":"2.142857","3":"1.400000"},{"1":"4.000000","2":"3.000000","3":"3.600000"},{"1":"3.500000","2":"3.000000","3":"2.400000"},{"1":"4.750000","2":"3.285714","3":"5.000000"},{"1":"4.000000","2":"2.428571","3":"3.000000"},{"1":"4.750000","2":"3.142857","3":"4.200000"},{"1":"4.000000","2":"3.000000","3":"3.000000"},{"1":"4.000000","2":"1.714286","3":"1.000000"},{"1":"4.171053","2":"2.916458","3":"3.609792"},{"1":"4.000000","2":"3.000000","3":"4.000000"},{"1":"5.000000","2":"2.428571","3":"3.200000"},{"1":"4.500000","2":"3.000000","3":"4.400000"},{"1":"3.750000","2":"3.571429","3":"3.600000"},{"1":"4.000000","2":"4.142857","3":"3.600000"},{"1":"4.250000","2":"1.857143","3":"3.609792"},{"1":"3.250000","2":"2.428571","3":"3.000000"},{"1":"4.750000","2":"4.000000","3":"4.400000"},{"1":"5.000000","2":"3.285714","3":"5.000000"},{"1":"4.000000","2":"3.714286","3":"3.400000"},{"1":"3.750000","2":"2.142857","3":"3.400000"},{"1":"5.000000","2":"3.285714","3":"4.000000"},{"1":"3.750000","2":"3.000000","3":"3.400000"},{"1":"3.000000","2":"1.428571","3":"2.400000"},{"1":"4.750000","2":"2.857143","3":"2.800000"},{"1":"4.000000","2":"3.000000","3":"2.600000"},{"1":"3.750000","2":"2.714286","3":"3.200000"},{"1":"4.750000","2":"3.857143","3":"4.000000"},{"1":"4.250000","2":"2.714286","3":"4.000000"},{"1":"3.750000","2":"2.142857","3":"1.600000"},{"1":"4.250000","2":"3.285714","3":"3.800000"},{"1":"4.500000","2":"2.428571","3":"3.800000"},{"1":"4.250000","2":"4.571429","3":"5.000000"},{"1":"4.750000","2":"4.142857","3":"3.800000"},{"1":"5.000000","2":"2.714286","3":"3.400000"},{"1":"3.500000","2":"3.714286","3":"2.800000"},{"1":"4.250000","2":"1.857143","3":"2.200000"},{"1":"3.750000","2":"4.000000","3":"2.800000"},{"1":"4.250000","2":"3.714286","3":"4.200000"},{"1":"4.000000","2":"2.428571","3":"3.400000"},{"1":"4.250000","2":"3.285714","3":"3.800000"},{"1":"4.250000","2":"2.857143","3":"4.000000"},{"1":"3.750000","2":"2.428571","3":"3.200000"},{"1":"4.000000","2":"2.571429","3":"3.600000"},{"1":"4.171053","2":"1.857143","3":"2.200000"},{"1":"4.750000","2":"4.000000","3":"5.000000"},{"1":"3.750000","2":"1.857143","3":"3.400000"},{"1":"2.500000","2":"1.857143","3":"1.400000"},{"1":"4.500000","2":"4.285714","3":"4.200000"},{"1":"4.000000","2":"1.714286","3":"3.800000"},{"1":"4.000000","2":"2.714286","3":"4.600000"},{"1":"4.750000","2":"3.714286","3":"4.800000"},{"1":"3.750000","2":"2.428571","3":"4.000000"},{"1":"5.000000","2":"3.000000","3":"3.800000"},{"1":"4.750000","2":"4.000000","3":"1.600000"},{"1":"4.250000","2":"3.000000","3":"3.609792"},{"1":"4.250000","2":"3.142857","3":"4.000000"},{"1":"4.250000","2":"3.428571","3":"4.000000"},{"1":"3.750000","2":"2.714286","3":"4.200000"},{"1":"4.250000","2":"2.571429","3":"2.600000"},{"1":"4.500000","2":"3.714286","3":"4.000000"},{"1":"4.000000","2":"2.571429","3":"3.200000"},{"1":"3.750000","2":"3.428571","3":"4.400000"},{"1":"4.750000","2":"3.714286","3":"4.400000"},{"1":"4.750000","2":"3.428571","3":"5.000000"},{"1":"5.000000","2":"2.916458","3":"5.000000"},{"1":"5.000000","2":"3.714286","3":"5.000000"},{"1":"3.500000","2":"1.857143","3":"2.800000"},{"1":"3.750000","2":"2.857143","3":"3.200000"},{"1":"4.250000","2":"2.571429","3":"3.200000"},{"1":"4.750000","2":"3.142857","3":"3.400000"},{"1":"4.000000","2":"2.571429","3":"4.000000"},{"1":"3.000000","2":"3.000000","3":"2.800000"},{"1":"4.500000","2":"2.916458","3":"1.800000"},{"1":"3.500000","2":"2.428571","3":"2.800000"},{"1":"4.500000","2":"3.714286","3":"4.600000"},{"1":"4.500000","2":"3.142857","3":"2.800000"},{"1":"4.250000","2":"2.142857","3":"3.000000"},{"1":"4.500000","2":"1.714286","3":"3.400000"},{"1":"2.500000","2":"2.142857","3":"1.400000"},{"1":"5.000000","2":"2.428571","3":"4.400000"},{"1":"4.750000","2":"4.142857","3":"4.600000"},{"1":"4.750000","2":"3.000000","3":"4.600000"},{"1":"4.750000","2":"2.142857","3":"4.600000"},{"1":"5.000000","2":"3.285714","3":"4.000000"},{"1":"4.500000","2":"2.916458","3":"5.000000"},{"1":"5.000000","2":"2.142857","3":"4.800000"},{"1":"3.250000","2":"2.142857","3":"3.200000"},{"1":"4.250000","2":"4.000000","3":"3.800000"},{"1":"3.250000","2":"1.571429","3":"1.600000"},{"1":"4.000000","2":"3.142857","3":"3.600000"},{"1":"4.000000","2":"2.142857","3":"4.000000"},{"1":"5.000000","2":"4.428571","3":"5.000000"},{"1":"4.500000","2":"3.285714","3":"3.200000"},{"1":"3.500000","2":"2.428571","3":"3.200000"},{"1":"4.750000","2":"2.571429","3":"3.800000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>A table of summary statistics for the data set can be obtained as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x <span class="sc">|&gt;</span> <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">colnames</span>(x),</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">names_to =</span> <span class="st">"Variable"</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">values_to =</span> <span class="st">"Value"</span>) <span class="sc">|&gt;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Variable) <span class="sc">|&gt;</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">N =</span> <span class="fu">n</span>(),</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">Nunq =</span> <span class="fu">n_distinct</span>(Value),</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">Mean =</span> <span class="fu">mean</span>(Value),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">SD =</span> <span class="fu">sd</span>(Value),</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">Min =</span> <span class="fu">min</span>(Value),</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">Median =</span> <span class="fu">median</span>(Value),</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">Max =</span> <span class="fu">max</span>(Value))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["Variable"],"name":[1],"type":["chr"],"align":["left"]},{"label":["N"],"name":[2],"type":["int"],"align":["right"]},{"label":["Nunq"],"name":[3],"type":["int"],"align":["right"]},{"label":["Mean"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["SD"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Min"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["Median"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Max"],"name":[8],"type":["dbl"],"align":["right"]}],"data":[{"1":"BehvEngmnt","2":"717","3":"17","4":"4.171053","5":"0.6265894","6":"1","7":"4.250000","8":"5"},{"1":"CognEngmnt","2":"717","3":"30","4":"2.916458","5":"0.7713089","6":"1","7":"2.916458","8":"5"},{"1":"EmotEngmnt","2":"717","3":"22","4":"3.609792","5":"0.9110551","6":"1","7":"3.609792","8":"5"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
</section>
<section id="model-estimation-and-model-selection" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="model-estimation-and-model-selection"><span class="header-section-number">4.2</span> Model estimation and model selection</h3>
<p>To begin our latent profile analysis, we first fit a number of candidate GMMs with different numbers of latent components and covariance parameritations, and compute the Bayesian Information Criterion (BIC) to select the “optimal” model. This model selection criterion jointly takes into account both the covariance decompositions and the number of mixture components in the model.</p>
<p>As mentioned earlier, given the characteristics of the data, which consists of a small number of unique values relative to the number of observations, a prior is used for regularisation. We invoke the default priors described above, summarise the BIC values of the three best models, and visualise the BIC values of all fitted models.</p>
<div class="cell" data-hash="ch9-model_cache/html/unnamed-chunk-8_d607b5df8ea134222ce393bc479ad34b">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>BIC <span class="ot">&lt;-</span> <span class="fu">mclustBIC</span>(x, <span class="at">prior =</span> <span class="fu">priorControl</span>())</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(BIC)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Best BIC values:</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="do">##              VVI,3        VVI,4       VVV,3</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="do">## BIC      -4521.213 -4526.905884 -4533.57166</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="do">## BIC diff     0.000    -5.693183   -12.35896</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(BIC)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">BIC traces for the estimated GMMs with default priors.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The selected model is a three-component GMM with diagonal covariance matrices of varying volume and shape, with axis-aligned orientation, indicated as <code>(VVI,3)</code>. Thus, the variables are independent within each cluster.</p>
</section>
<section id="examining-model-output" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="examining-model-output"><span class="header-section-number">4.3</span> Examining model output</h3>
<p>The fit of the optimal model is obtained using:</p>
<div class="cell" data-hash="ch9-model_cache/html/unnamed-chunk-9_3dc37452046a07442b38e79c3332d9eb">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">Mclust</span>(x, <span class="at">modelNames =</span> <span class="st">"VVI"</span>, <span class="at">G =</span> <span class="dv">3</span>, <span class="at">prior =</span> <span class="fu">priorControl</span>())</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod, <span class="at">parameters =</span> <span class="cn">TRUE</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="do">## ---------------------------------------------------- </span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Gaussian finite mixture model fitted by EM algorithm </span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="do">## ---------------------------------------------------- </span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Mclust VVI (diagonal, varying volume and shape) model with 3 components: </span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Prior: defaultPrior() </span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="do">##  log-likelihood   n df       BIC       ICL</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="do">##       -2194.856 717 20 -4521.213 -4769.174</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Clustering table:</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="do">##   1   2   3 </span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="do">## 184 119 414 </span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="do">## Mixing probabilities:</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="do">##         1         2         3 </span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.2895147 0.1620776 0.5484078 </span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Means:</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="do">##                [,1]     [,2]     [,3]</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="do">## BehvEngmnt 3.704041 4.713234 4.257355</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="do">## CognEngmnt 2.287057 3.699530 3.017293</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="do">## EmotEngmnt 2.738969 4.733899 3.737286</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="do">## Variances:</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,1]</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="do">##            BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="do">## BehvEngmnt  0.5022148  0.0000000  0.0000000</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="do">## CognEngmnt  0.0000000  0.3909235  0.0000000</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="do">## EmotEngmnt  0.0000000  0.0000000  0.7674268</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,2]</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="do">##            BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="do">## BehvEngmnt  0.0737948  0.0000000 0.00000000</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="do">## CognEngmnt  0.0000000  0.4150514 0.00000000</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="do">## EmotEngmnt  0.0000000  0.0000000 0.05540526</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,3]</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="do">##            BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="do">## BehvEngmnt  0.2048374  0.0000000  0.0000000</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a><span class="do">## CognEngmnt  0.0000000  0.3327557  0.0000000</span></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a><span class="do">## EmotEngmnt  0.0000000  0.0000000  0.2795838</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The shown output reports some basic information about the fit, such as the maximised log-likelihood (<code>log-likelihood</code>), the number of observations (<code>n</code>), the number of estimated parameters (<code>df</code>), the BIC criterion (<code>BIC</code>), and the clustering table based on the MAP classification. The latter indicates that the clusters also vary in terms of <em>size</em>. The optional argument <code>parameters = TRUE</code> in the <code>summary()</code> function call additionally prints the estimated parameters. Observe that the <code>VVI</code> model allows variance to vary across components while fixing all covariance parameters to zero.</p>
<p>A plot showing the classification provided by the estimated model can be drawn as follows:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="at">what =</span> <span class="st">"classification"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Scatterplot matrix of engagement features with data points marked and coloured by the identified clusters, and ellipses corresponding to projections of the estimated cluster covariances.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The estimated model identifies three clusters of varying size. The third group (shown as filled green triangles) accounts for more than 50% of the observations, while the first (shown as blue filled points) and the second (shown as red open squares) account for approximately 29% and 16%, respectively. The smallest cluster is also the group with the largest engagement scores.</p>
<p>The different engagement behaviour of the three identified clusters can be shown using a latent profiles plot of the estimated means with point sizes proportional to the estimated mixing probabilities (see <a href="#fig-latent-profiles-1">Figure&nbsp;<span>9.1</span></a>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># collect estimated means</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>means <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Profile =</span> <span class="fu">factor</span>(<span class="dv">1</span><span class="sc">:</span>mod<span class="sc">$</span>G),</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">t</span>(mod<span class="sc">$</span>parameters<span class="sc">$</span>mean)) <span class="sc">|&gt;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="sc">-</span><span class="dv">1</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"Variable"</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"Mean"</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># convert variable names to factor</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>means<span class="sc">$</span>Variable <span class="ot">&lt;-</span> <span class="fu">factor</span>(means<span class="sc">$</span>Variable, </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>                         <span class="at">levels =</span> <span class="fu">colnames</span>(mod<span class="sc">$</span>data))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># add mixing probabilities corresponding to profiles</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>means <span class="ot">&lt;-</span> means <span class="sc">|&gt;</span> </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_column</span>(<span class="at">MixPro =</span> mod<span class="sc">$</span>parameters<span class="sc">$</span>pro[means<span class="sc">$</span>Profile])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>means</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-latent-profiles-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div data-pagedtable="false">

<script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["Profile"],"name":[1],"type":["fct"],"align":["left"]},{"label":["Variable"],"name":[2],"type":["fct"],"align":["left"]},{"label":["Mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["MixPro"],"name":[4],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"BehvEngmnt","3":"3.704041","4":"0.2895147"},{"1":"1","2":"CognEngmnt","3":"2.287057","4":"0.2895147"},{"1":"1","2":"EmotEngmnt","3":"2.738969","4":"0.2895147"},{"1":"2","2":"BehvEngmnt","3":"4.713234","4":"0.1620776"},{"1":"2","2":"CognEngmnt","3":"3.699530","4":"0.1620776"},{"1":"2","2":"EmotEngmnt","3":"4.733899","4":"0.1620776"},{"1":"3","2":"BehvEngmnt","3":"4.257355","4":"0.5484078"},{"1":"3","2":"CognEngmnt","3":"3.017293","4":"0.5484078"},{"1":"3","2":"EmotEngmnt","3":"3.737286","4":"0.5484078"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;1<strong>.</strong> Latent profiles plot showing estimated means with point sizes proportional to estimated mixing probabilities.</figcaption><p></p>
</figure>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the means of the latent profiles</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(means, <span class="fu">aes</span>(<span class="at">x =</span> Variable, <span class="at">y =</span> Mean,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">group =</span> Profile, </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">shape =</span> Profile, </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">color =</span> Profile)) <span class="sc">+</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">size =</span> MixPro)) <span class="sc">+</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">"Latent profiles means"</span>) <span class="sc">+</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">mclust.options</span>(<span class="st">"classPlotColors"</span>)) <span class="sc">+</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_size</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-latent-profiles-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/fig-latent-profiles-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;2<strong>.</strong> Latent profiles plot showing estimated means with point sizes proportional to estimated mixing probabilities.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The smallest cluster (Profile 2) has the highest engagement scores for all three variables. All three scores are lower for the largest cluster (Profile 3), which are all in turn lower for Profile 1. All three profiles exhibit the lowest mean scores for the cognitive engagement attribute. For Profile 2, behavioural engagement and emotional engagement scores are comparable, whereas for the other two profiles, the mean scores for this attribute are lower than those for the behaviour engagement attribute. Taken together, we could characterise profiles 1, 3, and 2 as “low”, “medium”, and “high” engagement profiles, respectively.</p>
<p>To provide a more comprehensive understanding of the results presented in the previous graph, it would be beneficial to incorporate a measure of uncertainty for the estimated means of the latent profiles. This can be achieved by resampling using the function <code>MclustBootstrap()</code> as described above:</p>
<div class="cell" data-hash="ch9-model_cache/html/unnamed-chunk-12_8a82b8185cac598c96521e2d1093fc65">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>boot <span class="ot">&lt;-</span> <span class="fu">MclustBootstrap</span>(mod, <span class="at">type =</span> <span class="st">"bs"</span>, <span class="at">nboot =</span> <span class="dv">999</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The bootstrap distribution of the mixing weights can be visualised using histograms with the code</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mgp =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">0</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boot, <span class="at">what =</span> <span class="st">"pro"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-bootstrap-weights" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/fig-bootstrap-weights-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;3<strong>.</strong> Bootstrap distribution of GMM mixture weights.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>while the bootstrap distribution of the components means can be plotted with the code</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">mgp =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">0</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(boot, <span class="at">what =</span> <span class="st">"mean"</span>, <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-bootstrap-means" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/fig-bootstrap-means-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;4<strong>.</strong> Bootstrap distribution of GMM component means.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The resulting graphs are reported in <a href="#fig-bootstrap-weights">Figure&nbsp;<span>9.3</span></a> and <a href="#fig-bootstrap-means">Figure&nbsp;<span>9.4</span></a>, where the GMM estimates are shown as dashed vertical lines, while the horizontal segments represent the percentile confidence intervals at the 95% confidence level.</p>
<p>Numerical output of the resampling-based bootstrap distributions is given by:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>sboot <span class="ot">&lt;-</span> <span class="fu">summary</span>(boot, <span class="at">what =</span> <span class="st">"ci"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>sboot</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="do">## ---------------------------------------------------------- </span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Resampling confidence intervals </span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="do">## ---------------------------------------------------------- </span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Model                      = VVI </span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="do">## Num. of mixture components = 3 </span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Replications               = 999 </span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Type                       = nonparametric bootstrap </span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Confidence level           = 0.95 </span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Mixing probabilities:</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="do">##               1          2         3</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 2.5%  0.1275702 0.09255033 0.4761326</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="do">## 97.5% 0.3872065 0.23592891 0.6845753</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Means:</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,1]</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="do">##       BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="do">## 2.5%    3.479985   1.872176   2.082263</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="do">## 97.5%   3.822700   2.441357   2.942343</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,2]</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="do">##       BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="do">## 2.5%    4.628745   3.532034   4.527568</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="do">## 97.5%   4.898591   3.929510   4.878574</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,3]</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="do">##       BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="do">## 2.5%    4.097707   2.836241   3.533040</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="do">## 97.5%   4.366235   3.145216   3.887315</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="do">## Variances:</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,1]</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="do">##       BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="do">## 2.5%   0.4090113  0.2286101  0.5467998</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="do">## 97.5%  0.7845491  0.4913383  0.9885883</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,2]</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a><span class="do">##       BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="do">## 2.5%   0.0159611  0.3256681 0.01817132</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="do">## 97.5%  0.1042114  0.5728663 0.14713752</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a><span class="do">## [,,3]</span></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="do">##       BehvEngmnt CognEngmnt EmotEngmnt</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="do">## 2.5%   0.1587247  0.2842579  0.2297413</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a><span class="do">## 97.5%  0.2788433  0.3974127  0.4077299</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The information above can then be used to plot the latent profile means accompanied by 95% confidence intervals represented as vertical bars, as illustrated in <a href="#fig-bootstrap-mean-ci-1">Figure&nbsp;<span>9.5</span></a>. The confidence intervals for the cognitive and emotional engagement attributes are noticeably wider for the “low” engagement profile.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>means <span class="ot">&lt;-</span> means <span class="sc">|&gt;</span> </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_column</span>(<span class="at">lower =</span> <span class="fu">as.vector</span>(sboot<span class="sc">$</span>mean[<span class="dv">1</span>,,]),</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">upper =</span> <span class="fu">as.vector</span>(sboot<span class="sc">$</span>mean[<span class="dv">2</span>,,]))</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>means</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-bootstrap-mean-ci-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div data-pagedtable="false">

<script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["Profile"],"name":[1],"type":["fct"],"align":["left"]},{"label":["Variable"],"name":[2],"type":["fct"],"align":["left"]},{"label":["Mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["MixPro"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["lower"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["upper"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"BehvEngmnt","3":"3.704041","4":"0.2895147","5":"3.479985","6":"3.822700"},{"1":"1","2":"CognEngmnt","3":"2.287057","4":"0.2895147","5":"1.872176","6":"2.441357"},{"1":"1","2":"EmotEngmnt","3":"2.738969","4":"0.2895147","5":"2.082263","6":"2.942343"},{"1":"2","2":"BehvEngmnt","3":"4.713234","4":"0.1620776","5":"4.628745","6":"4.898591"},{"1":"2","2":"CognEngmnt","3":"3.699530","4":"0.1620776","5":"3.532034","6":"3.929510"},{"1":"2","2":"EmotEngmnt","3":"4.733899","4":"0.1620776","5":"4.527568","6":"4.878574"},{"1":"3","2":"BehvEngmnt","3":"4.257355","4":"0.5484078","5":"4.097707","6":"4.366235"},{"1":"3","2":"CognEngmnt","3":"3.017293","4":"0.5484078","5":"2.836241","6":"3.145216"},{"1":"3","2":"EmotEngmnt","3":"3.737286","4":"0.5484078","5":"3.533040","6":"3.887315"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;5<strong>.</strong> Latent profiles plot showing estimated means with 95% bootstrap confidence intervals.</figcaption><p></p>
</figure>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(means, <span class="fu">aes</span>(<span class="at">x =</span> Variable, <span class="at">y =</span> Mean, <span class="at">group =</span> Profile, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">shape =</span> Profile, <span class="at">color =</span> Profile)) <span class="sc">+</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">size =</span> MixPro)) <span class="sc">+</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">linewidth =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper), </span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                <span class="at">linewidth =</span> <span class="fl">0.5</span>, <span class="at">width =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="st">"Latent profiles means"</span>) <span class="sc">+</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">mclust.options</span>(<span class="st">"classPlotColors"</span>)) <span class="sc">+</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_size</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>), <span class="at">guide =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-bootstrap-mean-ci-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/fig-bootstrap-mean-ci-1.png" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;6<strong>.</strong> Latent profiles plot showing estimated means with 95% bootstrap confidence intervals.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Finally, the entropy of the estimated partition, average entropy of each latent component, and average posterior probabilities are obtained via:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>probs <span class="ot">&lt;-</span> mod<span class="sc">$</span>z                    <span class="co"># posterior conditional probs</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>probs_map <span class="ot">&lt;-</span> <span class="fu">apply</span>(probs, <span class="dv">1</span>, max) <span class="co"># maximum a posteriori probs</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>clusters <span class="ot">&lt;-</span> mod<span class="sc">$</span>classification    <span class="co"># cluster assignment for each obs</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> mod<span class="sc">$</span>n                        <span class="co"># number of obs</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> mod<span class="sc">$</span>G                        <span class="co"># number of latent profiles</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Entropy:</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>E <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">sum</span>(probs <span class="sc">*</span> <span class="fu">log</span>(probs))<span class="sc">/</span>(n <span class="sc">*</span> <span class="fu">log</span>(K))</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>E</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.6890602</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Case-specific entropy contributions:</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>Ei <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">rowSums</span>(probs <span class="sc">*</span> <span class="fu">log</span>(probs))<span class="sc">/</span><span class="fu">log</span>(K)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(Ei)<span class="sc">/</span>n</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.6890602</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>df_entropy  <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">clusters =</span> <span class="fu">as.factor</span>(clusters), <span class="at">entropy =</span> Ei)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>df_entropy <span class="sc">|&gt;</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(clusters) <span class="sc">|&gt;</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">count =</span> <span class="fu">n</span>(),</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>            <span class="at">mean =</span> <span class="fu">mean</span>(entropy),</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>            <span class="at">sd =</span> <span class="fu">sd</span>(entropy),</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>            <span class="at">min =</span> <span class="fu">min</span>(entropy),</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>            <span class="at">max =</span> <span class="fu">max</span>(entropy))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-entropy-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div data-pagedtable="false">

<script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["clusters"],"name":[1],"type":["fct"],"align":["left"]},{"label":["count"],"name":[2],"type":["int"],"align":["right"]},{"label":["mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["sd"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["min"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["max"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"184","3":"0.7400597","4":"0.2392350","5":"0.3693803","6":"1.0000000"},{"1":"2","2":"119","3":"0.6898535","4":"0.2254055","5":"0.1872428","6":"0.9925918"},{"1":"3","2":"414","3":"0.6661657","4":"0.1969912","5":"0.1716497","6":"0.9738122"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;7<strong>.</strong> Entropy contributions by cluster and total entropy (dashed line).</figcaption><p></p>
</figure>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_entropy, <span class="fu">aes</span>(<span class="at">y =</span> clusters, <span class="at">x =</span> entropy,  <span class="at">fill =</span> clusters)) <span class="sc">+</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density_ridges</span>(<span class="at">stat =</span> <span class="st">"binline"</span>, <span class="at">bins =</span> <span class="dv">21</span>,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">scale =</span> <span class="fl">0.9</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span> ,<span class="at">by=</span><span class="fl">0.1</span>), </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>                     <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.05</span>)) <span class="sc">+</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">mclust.options</span>(<span class="st">"classPlotColors"</span>)) <span class="sc">+</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> E, <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Case-specific entropy contribution"</span>, </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Latent profile"</span>) <span class="sc">+</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_ridges</span>(<span class="at">center_axis_labels =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>,</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">panel.spacing =</span> <span class="fu">unit</span>(<span class="dv">1</span>, <span class="st">"lines"</span>),</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        <span class="at">strip.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">8</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-entropy-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/fig-entropy-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;8<strong>.</strong> Entropy contributions by cluster and total entropy (dashed line).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>We note that, as shown in <a href="#fig-entropy-1">Figure&nbsp;<span>9.7</span></a> and <a href="#fig-aveapp-1">Figure&nbsp;<span>9.9</span></a>, all entropy and AvePP quantities appear satisfactory from the point of view of indicating reasonably well-separated clusters.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Average posterior probabilities by cluster:</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>df_AvePP <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">clusters =</span> <span class="fu">as.factor</span>(clusters), <span class="at">pp =</span> probs_map)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>df_AvePP <span class="sc">|&gt;</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(clusters) <span class="sc">|&gt;</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">count =</span> <span class="fu">n</span>(),</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">mean =</span> <span class="fu">mean</span>(pp),</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">sd =</span> <span class="fu">sd</span>(pp),</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">min =</span> <span class="fu">min</span>(pp),</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">max =</span> <span class="fu">max</span>(pp))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-aveapp-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<div data-pagedtable="false">

<script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["clusters"],"name":[1],"type":["fct"],"align":["left"]},{"label":["count"],"name":[2],"type":["int"],"align":["right"]},{"label":["mean"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["sd"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["min"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["max"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"184","3":"0.8642495","4":"0.1602211","5":"0.5130492","6":"1.0000000"},{"1":"2","2":"119","3":"0.8582641","4":"0.1459569","5":"0.4680391","6":"0.9989691"},{"1":"3","2":"414","3":"0.8499902","4":"0.1347749","5":"0.5022190","6":"0.9956586"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;9<strong>.</strong> Average posterior probabilities by cluster.</figcaption><p></p>
</figure>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_AvePP, <span class="fu">aes</span>(<span class="at">y =</span> clusters, <span class="at">x =</span> pp,  <span class="at">fill =</span> clusters)) <span class="sc">+</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density_ridges</span>(<span class="at">stat =</span> <span class="st">"binline"</span>, <span class="at">bins =</span> <span class="dv">21</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">scale =</span> <span class="fl">0.9</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by=</span><span class="fl">0.1</span>), </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>                     <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">1.05</span>)) <span class="sc">+</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">mclust.options</span>(<span class="st">"classPlotColors"</span>)) <span class="sc">+</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"MAP probabilities"</span>, <span class="at">y =</span> <span class="st">"Latent profile"</span>) <span class="sc">+</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_ridges</span>(<span class="at">center_axis_labels =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">panel.spacing =</span> <span class="fu">unit</span>(<span class="dv">1</span>, <span class="st">"lines"</span>),</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">strip.text.x =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">8</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-aveapp-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch9-model_files/figure-html/fig-aveapp-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;10<strong>.</strong> Average posterior probabilities by cluster.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="discussion" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="discussion"><span class="header-section-number">5</span> Discussion</h2>
<p>Using a person-centered method (finite Gaussian mixture model), the present analysis uncovered the heterogeneity within the SEM engagement data by identifying three latent or unobserved clusters: low, medium, and high engagement clusters. Uncovering the latent structure could help understand individual differences among students, identify the complex multidimensional variability of a construct —engagement in our case— and possibly help personalise teaching and learning. Several studies have revealed similar patterns of engagement which —similar to the current analysis— comprise three levels that can be roughly summarised as high, moderate, and low <span class="citation" data-cites="Saqr2021 Archambault2016 Zhen2019">[<a href="#ref-Saqr2021" role="doc-biblioref">9</a>, <a href="#ref-Archambault2016" role="doc-biblioref">44</a>, <a href="#ref-Zhen2019" role="doc-biblioref">45</a>]</span>. The heterogeneity of engagement has been demonstrated in longitudinal studies, in both face-to-face settings as well as online engagement <span class="citation" data-cites="Saqr2021">[<a href="#ref-Saqr2021" role="doc-biblioref">9</a>]</span>. Furthermore, the association between engagement and performance has been demonstrated to vary by achievement level, time of the year, as well as engagement state; that is, high achievers may at some point in their program descend to lower engagement states and still continue to have higher achievement <span class="citation" data-cites="Saqr2023-if">[<a href="#ref-Saqr2023-if" role="doc-biblioref">3</a>]</span>. Such patterns, variability, and individual differences are not limited to engagement, but has been reported for almost every major disposition in education psychology <span class="citation" data-cites="Hickendorff2018-kt">[<a href="#ref-Hickendorff2018-kt" role="doc-biblioref">2</a>]</span>.</p>
<p>On a general level, heterogeneity has been a hot topic in recent educational literature. Several calls have been voiced to adopt methods that capture different patterns or subgroups within students’ behavior or functioning. Assuming that there is “an average” pattern that represents the entirety of student populations requires the measured construct to have the same causal mechanism, same development pattern, and affect students in exactly the same way. The average assumption is of course impossible and has been proven inaccurate across a vast number of studies (e.g., <span class="citation" data-cites="Hickendorff2018-kt">[<a href="#ref-Hickendorff2018-kt" role="doc-biblioref">2</a>]</span> and <span class="citation" data-cites="Tormanen2022-ux">[<a href="#ref-Tormanen2022-ux" role="doc-biblioref">4</a>]</span>). Since heterogeneity is prevalent in psychological, behavioral, and physiological human data, person-centered methods will remain a very important tool for researchers <span class="citation" data-cites="Bryan2021">[<a href="#ref-Bryan2021" role="doc-biblioref">46</a>]</span>.</p>
<p>Person-centered methods can be grouped into algorithmic clustering methods on one hand and the model-based clustering paradigm on the other, with the former being more traditional and the latter being more novel in the learning analytics literature. The analysis of the SEM data centered here on the model-based approach, specifically the finite Gaussian mixture model framework. The <code>mclust</code> package enabled such models to be easily fitted and this framework exhibits many advantages over traditional clustering algorithms which rely on dissimilarity-based heuristics. Firstly, the likelihood-based underpinnings enable the selection of the optimal model using principled statistical model selection criteria. In particular, it is noteworthy in the present analysis that the model selection procedure was not limited to three-cluster solutions: mixtures with fewer or greater than three clusters were evaluated and the three-cluster solution —supported by previous studies in education research— was identified as optimal according to the BIC. Secondly, the parsimonious modelling of the covariance structures provides the flexibility to model clusters with different geometric characteristics. In particular, the clusters in the present analysis, whereby each group is described by a single Gaussian component with varying volume and shape, but the same orientation aligned with the coordinate axes are more flexible than the spherical, Euclidean distance-based clusters obtainable under the <span class="math inline">\(k\)</span>-means algorithm. Thirdly, the models relax the assumption that each observation is associated with exactly one cluster and yields informative cluster-membership probabilities for each observation, which can be used to compute useful diagnostics such as entropies and average posterior probabilities which are unavailable under so-called “hard” clustering frameworks. Finally, the <code>mclust</code> package facilitates simple summaries and visualisations of the resulting clusters and cluster-specific parameter estimates.</p>
<p>That being said, there are a number of methodological limitations of the GMM framework to be aware of in other settings. Firstly, and most obviously, such models are inappropriate for clustering categorical or mixed-type variables. For clustering longitudinal categorical sequences, such as those in Chapter 10 <span class="citation" data-cites="Saqr2024-tv">[<a href="#ref-Saqr2024-tv" role="doc-biblioref">47</a>]</span>, model-based approaches are provided by the mixtures of exponential-distance models framework of <span class="citation" data-cites="Murphy2021">[<a href="#ref-Murphy2021" role="doc-biblioref">48</a>]</span> (and related <code>MEDseq</code> R package) and the mixtures of hidden Markov models framework of <span class="citation" data-cites="seqHMM2019">[<a href="#ref-seqHMM2019" role="doc-biblioref">49</a>]</span> (and related <code>seqHMM</code> package; see Chapter 12 <span class="citation" data-cites="Helske2024-lq">[<a href="#ref-Helske2024-lq" role="doc-biblioref">50</a>]</span>). Regarding mixed-type variables, <span class="citation" data-cites="McParland2016">[<a href="#ref-McParland2016" role="doc-biblioref">51</a>]</span> provide a model-based framework (and the related <code>clustMD</code> package).</p>
<p>Secondly, the one-to-one correspondence typically assumed between component distributions and clusters is not always the case <span class="citation" data-cites="Hennig2010">[<a href="#ref-Hennig2010" role="doc-biblioref">52</a>]</span>. This is only true if the underlying true component densities are Gaussian. When the assumption of component-wise normality is not satisfied, the performance of such models will deteriorate as more components are required to fit the data well. However, even for continuous data, GMMs tend to overestimate the number of clusters when the assumption of normality is violated. Two strategies for dealing with this are provided by the <code>mclust</code> package, one based on combining Gaussian mixture components according to an entropy criterion, and one based on a adding a so-called “noise component” —represented by a uniform distribution— to the mixture. The noise component captures outliers which do not fit the prevailing patterns of Gaussian clusters, which would otherwise be assigned to (possibly many) small clusters and minimises their deleterious effect on parameter estimation for the other, more defined clusters. Further details of combining components and adding a noise component can be found in <span class="citation" data-cites="mclust:book:2023">[<a href="#ref-mclust:book:2023" role="doc-biblioref">30</a>]</span>. Alternatively, mixture models which depart from normality have been an active area of research in model-based clustering in recent years. Such approaches —some of which are available in the R package <code>mixture</code> <span class="citation" data-cites="mixture2022">[<a href="#ref-mixture2022" role="doc-biblioref">53</a>]</span>— replace the underlying Gaussian component distributions with e.g., generalised hyperbolic distributions, the multivariate <span class="math inline">\(t\)</span> distribution, and the multivarate skew-<span class="math inline">\(t\)</span> distribution.</p>
<p>A third main limitation of GMMs is their ineffectiveness in high-dimensional settings, when the data dimension <span class="math inline">\(d\)</span> is comparable to or even greater than <span class="math inline">\(n\)</span>. Among the 14 parsimonious parameterisations available in <code>mclust</code>, only models with diagonal covariance structures are tractable when <span class="math inline">\(n \le p\)</span>. Incorporating factor-analytic covariance decompositions in so-called finite Gaussian mixtures of factor analysers have been proposed for addressing this issue <span class="citation" data-cites="Ghahramani1996 McLachlan2003">[<a href="#ref-Ghahramani1996" role="doc-biblioref">54</a>, <a href="#ref-McLachlan2003" role="doc-biblioref">55</a>]</span>. Imposing constraints on the parameters of such factor-analytic structures in the component covariance matrices in the spirit of <code>mclust</code> leads to another family of parsimonious Gaussian mixture models <span class="citation" data-cites="McNicholas2008">[<a href="#ref-McNicholas2008" role="doc-biblioref">56</a>]</span>, which are implemented in the R package <code>pgmm</code>. Model selection becomes increasingly difficult with such models, given the need to choose both the optimal number of mixture components and the optimal number of latent factors (as well as the covariance parameterisation, in the case of <code>pgmm</code>). Infinite mixtures of infinite factor analysers —implemented in the R package <code>IMIFA</code>— are a recent, Bayesian extension which enable automatic inference of the number of components and the numbers of cluster-specific latent factors <span class="citation" data-cites="Murphy2020">[<a href="#ref-Murphy2020" role="doc-biblioref">57</a>]</span>.</p>
<p>Another recent extension, building directly on the 14 models from <code>mclust</code>, is the MoEClust model family of <span class="citation" data-cites="MoEClust2020">[<a href="#ref-MoEClust2020" role="doc-biblioref">58</a>]</span> and the associated <code>MoEClust</code> R package, which closely mimics its syntax. MoEClust effectively embeds Gaussian parsimonious clustering models in the mixtures of experts framework, enabling additional sources of heterogeneity in the form of covariates to be incorporated directly in the clustering model, to guide the construction of the clusters. Either, neither, or both the mixing proportions and/or component mean parameters can be modelled as functions of these covariates. The former is perhaps particularly appealing, given its analogous equivalence to latent profile <em>regression</em> <span class="citation" data-cites="Dayton1988">[<a href="#ref-Dayton1988" role="doc-biblioref">59</a>]</span>. Hypothetically, assuming information on the gender and age of the students in the present analysis was available, such covariates would influence the probabilities of cluster membership under such a model, while the correspondence thereafter between the parameters of the component distributions and the clusters would have the same interpretation as per standard LPA models.</p>


</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-Howard2018-iv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Howard MC, Hoffman ME (2018) <span>Variable-Centered</span>, <span>Person-Centered</span>, and <span>Person-Specific</span> approaches: <span>W</span>here theory meets the method. Organizational Research Methods 21:846–876. https://doi.org/<a href="https://doi.org/10.1177/1094428117744021">10.1177/1094428117744021</a></div>
</div>
<div id="ref-Hickendorff2018-kt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Hickendorff M, Edelsbrunner PA, McMullen J, Schneider M, Trezise K (2018) Informative tools for characterizing individual differences in learning: <span>L</span>atent class, latent profile, and latent transition analysis. Learning and Individual Differences 66:4–15. https://doi.org/<a href="https://doi.org/10.1016/j.lindif.2017.11.001">10.1016/j.lindif.2017.11.001</a></div>
</div>
<div id="ref-Saqr2023-if" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Saqr M, López-Pernas S, Helske S, Hrastinski S (2023) The longitudinal association between engagement and achievement varies by time, students’ subgroups, and achievement state: <span>A</span> full program study. Computers &amp; Education 199:104787. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2023.104787">10.1016/j.compedu.2023.104787</a></div>
</div>
<div id="ref-Tormanen2022-ux" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Törmänen, Järvenoja, Saqr, Malmberg, others (2022) A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education 7: https://doi.org/<a href="https://doi.org/10.3389/feduc.2022.866612">10.3389/feduc.2022.866612</a></div>
</div>
<div id="ref-saqr2023modelling" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Saqr M (2023) Modelling within-person idiographic variance could help explain and individualize learning. British Journal of Educational Technology</div>
</div>
<div id="ref-Fraley:Raftery:2002" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Fraley C, Raftery AE (2002) Model-based clustering, discriminant analysis, and density estimation. Journal of the American Statistical Association 97:611–631. https://doi.org/<a href="https://doi.org/10.1198/016214502760047131">10.1198/016214502760047131</a></div>
</div>
<div id="ref-Rpkg:mclust" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Fraley C, Raftery AE, Scrucca L (2023) <a href="https://CRAN.R-project.org/package=mclust"><span class="nocase">mclust</span>: <span>G</span>aussian mixture modelling for model-based clustering, classification, and density estimation</a></div>
</div>
<div id="ref-Rstat" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">R Core Team (2023) <a href="https://www.R-project.org/">R: <span>A</span> language and environment for statistical computing</a>. <span>R Foundation for Statistical Computing</span>, Vienna, Austria</div>
</div>
<div id="ref-Saqr2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2021) The longitudinal trajectories of online engagement over a full program. Computers &amp; Education 175:104325. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2021.104325">10.1016/j.compedu.2021.104325</a></div>
</div>
<div id="ref-Yu2022-fr" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Yu J, Huang C, He T, Wang X, Zhang L (2022) Investigating students’ emotional self-efficacy profiles and their relations to self-regulation, motivation, and academic performance in online learning contexts: <span>A</span> person-centered approach. Education and Information Technologies 27:11715–11740. https://doi.org/<a href="https://doi.org/10.1007/s10639-022-11099-0">10.1007/s10639-022-11099-0</a></div>
</div>
<div id="ref-Saqr2022-fp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2022) How <span>CSCL</span> roles emerge, persist, transition, and evolve over time: <span>A</span> four-year longitudinal study. Computers &amp; Education 189:104581. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2022.104581">10.1016/j.compedu.2022.104581</a></div>
</div>
<div id="ref-Cheng2023-fc" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Cheng S, Huang J-C, Hebert W (2023) Profiles of vocational college students’ achievement emotions in online learning environments: <span>A</span>ntecedents and outcomes. Computers in Human Behaviour 138:107452. https://doi.org/<a href="https://doi.org/10.1016/j.chb.2022.107452">10.1016/j.chb.2022.107452</a></div>
</div>
<div id="ref-Hoi2023-sz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Hoi VN (2023) Transitioning from school to university: <span>A</span> person-oriented approach to understanding first-year students’ classroom engagement in higher education. Educational Review 1–21. https://doi.org/<a href="https://doi.org/10.1080/00131911.2022.2159935">10.1080/00131911.2022.2159935</a></div>
</div>
<div id="ref-Scheidt2021-sg" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Scheidt M, Godwin A, Berger E, Chen J, Self BP, Widmann JM, Gates AQ (2021) Engineering students’ noncognitive and affective factors: <span>G</span>roup differences from cluster analysis. Journal of Engineering Education 110:343–370. https://doi.org/<a href="https://doi.org/10.1002/jee.20386">10.1002/jee.20386</a></div>
</div>
<div id="ref-Zhang2023-zt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">Zhang Y, Paquette L, Pinto JD, Liu Q, Fan AX (2023) Combining latent profile analysis and programming traces to understand novices’ differences in debugging. Education and Information Technologies 28:4673–4701. https://doi.org/<a href="https://doi.org/10.1007/s10639-022-11343-7">10.1007/s10639-022-11343-7</a></div>
</div>
<div id="ref-Hennig2015" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Hennig C (2015) What are the true clusters? Pattern Recognition Letters 64:53–62</div>
</div>
<div id="ref-Everitt2011" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Everitt BS, Landau S, Leese M, Stahl D (2011) <span>Cluster Analysis</span>, Fifth. John Wiley &amp; Sons, New York, NY, USA</div>
</div>
<div id="ref-Fraley:1998" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Fraley C (1998) Algorithms for model-based <span>G</span>aussian hierarchical clustering. <span>SIAM</span> Journal on Scientific Computing 20:270–281. https://doi.org/<a href="https://doi.org/10.1137/S1064827596311451">10.1137/S1064827596311451</a></div>
</div>
<div id="ref-McLachlan:Peel:2000" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">McLachlan GJ, Peel D (2000) Finite mixture models. John Wiley &amp; Sons, New York, NY, USA</div>
</div>
<div id="ref-Dempster:Laird:Rubin:1977" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Dempster AP, Laird NM, Rubin DB (1977) Maximum likelihood from incomplete data via the <span>EM</span> algorithm (with discussion). Journal of the Royal Statistical Society: Series B (Statistical Methodology) 39:1–38. https://doi.org/<a href="https://doi.org/10.1111/j.2517-6161.1977.tb01600.x">10.1111/j.2517-6161.1977.tb01600.x</a></div>
</div>
<div id="ref-Spearman:1904" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Spearman C (1904) <span><span>“General Intelligence,”</span></span> objectively determined and measured. The American Journal of Psychology 15:201–292. https://doi.org/<a href="https://doi.org/10.2307/1412107">10.2307/1412107</a></div>
</div>
<div id="ref-Joreskog:1970" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline">Jöreskog KG (1970) A general method for analysis of covariance structures. Biometrika 57:239–251</div>
</div>
<div id="ref-Blei:Ng:Jordan:2003" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline">Blei DM, Ng AY, Jordan MI (2003) Latent <span>D</span>irichlet allocation. Journal of Machine Learning Research 3:993–1022</div>
</div>
<div id="ref-Zucchini:MacDonald:Langrock:2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline">Zucchini W, MacDonald IL, Langrock R (2016) Hidden <span>M</span>arkov models for time series: <span>A</span>n introduction using <span>R</span>. Chapman &amp; Hall/CRC Press, London, UK</div>
</div>
<div id="ref-Bartolucci:Farcomeni:Pennoni:2012" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline">Bartolucci F, Farcomeni A, Pennoni F (2012) Latent <span>M</span>arkov models for longitudinal data. Chapman &amp; Hall/CRC Press</div>
</div>
<div id="ref-Bartholomew:Knott:Moustaki:2011" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline">Bartholomew DJ, Knott M, Moustaki I (2011) Latent variable models and factor analysis: <span>A</span> unified approach, 3rd ed. John Wiley &amp; Sons, Chichester, UK</div>
</div>
<div id="ref-Rosenberg:Beymer:Anderson:VanLissa:Schmidt:2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline">Rosenberg JM, Beymer PN, Anderson DJ, Van Lissa CJ, Schmidt JA (2018) Tidy<span>LPA</span>: <span>A</span>n <span>R</span> package to easily carry out latent profile analysis (<span>LPA</span>) using open-source or commercial software. Journal of Open Source Software 3:978. https://doi.org/<a href="https://doi.org/10.21105/joss.00978">10.21105/joss.00978</a></div>
</div>
<div id="ref-Banfield:Raftery:1993" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline">Banfield J, Raftery AE (1993) Model-based <span>G</span>aussian and non-<span>G</span>aussian clustering. Biometrics 49:803–821. https://doi.org/<a href="https://doi.org/10.2307/2532201">10.2307/2532201</a></div>
</div>
<div id="ref-Celeux:Govaert:1995" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline">Celeux G, Govaert G (1995) <span>G</span>aussian parsimonious clustering models. Pattern Recognition 28:781–793. https://doi.org/<a href="https://doi.org/10.1016/0031-3203(94)00125-6">10.1016/0031-3203(94)00125-6</a></div>
</div>
<div id="ref-mclust:book:2023" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline">Scrucca L, Fraley C, Murphy TB, Raftery AE (2023) <a href="https://doi.org/10.1201/9781003277965">Model-based clustering, classification, and density estimation using <span class="nocase">mclust</span> in <span>R</span></a>. Chapman &amp; Hall/CRC Press, London, UK</div>
</div>
<div id="ref-McLachlan:Krishnan:2008" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline">McLachlan GJ, Krishnan T (2008) The <span>EM</span> algorithm and extensions, 2nd ed. Wiley-Interscience, Hoboken, NJ, USA</div>
</div>
<div id="ref-Schwarz:1978" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline">Schwarz G (1978) Estimating the dimension of a model. The Annals of Statistics 6:461–464. https://doi.org/<a href="https://doi.org/10.1214/aos/1176344136">10.1214/aos/1176344136</a></div>
</div>
<div id="ref-Biernacki:Celeux:Govaert:2000" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">33. </div><div class="csl-right-inline">Biernacki C, Celeux G, Govaert G (2000) Assessing a mixture model for clustering with the integrated completed likelihood. <span>IEEE</span> Transactions on Pattern Analysis and Machine Intelligence 22:719–725</div>
</div>
<div id="ref-NylundGibsonChoi2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">34. </div><div class="csl-right-inline">Nylund-Gibson K, Choi AY (2018) Ten frequently asked questions about latent class analysis. Translational Issues in Psychological Science 4:440–461</div>
</div>
<div id="ref-Scrucca:etal:2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">35. </div><div class="csl-right-inline">Scrucca L, Fop M, Murphy TB, Raftery AE (2016) <span class="nocase">mclust</span> 5: <span>C</span>lustering, classification and density estimation using <span>G</span>aussian finite mixture models. <span>The R Journal</span> 8:205–233. https://doi.org/<a href="https://doi.org/10.32614/RJ-2016-021">10.32614/RJ-2016-021</a></div>
</div>
<div id="ref-Fraley:Raftery:2007a" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">36. </div><div class="csl-right-inline">Fraley C, Raftery AE (2007) Bayesian regularization for normal mixture estimation and model-based clustering. Journal of Classification 24:155–181</div>
</div>
<div id="ref-Basford:Greenway:McLachlan:Peel:1997" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">37. </div><div class="csl-right-inline">Basford KE, Greenway DR, McLachlan GJ, Peel D (1997) Standard errors of fitted component means of normal mixtures. Computational Statistics 12:1–18</div>
</div>
<div id="ref-OHagan:Murphy:Scrucca:Gormley:2019" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">38. </div><div class="csl-right-inline">O’Hagan A, Murphy TB, Scrucca L, Gormley IC (2019) Investigation of parameter uncertainty in clustering using a <span>G</span>aussian mixture model via jackknife, bootstrap and weighted likelihood bootstrap. Computational Statistics 34:1779–1813. https://doi.org/<a href="https://doi.org/10.1007/s00180-019-00897-9">10.1007/s00180-019-00897-9</a></div>
</div>
<div id="ref-Efron:1979" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">39. </div><div class="csl-right-inline">Efron B (1979) Bootstrap methods: <span>A</span>nother look at the jackknife. The Annals of Statistics 7:1–26</div>
</div>
<div id="ref-Rubin:1981" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">40. </div><div class="csl-right-inline">Rubin DB (1981) The <span>B</span>ayesian bootstrap. The Annals of Statistics 9:130–134</div>
</div>
<div id="ref-Newton:Raftery:1994" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">41. </div><div class="csl-right-inline">Newton MA, Raftery AE (1994) Approximate bayesian inference with the weighted likelihood bootstrap (with discussion). Journal of the Royal Statistical Society: Series B (Statistical Methodology) 56:3–48</div>
</div>
<div id="ref-Cover:Thomas:2006" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">42. </div><div class="csl-right-inline">Cover TM, Thomas JA (2006) Elements of information theory, 2nd ed. John Wiley &amp; Sons, New York, NY, USA</div>
</div>
<div id="ref-Celeux:Soromenho:1996" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">43. </div><div class="csl-right-inline">Celeux G, Soromenho G (1996) An entropy criterion for assessing the number of clusters in a mixture model. Journal of Classification 13:195–212</div>
</div>
<div id="ref-Archambault2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">44. </div><div class="csl-right-inline">Archambault I, Dupéré V (2016) Joint trajectories of behavioral, affective, and cognitive engagement in elementary school. The Journal of Educational Research 110:188–198. https://doi.org/<a href="https://doi.org/10.1080/00220671.2015.1060931">10.1080/00220671.2015.1060931</a></div>
</div>
<div id="ref-Zhen2019" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">45. </div><div class="csl-right-inline">Zhen R, Liu R-D, Wang M-T, Ding Y, Jiang R, Fu X, Sun Y (2019) Trajectory patterns of academic engagement among elementary school students: <span>T</span>he implicit theory of intelligence and academic self-efficacy matters. British Journal of Educational Psychology 90:618–634. https://doi.org/<a href="https://doi.org/10.1111/bjep.12320">10.1111/bjep.12320</a></div>
</div>
<div id="ref-Bryan2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">46. </div><div class="csl-right-inline">Bryan CJ, Tipton E, Yeager DS (2021) Behavioural science is unlikely to change the world without a heterogeneity revolution. Nature Human Behaviour 5:980–989. https://doi.org/<a href="https://doi.org/10.1038/s41562-021-01143-3">10.1038/s41562-021-01143-3</a></div>
</div>
<div id="ref-Saqr2024-tv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">47. </div><div class="csl-right-inline">Saqr M, López-Pernas S, Helske S, Durand M, Murphy K, Studer M, Ritschard G (2024) Sequence analysis in education: Principles, technique, and tutorial with r. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using <span>R</span>. Springer</div>
</div>
<div id="ref-Murphy2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">48. </div><div class="csl-right-inline">Murphy K, Murphy TB, Piccarreta R, Gormley IC (2021) Clustering longitudinal life-course sequences using mixtures of exponential-distance models. Journal of the Royal Statistical Society: Series A (Statistics in Society) 184:1414–1451. https://doi.org/<a href="https://doi.org/10.1111/rssa.12712">10.1111/rssa.12712</a></div>
</div>
<div id="ref-seqHMM2019" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">49. </div><div class="csl-right-inline">Helske S, Helske J (2019) <span>M</span>ixture hidden <span>M</span>arkov models for sequence data: <span>T</span>he <span class="nocase">seqHMM</span> package in <span>R</span>. Journal of Statistical Software 88:1–32</div>
</div>
<div id="ref-Helske2024-lq" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">50. </div><div class="csl-right-inline">Helske J, Helske S, Saqr M, López-Pernas S, Murphy K (2024) A modern approach to transition analysis and process mining with markov models: A tutorial with <span>R</span>. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using <span>R</span>. Springer, pp in–press</div>
</div>
<div id="ref-McParland2016" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">51. </div><div class="csl-right-inline">McParland D, Gormley IC (2016) <span>M</span>odel based clustering for mixed data: <span class="nocase">clustMD</span>. Advances in Data Analysis and Classification 10:155–169</div>
</div>
<div id="ref-Hennig2010" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">52. </div><div class="csl-right-inline">Hennig C (2010) Methods for merging <span>G</span>aussian mixture components. Advances in Data Analysis and Classification 4:3–34</div>
</div>
<div id="ref-mixture2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">53. </div><div class="csl-right-inline">Pocuca N, Browne RP, McNicholas PD (2022) <a href="https://CRAN.R-project.org/package=mixture"><span class="nocase">mixture</span>: <span>M</span>ixture models for clustering and classification</a></div>
</div>
<div id="ref-Ghahramani1996" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">54. </div><div class="csl-right-inline">Ghahramani Z, Hinton GE (1996) The <span>EM</span> algorithm for mixtures of factor analyzers. Department of Computer Science, University of Toronto</div>
</div>
<div id="ref-McLachlan2003" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">55. </div><div class="csl-right-inline">McLachlan GJ, Peel D, Bean RW (2003) Modelling high-dimensional data by mixtures of factor analyzers. Computational Statistics &amp; Data Analysis 41:379–388</div>
</div>
<div id="ref-McNicholas2008" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">56. </div><div class="csl-right-inline">McNicholas PD, Murphy TB (2008) <span class="nocase">Parsimonious <span>G</span>aussian mixture models</span>. Statistics and Computing 18:285–296</div>
</div>
<div id="ref-Murphy2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">57. </div><div class="csl-right-inline">Murphy K, Viroli C, Gormley IC (2020) Infinite mixtures of infinite factor analysers. Bayesian Analysis 15:937–963</div>
</div>
<div id="ref-MoEClust2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">58. </div><div class="csl-right-inline">Murphy K, Murphy TB (2020) Gaussian parsimonious clustering models with covariates and a noise component. Advances in Data Analysis and Classification 14:293–325. https://doi.org/<a href="https://doi.org/10.1007/s11634-019-00373-8">10.1007/s11634-019-00373-8</a></div>
</div>
<div id="ref-Dayton1988" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">59. </div><div class="csl-right-inline">Dayton CM, Macready GB (1988) <span>C</span>oncomitant-variable latent-class models. Journal of the American Statistical Association 83:173–178</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/ch08-clustering/ch8-clus.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Dissimilarity-based Clustering</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/ch10-sequence-analysis/ch10-seq.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequence analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
  </div>
</footer>
<script>
  document.querySelector(".quarto-title").innerHTML =  /*'<div class="badge bs-warning bg-warning text-dark" style="float:right;">Pre-print</div>' + */ document.querySelector(".quarto-title").innerHTML
  var keywords = document.querySelector('meta[name="keywords"]')
  if (keywords && keywords.content) {
    document.getElementById("title-block-header").innerHTML = document.getElementById("title-block-header").innerHTML + 
      '<div class="abstract"><div class="abstract-title">Keywords</div><div class="quarto-title-meta-contents"><p>'+
      keywords.content +
      '</p></div></div>'
  }
  function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(newNode, referenceNode.nextSibling);
  }
  var authors = document.querySelectorAll('meta[name="author"]')
  var firstpage = document.querySelector('meta[name="citation_firstpage"]').content
  var lastpage = document.querySelector('meta[name="citation_lastpage"]').content
  var doi = document.querySelector('meta[name="citation_doi"]').content
  if (authors) {
    var authorlist = Array.from(authors).map(e=>e.content).reduce((accum, curr) =>  accum + curr + ", ", "","").replace(/\,\s$/,"")
    var citt = `<div class="card border-primary mb-3" style=;">
      <div class="card-header bg-primary">To cite this chapter</div>
      <div class="card-body small">
        <p class="card-text">${authorlist} (2024).
        <b>${document.getElementsByClassName("chapter-title")[0].innerText}</b>. 
        In M. Saqr & S. López-Pernas (Eds.), <i>Learning analytics methods and tutorials: A practical guide using R</i> &nbsp;
         (pp. ${firstpage}-${lastpage}).Springer, Cham. doi: <a href="https://doi.org/${doi}">${doi}</a></p>
      </div>
    </div>`;
    insertAfter(document.getElementsByTagName("HEADER")[1],new DOMParser().parseFromString(citt, 'text/html').body.childNodes[0])
  }
</script>



</body></html>
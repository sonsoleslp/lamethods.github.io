<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mohammed Saqr">
<meta name="author" content="Ahmed Tlili">
<meta name="author" content="Sonsoles López-Pernas">
<meta name="keywords" content="learning analytics, automated machine learning, precision education, idiographic analysis, explainable artificial intelligence">

<title>Advanced learning analytics methods - 22&nbsp; Automating Individualized Machine Learning and AI Prediction using AutoML: The Case of Idiographic Predictions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/ch21-mle/ch21-mle.html" rel="prev">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y4VBV3J9WD"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y4VBV3J9WD', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  

<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>


<meta name="twitter:title" content="Advanced learning analytics methods - 22&nbsp; Automating Individualized Machine Learning and AI Prediction using AutoML: The Case of Idiographic Predictions">
<meta name="twitter:description" content="This chapter introduces a tutorial on using Automated Machine Learning (AutoML) to automate and scale predictive modeling in education.">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="[22]{.chapter-number}&nbsp; [Automating Individualized Machine Learning and AI Prediction using AutoML: The Case of Idiographic Predictions]{.chapter-title}">
<meta name="citation_abstract" content="This chapter introduces a tutorial on using Automated Machine Learning (AutoML) to automate and scale predictive modeling in education. In particular, we illustrate the usefulness of AutoML for idiographic analysis, where each individual student has their own particular model fitted from their own individual data. We demonstrate how AutoML simplifies the ML pipeline, enabling the creation of individually optimized models for multiple datasets Moreover, we illustrate how to apply explainable artificial intelligence techniques to automate the interpretation of the main model predictors, offering a view of the variables that matter. The complete pipeline demonstrated in this tutorial holds potential to provide automated real-time insights based on idiographic analysis in a transparent and trustable way.">
<meta name="citation_keywords" content="learning analytics, automated machine learning, precision education, idiographic analysis, explainable artificial intelligence">
<meta name="citation_author" content="Mohammed Saqr">
<meta name="citation_author" content="Ahmed Tlili">
<meta name="citation_author" content="Sonsoles López-Pernas">
<meta name="citation_fulltext_html_url" content="https://lamethods.github.io/ch22-automl.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=The investigation of student’s online learning adaptability level prediction based on AutoML;,citation_abstract=In the rapidly evolving realm of online education, developing an accurate method for assessing students’ adaptability is of paramount importance to the educational field. It enables educational institutions to better understand student performance and needs, allowing for the provision of timely support and resources. Therefore, this study employed Automated Machine Learning (AutoML) technology to predict students’ adaptability to online learning. Utilizing Baidu’s AI development platform named EasyDL, this research conducted an in-depth analysis of 1, 205 data samples provided by the Kaggle platform. The model’s performance was evaluated using key indicators e.g. accuracy, precision, recall, and F1-score, and it was compared with traditional machine learning methods to establish its superiority. The experimental results demonstrate that AutoML technology effectively predicts students’ adaptability to online learning, with the model achieving an accuracy rate of 90.9%. While there is still room for improvement in predicting high adaptability levels in students, the model significantly underscored the importance of critical features such as age, location, type of educational institution, and class duration. These findings not only validate the efficacy of AutoML technology in the educational sector but also lay an empirical foundation for future research.;,citation_author=Yan Zhao;,citation_author=Pengbo Wang;,citation_publication_date=2024-02;,citation_cover_date=2024-02;,citation_year=2024;,citation_fulltext_html_url=https://ieeexplore.ieee.org/abstract/document/10485809?casa_token=s-UFJLX5j8sAAAAA:-n7Oc6LnTtQO6711g6kyUijFMddJI2xHU0nBjMouikK5D13A4Zb1VFE64Q2IUCzXsHLw-NIWSgDstQ;,citation_doi=10.1109/eebda60612.2024.10485809;,citation_volume=2;,citation_conference_title=2024 IEEE 3rd international conference on electrical engineering, big data and algorithms (EEBDA);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=AutoML feature engineering for student modeling yields high accuracy, but limited interpretability;,citation_abstract=Automatic machine learning (AutoML) methods automate the time-consuming, feature-engineering process so that researchers produce accurate student models more quickly and easily. In this paper, we compare two AutoML feature engineering methods in the context of the National Assessment of Educational Progress (NAEP) data mining competition. The methods we compare, Featuretools and TSFRESH (Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests), have rarely been applied in the context of student interaction log data. Thus, we address research questions regarding the accuracy of models built with AutoML features, how AutoML feature types compare to each other and to expert-engineered features, and how interpretable the features are. Additionally, we developed a novel feature selection method that addresses problems applying AutoML feature engineering in this context, where there were many heterogeneous features (over 4,000) and relatively few students. Our entry to the NAEP competition placed 3rd overall on the final held-out dataset and 1st on the public leaderboard, with a final Cohen’s kappa = .212 and area under the receiver operating characteristic curve (AUC) = .665 when predicting whether students would manage their time effectively on a math assessment. We found that TSFRESH features were significantly more effective than either Featuretools features or expert-engineered features in this context; however, they were also among the most difficult features to interpret based on a survey of six experts’ judgments. Finally, we discuss the tradeoffs between effort and interpretability that arise in AutoML-based student modeling.;,citation_author=Nigel Bosch;,citation_publication_date=2021-08;,citation_cover_date=2021-08;,citation_year=2021;,citation_fulltext_html_url=https://jedm.educationaldatamining.org/index.php/JEDM/article/view/501;,citation_issue=2;,citation_doi=10.5281/ZENODO.5275314;,citation_issn=2157-2100,2157-2100;,citation_volume=13;,citation_journal_title=JEDM;,citation_publisher=Zenodo;">
<meta name="citation_reference" content="citation_title=Assisting educational analytics with AutoML functionalities;,citation_abstract=The plethora of changes that have taken place in policy formulations on higher education in recent years in Greece has led to unification, the abolition of departments or technological educational institutions (TEI) and mergers at universities. As a result, many students are required to complete their studies in departments of the abolished TEI. Dropout or a delay in graduation is a significant problem that results from newly joined students at the university, in addition to the provision of studies. There are various reasons for this, with student performance during studies being one of the major contributing factors. This study was aimed at predicting the time required for weak students to pass their courses so as to allow the university to develop strategic programs that will help them improve performance and graduate in time. This paper presents various components of educational data mining incorporating a new state-of-the-art strategy, called AutoML, which is used to find the best models and parameters and is capable of predicting the length of time required for students to pass their courses using their past course performance and academic information. A dataset of 23,687 “Computer Networking” module students was used to train and evaluate the classification of a model developed in the KNIME Analytics (open source) data science platform. The accuracy of the model was measured using well-known evaluation criteria, such as precision, recall, and F-measure. The model was applied to data related to three basic courses and correctly predicted approximately 92% of students’ performance and, specifically, students who are likely to drop out or experience a delay before graduating.;,citation_author=Spyridon Garmpis;,citation_author=Manolis Maragoudakis;,citation_author=Aristogiannis Garmpis;,citation_publication_date=2022-06;,citation_cover_date=2022-06;,citation_year=2022;,citation_fulltext_html_url=https://www.mdpi.com/2073-431X/11/6/97;,citation_issue=6;,citation_doi=10.3390/computers11060097;,citation_issn=2073-431X,2073-431X;,citation_volume=11;,citation_journal_title=Computers;,citation_publisher=MDPI AG;">
<meta name="citation_reference" content="citation_title=The investigation of student’s online learning adaptability level prediction based on AutoML;,citation_abstract=In the rapidly evolving realm of online education, developing an accurate method for assessing students’ adaptability is of paramount importance to the educational field. It enables educational institutions to better understand student performance and needs, allowing for the provision of timely support and resources. Therefore, this study employed Automated Machine Learning (AutoML) technology to predict students’ adaptability to online learning. Utilizing Baidu’s AI development platform named EasyDL, this research conducted an in-depth analysis of 1, 205 data samples provided by the Kaggle platform. The model’s performance was evaluated using key indicators e.g. accuracy, precision, recall, and F1-score, and it was compared with traditional machine learning methods to establish its superiority. The experimental results demonstrate that AutoML technology effectively predicts students’ adaptability to online learning, with the model achieving an accuracy rate of 90.9%. While there is still room for improvement in predicting high adaptability levels in students, the model significantly underscored the importance of critical features such as age, location, type of educational institution, and class duration. These findings not only validate the efficacy of AutoML technology in the educational sector but also lay an empirical foundation for future research.;,citation_author=Yan Zhao;,citation_author=Pengbo Wang;,citation_publication_date=2024-02;,citation_cover_date=2024-02;,citation_year=2024;,citation_fulltext_html_url=https://ieeexplore.ieee.org/abstract/document/10485809?casa_token=s-UFJLX5j8sAAAAA:-n7Oc6LnTtQO6711g6kyUijFMddJI2xHU0nBjMouikK5D13A4Zb1VFE64Q2IUCzXsHLw-NIWSgDstQ;,citation_doi=10.1109/eebda60612.2024.10485809;,citation_volume=2;,citation_conference_title=2024 IEEE 3rd international conference on electrical engineering, big data and algorithms (EEBDA);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Easing the prediction of student dropout for everyone integrating AutoML and explainable artificial intelligence;,citation_abstract=This paper proposes an interactive web-based Python dashboard tool for allowing any users to easily predict students at risk and help make decisions about avoiding student dropout. The user must not necessarily have the programming skills required to develop a machine-learning project. Instead, our system will allow the user to upload students¿½f information dataset, and automatically will generate the best possible prediction model and explanations. The novelty of this tool is that it integrates Automated Machine Learning (AutoML) and Explainable Arti-ficial Intelligence (XAI) techniques, especially counterfactual explanations, into the same interface to make the process more accessible. The objective is to democratize and personalize data science by allowing any stakeholder, to make predictions of student dropout from a dashboard. It provides two different interfaces: a basic interface for beginners and a more complete interface for advanced users. In this paper, we describe the use of the dashboard on a free public dataset for predicting student dropout.;,citation_author=Pamela Buñay-Guisñan;,citation_author=Juan Alfonso Lara;,citation_author=Alberto Cano;,citation_author=Rebeca Cerezo;,citation_author=Cristóbal Romero;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://educationaldatamining.org/edm2024/proceedings/2024.EDM-posters.98/2024.EDM-posters.98.pdf;,citation_doi=10.5281/ZENODO.12729972;,citation_publisher=International Educational Data Mining Society;">
<meta name="citation_reference" content="citation_title=Fuzzy-based active learning for predicting student academic performance using autoML: A step-wise approach;,citation_abstract=Predicting students’ learning outcomes is one of the main topics of interest in the area of Educational Data Mining and Learning Analytics. To this end, a plethora of machine learning methods has been successfully applied for solving a variety of predictive problems. However, it is of utmost importance for both educators and data scientists to develop accurate learning models at low cost. Fuzzy logic constitutes an appropriate approach for building models of high performance and transparency. In addition, active learning reduces both the time and cost of labeling effort, by exploiting a small set of labeled data along with a large set of unlabeled data in the most efficient way. In addition, choosing the proper method for a given problem formulation and configuring the optimal parameter setting is a demanding task, considering the high-dimensional input space and the complexity of machine learning algorithms. As such, exploring the potential of automated machine learning (autoML) strategies from the perspective of machine learning adeptness is important. In this context, the present study introduces a fuzzy-based active learning method for predicting students’ academic performance which combines, in a modular way, autoML practices. A lot of experiments was carried out, revealing the efficiency of the proposed method for the accurate prediction of students at risk of failure. These insights may have the potential to support the learning experience and be useful the wider science of learning.;,citation_author=Maria Tsiakmaki;,citation_author=Georgios Kostopoulos;,citation_author=Sotiris Kotsiantis;,citation_author=Omiros Ragos;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_fulltext_html_url=https://link.springer.com/article/10.1007/s12528-021-09279-x;,citation_issue=3;,citation_doi=10.1007/s12528-021-09279-x;,citation_issn=1042-1726,1867-1233;,citation_volume=33;,citation_journal_title=J. Comput. High. Educ.;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Predictive analytics in information systems research;,citation_abstract=This research essay highlights the need to integrate predictive analytics into information systems research and shows several concrete ways in which this goal can be accomplished. Predictive analytics include empirical methods (statistical and other) tha;,citation_author=Galit Shmueli;,citation_author=Otto R Koppius;,citation_publication_date=2011-09;,citation_cover_date=2011-09;,citation_year=2011;,citation_fulltext_html_url=https://misq.umn.edu/predictive-analytics-in-information-systems-research.html;,citation_issue=3;,citation_volume=35;,citation_journal_title=MIS Quarterly;">
<meta name="citation_reference" content="citation_title=Leveraging predictive analytics for strategic decision-making: Enhancing business performance through data-driven insights;,citation_abstract=This paper explores the transformative role of predictive analytics in enhancing strategic decision-making and business performance. It delves into the components of predictive analytics, including data mining, machine learning, and statistical techniques. It highlights its historical evolution and technological enablers like big data platforms, cloud computing, and AI. The paper examines how predictive analytics improves profitability, efficiency, and market share by providing actionable insights from raw data. It also discusses emerging trends such as advancements in AI, the Internet of Things (IoT), and real-time analytics while addressing associated risks like data privacy and ethical considerations. The conclusion underscores the necessity of adopting predictive analytics for sustainable growth and competitive advantage in today’s data-driven business environment.;,citation_author=Abayomi Abraham Adesina;,citation_author=Toluwalase Vanessa Iyelolu;,citation_author=Patience Okpeke Paul;,citation_publication_date=2024-06;,citation_cover_date=2024-06;,citation_year=2024;,citation_fulltext_html_url=https://wjarr.com/content/leveraging-predictive-analytics-strategic-decision-making-enhancing-business-performance;,citation_issue=3;,citation_doi=10.30574/wjarr.2024.22.3.1961;,citation_issn=2581-9615;,citation_volume=22;,citation_journal_title=World J. Adv. Res. Rev.;,citation_publisher=GSC Online Press;">
<meta name="citation_reference" content="citation_title=Eight years of AutoML: Categorisation, review and trends;,citation_abstract=AbstractKnowledge extraction through machine learning techniques has been successfully applied in a large number of application domains. However, apart from the required technical knowledge and background in the application domain, it usually involves a number of time-consuming and repetitive steps. Automated machine learning (AutoML) emerged in 2014 as an attempt to mitigate these issues, making machine learning methods more practicable to both data scientists and domain experts. AutoML is a broad area encompassing a wide range of approaches aimed at addressing a diversity of tasks over the different phases of the knowledge discovery process being automated with specific techniques. To provide a big picture of the whole area, we have conducted a systematic literature review based on a proposed taxonomy that permits categorising 447 primary studies selected from a search of 31,048 papers. This review performs an extensive and rigorous analysis of the AutoML field, scrutinising how the primary studies have addressed the dimensions of the taxonomy, and identifying any gaps that remain unexplored as well as potential future trends. The analysis of these studies has yielded some intriguing findings. For instance, we have observed a significant growth in the number of publications since 2018. Additionally, it is noteworthy that the algorithm selection problem has gradually been superseded by the challenge of workflow composition, which automates more than one phase of the knowledge discovery process simultaneously. Of all the tasks in AutoML, the growth of neural architecture search is particularly noticeable.;,citation_author=Rafael Barbudo;,citation_author=Sebastián Ventura;,citation_author=José Raúl Romero;,citation_publication_date=2023-12;,citation_cover_date=2023-12;,citation_year=2023;,citation_fulltext_html_url=https://link.springer.com/article/10.1007/s10115-023-01935-1;,citation_issue=12;,citation_doi=10.1007/s10115-023-01935-1;,citation_issn=0219-1377,0219-3116;,citation_volume=65;,citation_journal_title=Knowl. Inf. Syst.;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Improving automated machine-learning systems through green AI;,citation_abstract=Automated machine learning (AutoML), which aims to facilitate the design and optimization of machine-learning models with reduced human effort and expertise, is a research field with significant potential to drive the development of artificial intelligence in science and industry. However, AutoML also poses challenges due to its resource and energy consumption and environmental impact, aspects that have often been overlooked. This paper predominantly centers on the sustainability implications arising from computational processes within the realm of AutoML. Within this study, a proof of concept has been conducted using the widely adopted Scikit-learn library. Energy efficiency metrics have been employed to fine-tune hyperparameters in both Bayesian and random search strategies, with the goal of enhancing the environmental footprint. These findings suggest that AutoML can be rendered more sustainable by thoughtfully considering the energy efficiency of computational processes. The obtained results from the experimentation are promising and align with the framework of Green AI, a paradigm aiming to enhance the ecological footprint of the entire AutoML process. The most suitable proposal for the studied problem, guided by the proposed metrics, has been identified, with potential generalizability to other analogous problems.;,citation_author=Dagoberto Castellanos-Nieves;,citation_author=Luis García-Forte;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=https://www.mdpi.com/2076-3417/13/20/11583;,citation_issue=20;,citation_doi=10.3390/app132011583;,citation_issn=2076-3417,2076-3417;,citation_volume=13;,citation_journal_title=Appl. Sci. (Basel);,citation_publisher=MDPI AG;">
<meta name="citation_reference" content="citation_title=Automated machine learning: The new wave of machine learning;,citation_abstract=With the explosion in the use of machine learning in various domains, the need for an efficient pipeline for the development of machine learning models has never been more critical. However, the task of forming and training models largely remains traditional with a dependency on domain experts and time-consuming data manipulation operations, which impedes the development of machine learning models in both academia as well as industry. This demand advocates the new research era concerned with fitting machine learning models fully automatically i.e., AutoML. Automated Machine Learning(AutoML) is an end-to-end process that aims at automating this model development pipeline without any external assistance. First, we provide an insights of AutoML. Second, we delve into the individual segments in the AutoML pipeline and cover their approaches in brief. We also provide a case study on the industrial use and impact of AutoML with a focus on practical applicability in a business context. At last, we conclude with the open research issues, and future research directions.;,citation_author=Karansingh Chauhan;,citation_author=Shreena Jani;,citation_author=Dhrumin Thakkar;,citation_author=Riddham Dave;,citation_author=Jitendra Bhatia;,citation_author=Sudeep Tanwar;,citation_author=Mohammad S Obaidat;,citation_publication_date=2020-03;,citation_cover_date=2020-03;,citation_year=2020;,citation_fulltext_html_url=https://ieeexplore.ieee.org/document/9074859;,citation_doi=10.1109/icimia48430.2020.9074859;,citation_isbn=9781728141671,9781728141664;,citation_conference_title=2020 2nd international conference on innovative mechanisms for industry applications (ICIMIA);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=A systematic literature review on AutoML for multi-target learning tasks;,citation_abstract=Automated machine learning (AutoML) aims to automate machine learning (ML) tasks, eliminating human intervention from the learning process as much as possible. However, most studies on AutoML are related to unique targets. This article aimed to identify and analyze studies on AutoML applied to multi-label classification and multi-target regression through a systematic literature review (SLR). Initially, we defined the research questions, the search string, the data sources for the search, and the inclusion and exclusion criteria. Then, we carried out the study selection process in four steps, with snowballing being the last stage. Altogether 12 studies were selected to compose SLR. All studies automated the task of ML model search of the pipeline, one study automated the task of feature engineering of the pipeline, all were related to Multi-label Classification, and only one addressed multi-target regression. The search space consisted of algorithms/neural operations and hyperparameters, the studies employed optimization algorithms (such as Genetic Algorithms and Hierarchical Task Networks) to produce increasingly better candidate solutions and one metric to assess the quality of candidate solutions. Only two studies employed Transfer Learning to contribute to AutoML. This article reviewed AutoML, multi-label classification, and multi-target regression and, by answering the SLR research questions, showed how current studies address these issues and gave insights into future directions for AutoML and multi-target tasks.;,citation_author=Aline Marques Del Valle;,citation_author=Rafael Gomes Mantovani;,citation_author=Ricardo Cerri;,citation_publication_date=2023-11;,citation_cover_date=2023-11;,citation_year=2023;,citation_fulltext_html_url=https://link.springer.com/article/10.1007/s10462-023-10569-2;,citation_issue=S2;,citation_doi=10.1007/s10462-023-10569-2;,citation_issn=0269-2821,1573-7462;,citation_volume=56;,citation_journal_title=Artif. Intell. Rev.;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Neural architecture search: A survey;,citation_author=Thomas Elsken;,citation_author=Jan Hendrik Metzen;,citation_author=Frank Hutter;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=http://jmlr.org/papers/v20/18-598.html;,citation_issue=55;,citation_issn=1533-7928,1532-4435;,citation_volume=20;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Predictive analytics: A review of trends and techniques;,citation_abstract=Predictive analytics is a term mainly used in statistical and analytics techniques. This term is drawn from statistics, machine learning, database techniques and optimization techniques. It has roots in classical statistics. It predicts the future by analyzing current and historical data. The futur…;,citation_author=Vaibhav Kumar;,citation_author=M L Garg;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://www.ijcaonline.org/archives/volume182/number1/kumar-2018-ijca-917434.pdf;,citation_issue=1;,citation_volume=182;,citation_journal_title=International Journal of Computer Applications;,citation_publisher=Foundation of Computer Science USA;">
<meta name="citation_reference" content="citation_title=Predictive analytics: A survey, trends, applications, oppurtunities &amp;amp;amp; challenges;,citation_author=Nishchol Mishra;,citation_author=Sanjay Silakari;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=3;,citation_journal_title=International Journal of Computer Science and Information Technologies;,citation_publisher=Citeseer;">
<meta name="citation_reference" content="citation_title=Harnessing predictive analytics for strategic foresight: A comprehensive review of techniques and applications in transforming raw data to actionable insights;,citation_abstract=In an era characterized by an unprecedented influx of data, the skill to extract actionable insights from this deluge has become paramount for organizations acr;,citation_author=Oluwaseun Olaniyi;,citation_author=Nishant Hemantkumar Shah;,citation_author=Anthony Abalaka;,citation_author=Folashade Gloria Olaniyi;,citation_publication_date=2023-11;,citation_cover_date=2023-11;,citation_year=2023;,citation_fulltext_html_url=https://papers.ssrn.com/abstract=4635189;,citation_doi=10.2139/ssrn.4635189;,citation_issn=1556-5068;,citation_journal_title=SSRN Electron. J.;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Harnessing predictive analytics for strategic foresight: A comprehensive review of techniques and applications in transforming raw data to actionable insights;,citation_abstract=In an era characterized by an unprecedented influx of data, the skill to extract actionable insights from this deluge has become paramount for organizations acr;,citation_author=Oluwaseun Olaniyi;,citation_author=Nishant Hemantkumar Shah;,citation_author=Anthony Abalaka;,citation_author=Folashade Gloria Olaniyi;,citation_publication_date=2023-11;,citation_cover_date=2023-11;,citation_year=2023;,citation_fulltext_html_url=https://papers.ssrn.com/abstract=4635189;,citation_doi=10.2139/ssrn.4635189;,citation_issn=1556-5068;,citation_journal_title=SSRN Electron. J.;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=AutoML in the age of large language models: Current challenges, future opportunities and risks;,citation_abstract=The fields of both Natural Language Processing (NLP) and Automated Machine Learning (AutoML) have achieved remarkable results over the past years. In NLP, especially Large Language Models (LLMs) have experienced a rapid series of breakthroughs very recently. We envision that the two fields can radically push the boundaries of each other through tight integration. To showcase this vision, we explore the potential of a symbiotic relationship between AutoML and LLMs, shedding light on how they can benefit each other. In particular, we investigate both the opportunities to enhance AutoML approaches with LLMs from different perspectives and the challenges of leveraging AutoML to further improve LLMs. To this end, we survey existing work, and we critically assess risks. We strongly believe that the integration of the two fields has the potential to disrupt both fields, NLP and AutoML. By highlighting conceivable synergies, but also risks, we aim to foster further exploration at the intersection of AutoML and LLMs.;,citation_author=Alexander Tornede;,citation_author=Difan Deng;,citation_author=Theresa Eimer;,citation_author=Joseph Giovanelli;,citation_author=Aditya Mohan;,citation_author=Tim Ruhkopf;,citation_author=Sarah Segel;,citation_author=Daphne Theodorakopoulos;,citation_author=Tanja Tornede;,citation_author=Henning Wachsmuth;,citation_author=Marius Lindauer;,citation_publication_date=2023-06;,citation_cover_date=2023-06;,citation_year=2023;,citation_fulltext_html_url=http://arxiv.org/abs/2306.08107;,citation_journal_title=arXiv [cs.LG];">
<meta name="citation_reference" content="citation_title=Automated machine learning: From principles to practices;,citation_abstract=Machine learning (ML) methods have been developing rapidly, but configuring and selecting proper methods to achieve a desired performance is increasingly difficult and tedious. To address this challenge, automated machine learning (AutoML) has emerged, which aims to generate satisfactory ML configurations for given tasks in a data-driven way. In this paper, we provide a comprehensive survey on this topic. We begin with the formal definition of AutoML and then introduce its principles, including the bi-level learning objective, the learning strategy, and the theoretical interpretation. Then, we summarize the AutoML practices by setting up the taxonomy of existing works based on three main factors: the search space, the search algorithm, and the evaluation strategy. Each category is also explained with the representative methods. Then, we illustrate the principles and practices with exemplary applications from configuring ML pipeline, one-shot neural architecture search, and integration with foundation models. Finally, we highlight the emerging directions of AutoML and conclude the survey.;,citation_author=Zhenqian Shen;,citation_author=Yongqi Zhang;,citation_author=Lanning Wei;,citation_author=Huan Zhao;,citation_author=Quanming Yao;,citation_publication_date=2018-10;,citation_cover_date=2018-10;,citation_year=2018;,citation_fulltext_html_url=http://arxiv.org/abs/1810.13306;,citation_journal_title=arXiv [cs.AI];">
<meta name="citation_reference" content="citation_title=Democratizing artificial intelligence imaging analysis with automated machine learning: tutorial;,citation_abstract=Deep learning-based clinical imaging analysis underlies diagnostic artificial intelligence (AI) models, which can match or even exceed the performance of clinical experts, having the potential to revolutionize clinical practice. A wide variety of automated machine learning (autoML) platforms lower the technical barrier to entry to deep learning, extending AI capabilities to clinicians with limited technical expertise, and even autonomous foundation models such as multimodal large language models. Here, we provide a technical overview of autoML with descriptions of how autoML may be applied in education, research, and clinical practice. Each stage of the process of conducting an autoML project is outlined, with an emphasis on ethical and technical best practices. Specifically, data acquisition, data partitioning, model training, model validation, analysis, and model deployment are considered. The strengths and limitations of available code-free, code-minimal, and code-intensive autoML platforms are considered. AutoML has great potential to democratize AI in medicine, improving AI literacy by enabling “hands-on” education. AutoML may serve as a useful adjunct in research by facilitating rapid testing and benchmarking before significant computational resources are committed. AutoML may also be applied in clinical contexts, provided regulatory requirements are met. The abstraction by autoML of arduous aspects of AI engineering promotes prioritization of data set curation, supporting the transition from conventional model-driven approaches to data-centric development. To fulfill its potential, clinicians must be educated on how to apply these technologies ethically, rigorously, and effectively; this tutorial represents a comprehensive summary of relevant considerations.;,citation_author=Arun James Thirunavukarasu;,citation_author=Kabilan Elangovan;,citation_author=Laura Gutierrez;,citation_author=Yong Li;,citation_author=Iris Tan;,citation_author=Pearse A Keane;,citation_author=Edward Korot;,citation_author=Daniel Shu Wei Ting;,citation_publication_date=2023-10;,citation_cover_date=2023-10;,citation_year=2023;,citation_fulltext_html_url=http://dx.doi.org/10.2196/49949;,citation_doi=10.2196/49949;,citation_issn=1439-4456,1438-8871;,citation_pmid=37824185;,citation_volume=25;,citation_journal_title=J. Med. Internet Res.;">
<meta name="citation_reference" content="citation_title=Efficient and robust automated machine learning;,citation_author=Matthias Feurer;,citation_author=Aaron Klein;,citation_author=Katharina Eggensperger;,citation_author=Jost Springenberg;,citation_author=Manuel Blum;,citation_author=Frank Hutter;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=https://proceedings.neurips.cc/paper_files/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf;,citation_volume=28;,citation_journal_title=Advances in Neural Information Processing Systems;">
<meta name="citation_reference" content="citation_title=Benchmarking automated machine learning (AutoML) frameworks for object detection;,citation_abstract=Automated Machine Learning (AutoML) is a subdomain of machine learning that seeks to expand the usability of traditional machine learning methods to non-expert users by automating various tasks which normally require manual configuration. Prior benchmarking studies on AutoML systems—whose aim is to compare and evaluate their capabilities—have mostly focused on tabular or structured data. In this study, we evaluate AutoML systems on the task of object detection by curating three commonly used object detection datasets (Open Images V7, Microsoft COCO 2017, and Pascal VOC2012) in order to benchmark three different AutoML frameworks—namely, Google’s Vertex AI, NVIDIA’s TAO, and AutoGluon. We reduced the datasets to only include images with a single object instance in order to understand the effect of class imbalance, as well as dataset and object size. We used the metrics of the average precision (AP) and mean average precision (mAP). Solely in terms of accuracy, our results indicate AutoGluon as the best-performing framework, with a mAP of 0.8901, 0.8972, and 0.8644 for the Pascal VOC2012, COCO 2017, and Open Images V7 datasets, respectively. NVIDIA TAO achieved a mAP of 0.8254, 0.8165, and 0.7754 for those same datasets, while Google’s VertexAI scored 0.855, 0.793, and 0.761. We found the dataset size had an inverse relationship to mAP across all the frameworks, and there was no relationship between class size or imbalance and accuracy. Furthermore, we discuss each framework’s relative benefits and drawbacks from the standpoint of ease of use. This study also points out the issues found as we examined the labels of a subset of each dataset. Labeling errors in the datasets appear to have a substantial negative effect on accuracy that is not resolved by larger datasets. Overall, this study provides a platform for future development and research on this nascent field of machine learning.;,citation_author=Samuel Oliveira;,citation_author=Oguzhan Topsakal;,citation_author=Onur Toker;,citation_publication_date=2024-01;,citation_cover_date=2024-01;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.3390/info15010063;,citation_issue=1;,citation_doi=10.3390/info15010063;,citation_issn=2078-2489;,citation_volume=15;,citation_journal_title=Information (Basel);,citation_publisher=MDPI AG;">
<meta name="citation_reference" content="citation_title=Idiographic learning analytics: A within-person ethical perspective;,citation_abstract=One of the main obstacles impeding the widespread use and adoption of learning analytics is the threat that it poses to students’ data privacy. In this article, we present a proposal for …;,citation_author=S López-Pernas;,citation_author=M Saqr;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://www.researchgate.net/profile/Sonsoles-Lopez-Pernas/publication/350886273_Idiographic_Learning_Analytics_A_Within-Person_Ethical_Perspective/links/607839718ea909241efea6f5/Idiographic-Learning-Analytics-A-Within-Person-Ethical-Perspective.pdf;,citation_journal_title=researchgate.net;">
<meta name="citation_reference" content="citation_title=Stability within and heterogeneity between: An idiographic approach to the temporal dynamics of momentary self-regulated learning;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Tiina Törmänen;,citation_author=L V D E Vogelsmeier;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_conference_title=Proceedings of the 15th international conference on learning analytics and knowledge;,citation_conference=SoLAR; ACM;">
<meta name="citation_reference" content="citation_title=Predictive modelling in teaching and learning;,citation_author=Christopher Brooks;,citation_author=Craig Thompson;,citation_publication_date=2017-05;,citation_cover_date=2017-05;,citation_year=2017;,citation_fulltext_html_url=http://dx.doi.org/10.18608/hla17.005;,citation_doi=10.18608/hla17.005;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Predictive Modelling in Learning Analytics: A Machine Learning Approach in R;,citation_author=Jelena Jovanovic;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1007/978-3-031-54464-4_7;,citation_doi=10.1007/978-3-031-54464-4_7;,citation_language=en;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Is there order in the mess? A single paper meta-analysis approach to identification of predictors of success in learning analytics;,citation_author=Mohammed Saqr;,citation_author=Jelena Jovanovic;,citation_author=Olga Viberg;,citation_author=Dragan Gašević;,citation_publication_date=2022-04-11;,citation_cover_date=2022-04-11;,citation_year=2022;,citation_fulltext_html_url=http://dx.doi.org/10.1080/03075079.2022.2061450;,citation_issue=12;,citation_doi=10.1080/03075079.2022.2061450;,citation_volume=47;,citation_language=en;,citation_journal_title=Studies in Higher Education;">
<meta name="citation_reference" content="citation_title=Idiographic artificial intelligence to explain students’ self-regulation: Toward precision education;,citation_author=Mohammed Saqr;,citation_author=Rongxin Cheng;,citation_author=Sonsoles López-Pernas;,citation_author=Emorie D Beck;,citation_publication_date=2024-08;,citation_cover_date=2024-08;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.lindif.2024.102499;,citation_doi=10.1016/j.lindif.2024.102499;,citation_volume=114;,citation_language=en;,citation_journal_title=Learning and Individual Differences;">
<meta name="citation_reference" content="citation_title=h2o: R interface for the ’H2O’ scalable machine learning platform;,citation_author=Tomas Fryda;,citation_author=Erin LeDell;,citation_author=Navdeep Gill;,citation_author=Spencer Aiello;,citation_author=Anqi Fu;,citation_author=Arno Candel;,citation_author=Cliff Click;,citation_author=Tom Kraljevic;,citation_author=Tomas Nykodym;,citation_author=Patrick Aboyoun;,citation_author=Michal Kurka;,citation_author=Michal Malohlava;,citation_author=Sebastien Poirier;,citation_author=Wendy Wong;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://github.com/h2oai/h2o-3;">
<meta name="citation_reference" content="citation_title=A survey of the state-of-the-art AutoML tools and their comparisons;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=http://dx.doi.org/10.59287/as-ijanser.570;,citation_doi=10.59287/as-ijanser.570;,citation_journal_title=International Journal of Advanced Natural Sciences and Engineering Researches;">
<meta name="citation_reference" content="citation_title=AutoML: A survey of the state-of-the-art;,citation_author=Xin He;,citation_author=Kaiyong Zhao;,citation_author=Xiaowen Chu;,citation_publication_date=2021-01;,citation_cover_date=2021-01;,citation_year=2021;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.knosys.2020.106622;,citation_doi=10.1016/j.knosys.2020.106622;,citation_volume=212;,citation_language=en;,citation_journal_title=Knowledge-Based Systems;">
<meta name="citation_reference" content="citation_title=Unpacking learning in the age of AI: Bridging AI, complexity, and precision education;,citation_author=Sonsoles López-Pernas;,citation_author=Ahmed Tlili;,citation_author=Rwitajit Majumdar;,citation_author=Sami Heikkinen;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=AI, explainable AI and evaluative AI: An introduction to informed data-driven decision-making in education;,citation_author=Sonsoles López-Pernas;,citation_author=Eduardo Oliveira;,citation_author=Yige Song;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Artificial intelligence: Using machine learning to predict students’ performance;,citation_author=Mohammed Saqr;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Artificial intelligence: Using machine learning to classify students and predict low achievers;,citation_author=Mohammed Saqr;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Comparative analysis of regularization methods for predicting student certification in online courses;,citation_author=Tian Li;,citation_author=Feifei Han;,citation_author=Jiesi Guo;,citation_author=Jinran Wu;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Explainable artificial intelligence in education: A tutorial for identifying the variables that matter;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Individualized explainable artificial intelligence: A tutorial for identifying local and individual predictions;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=An introduction to large language models in education;,citation_author=Eduardo Oliveira;,citation_author=Yige Song;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The use of natural language processing in learning analytics;,citation_author=Tarid Wongvorachan;,citation_author=Okan Bulut;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Using language models for automated discourse coding: A primer and tutorial;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=LLMs for explainable artificial intelligence: Automating natural language explanations of predictive analytics models;,citation_author=Sonsoles López-Pernas;,citation_author=Yige Song;,citation_author=Eduardo Oliveira;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Complex dynamic systems in education: Beyond the static, the linear and the causal reductionism;,citation_author=Mohammed Saqr;,citation_author=Daryn Dever;,citation_author=Sonsoles López-Pernas;,citation_author=Christophe Gernigon;,citation_author=Gwen Marchand;,citation_author=Avi Kaplan;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The advanced applications of psychological networks with EGA;,citation_author=Tarid Wongvorachan;,citation_author=Okan Bulut;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Recurrent quantification analysis;,citation_author=Daryn Dever;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Mapping relational dynamics with transition network analysis: A primer and tutorial;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Capturing the breadth and dynamics of the temporal processes with frequency transition network analysis: A primer and tutorial;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Mining patterns and clusters with transition network analysis: A heterogeneity approach;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=A comprehensive introduction to idiographic and within-person analytics;,citation_author=Mohammed Saqr;,citation_author=Hibiki Ito;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The three levels of analysis: Variable-centered, person-centered and person-specific analysis in education;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Idiographic networks: A tutorial on graphical vector autoregression and unified structural equation modeling;,citation_author=Mohammed Saqr;,citation_author=Daryn Dever;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Detecting long-memory psychological processes in academic settings using whittle’s maximum likelihood estimator: An application with r;,citation_author=Rémi Altamore;,citation_author=Clément Roume;,citation_author=Anne Teboul;,citation_author=Christophe Gernigon;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Automating individualized machine learning and AI prediction using AutoML: The case of idiographic predictions;,citation_author=Mohammed Saqr;,citation_author=Ahmed Tlili;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Getting started with R for education research;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Introductory statistics with R for educational researchers;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=An R approach to data cleaning and wrangling for education research;,citation_author=Juho Kopra;,citation_author=Santtu Tikka;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Visualizing and reporting educational data with R;,citation_abstract=AbstractVisualizing data is central in learning analytics research, underpins learning dashboards, and is a prime method for reporting results and insights to stakeholders. In this chapter, the reader will be guided through the process of generating meaningful and aesthetically pleasing visualizations of different types of student data using well-known R packages. The main visualization types will be demonstrated with an explanation of their usage and use cases. Furthermore, learning-related examples will be discussed in detail. For instance, readers will learn how to visualize learners’ logs extracted from learning management systems to show how trace data can be used to track students’ learning activities. In addition to creating compelling plots, readers will also be able to generate professional-looking tables with summary statistics.;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://link.springer.com/chapter/10.1007/978-3-031-54464-4_6;,citation_doi=10.1007/978-3-031-54464-4\_6;,citation_isbn=9783031544637,9783031544644;,citation_inbook_title=Learning analytics methods and tutorials;">
<meta name="citation_reference" content="citation_title=Idiographic learning analytics: A definition and a case study;,citation_author=Mohammed Saqr;,citation_author=Sonsoles Lopez-Pernas;,citation_publication_date=2021-07;,citation_cover_date=2021-07;,citation_year=2021;,citation_fulltext_html_url=http://dx.doi.org/10.1109/icalt52272.2021.00056;,citation_doi=10.1109/icalt52272.2021.00056;,citation_journal_title=2021 International Conference on Advanced Learning Technologies (ICALT);">
<meta name="citation_reference" content="citation_title=A scoping review of idiographic research in education: Too little, but not too late;,citation_author=Hibiki Ito;,citation_author=Sonsoles López-Pemas;,citation_author=Mohammed Saqr;,citation_publication_date=2024-07-01;,citation_cover_date=2024-07-01;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1109/icalt61570.2024.00010;,citation_doi=10.1109/icalt61570.2024.00010;,citation_journal_title=2024 IEEE International Conference on Advanced Learning Technologies (ICALT);">
<meta name="citation_reference" content="citation_title=Modelling within-person idiographic variance could help explain and individualize learning;,citation_author=Mohammed Saqr;,citation_publication_date=2023-02-24;,citation_cover_date=2023-02-24;,citation_year=2023;,citation_fulltext_html_url=http://dx.doi.org/10.1111/bjet.13309;,citation_issue=5;,citation_doi=10.1111/bjet.13309;,citation_volume=54;,citation_language=en;,citation_journal_title=British Journal of Educational Technology;">
<meta name="citation_reference" content="citation_title=Group-level analysis of engagement poorly reflects individual students’ processes: Why we need idiographic learning analytics;,citation_author=Mohammed Saqr;,citation_publication_date=2024-01;,citation_cover_date=2024-01;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.chb.2023.107991;,citation_doi=10.1016/j.chb.2023.107991;,citation_volume=150;,citation_language=en;,citation_journal_title=Computers in Human Behavior;">
<meta name="citation_reference" content="citation_title=Mapping the self in self-regulation using complex dynamic systems approach;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2024-03-14;,citation_cover_date=2024-03-14;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1111/bjet.13452;,citation_issue=4;,citation_doi=10.1111/bjet.13452;,citation_volume=55;,citation_language=en;,citation_journal_title=British Journal of Educational Technology;">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">LA Methods</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../book1/index.html">
 <span class="menu-text">Learning Analytics Methods and Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../book2/index.html">
 <span class="menu-text">Advanced Learning Analytics Methods</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/lamethods/code2/"><i class="bi bi-github" role="img" aria-label="Source Code">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Automating Individualized Machine Learning and AI Prediction using AutoML: The Case of Idiographic Predictions</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contributors.html" class="sidebar-item-text sidebar-link">Contributors</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch01-intro/ch01-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Artificial Intelligence</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch02-AIxAI/ch02-aixai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI and XAI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch03-prediction/ch03-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Prediction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch04-classification/ch04-classification.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch05-regularization/ch05-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regularization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch06-xai-global/ch06-xai-global.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Global XAI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch07-xai-local/ch07-xai-local.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Local XAI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Large Language Models</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch08-llms/ch08-llms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Large Language Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch09-nlp/ch09-nlp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch10-bert/ch10-bert.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Classification with BERT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch11-llmsxai/ch11-llmsxai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Automated feedback with XAI and LLMs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Complex Systems</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch12-cds/ch12-cds.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Complex Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch13-ega/ch13-ega.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Exploratory Graph Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch14-rqa/ch14-rqa.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Recurrent Quantification Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch15-tna/ch15-tna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Transition Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch16-ftna/ch16-ftna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Frequency-based Transition Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch17-tna-clusters/ch17-tna-clusters.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Transition Network Analysis Clusters</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Idiographic</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch18-idio/ch18-idio.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Within-person analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch19-three-levels/ch19-three-levels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Heterogeneity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch20-var/ch20-var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Vector Autoregression and uSEM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch21-mle/ch21-mle.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch22-automl/ch22-automl.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Automated Machine Learning</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">1</span>  Introduction</a></li>
  <li><a href="#automated-machine-learning-automl" id="toc-automated-machine-learning-automl" class="nav-link" data-scroll-target="#automated-machine-learning-automl"><span class="toc-section-number">2</span>  Automated Machine Learning (AutoML)</a></li>
  <li><a href="#automl-in-education-research" id="toc-automl-in-education-research" class="nav-link" data-scroll-target="#automl-in-education-research"><span class="toc-section-number">3</span>  AutoML in education research</a></li>
  <li><a href="#tutorial-using-h2o-for-ml-for-idiographic-ml" id="toc-tutorial-using-h2o-for-ml-for-idiographic-ml" class="nav-link" data-scroll-target="#tutorial-using-h2o-for-ml-for-idiographic-ml"><span class="toc-section-number">4</span>  Tutorial: Using <code>h2o</code> for ML for idiographic ML</a>
  <ul class="collapse">
  <li><a href="#building-an-idiographic-model" id="toc-building-an-idiographic-model" class="nav-link" data-scroll-target="#building-an-idiographic-model"><span class="toc-section-number">4.1</span>  Building an idiographic model</a></li>
  <li><a href="#multiple-idiographic-models" id="toc-multiple-idiographic-models" class="nav-link" data-scroll-target="#multiple-idiographic-models"><span class="toc-section-number">4.2</span>  Multiple idiographic models</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="toc-section-number">5</span>  Conclusion</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
</nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<a href="https://github.com/lamethods/code2" target="_blank"> <button class="btn btn-outline-dark"> <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 496 512" style="width: 22px;vertical-align: text-top;margin-right: 9px;"> <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" style="width: 24px;"> </path> </svg>Download code </button> </a>
<div style="padding: 10px;">
Check out our previous book! <br> <a href="../../../book1/index.html"><img src="../../../book1/1712067211600.jpeg" style="
     width: 70%;
 "></a>
</div>
<p><br> <small>© 2025 The authors</small></p>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Automating Individualized Machine Learning and AI Prediction using AutoML: The Case of Idiographic Predictions</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Mohammed Saqr </p>
             <p>Ahmed Tlili </p>
             <p>Sonsoles López-Pernas </p>
          </div>
  </div>
    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    This chapter introduces a tutorial on using Automated Machine Learning (AutoML) to automate and scale predictive modeling in education. In particular, we illustrate the usefulness of AutoML for idiographic analysis, where each individual student has their own particular model fitted from their own individual data. We demonstrate how AutoML simplifies the ML pipeline, enabling the creation of individually optimized models for multiple datasets Moreover, we illustrate how to apply explainable artificial intelligence techniques to automate the interpretation of the main model predictors, offering a view of the variables that matter. The complete pipeline demonstrated in this tutorial holds potential to provide automated real-time insights based on idiographic analysis in a transparent and trustable way.
  </div>
</div>

</header>

<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Predictive analytics is a branch of analytics that uses students’ data, statistical algorithms, or machine learning (ML) techniques to forecast future outcomes <span class="citation" data-cites="mishra2012predictive">[<a href="#ref-mishra2012predictive" role="doc-biblioref">1</a>]</span> <span class="citation" data-cites="jovanovic2024">[<a href="#ref-jovanovic2024" role="doc-biblioref">2</a>]</span>; <span class="citation" data-cites="predicti2017">[<a href="#ref-predicti2017" role="doc-biblioref">3</a>]</span>; <span class="citation" data-cites="saqr2022">[<a href="#ref-saqr2022" role="doc-biblioref">4</a>]</span>. Prediction is important for developing theories, hypothesis testing, and evaluating the relevance of the theoretical knowledge to research and practice. Therefore, prediction has been a central pillar of of scientific research <span class="citation" data-cites="Shmueli2011-cn">[<a href="#ref-Shmueli2011-cn" role="doc-biblioref">5</a>]</span>. Moreover, predictive analytics enables organizations to make informed decisions, optimize resources, and anticipate future risks or opportunities <span class="citation" data-cites="Adesina2024-dc">[<a href="#ref-Adesina2024-dc" role="doc-biblioref">6</a>]</span>. As such, predictive analytics has been widely adopted across industries, from healthcare to marketing, due to its ability to transform data into actionable insights. As data becomes increasingly diverse and voluminous, predictive analytics plays a critical role in handling big data and providing actionable insights <span class="citation" data-cites="Olaniyi2023-hc">[<a href="#ref-Olaniyi2023-hc" role="doc-biblioref">7</a>]</span>; <span class="citation" data-cites="saqr2022">[<a href="#ref-saqr2022" role="doc-biblioref">4</a>]</span>; <span class="citation" data-cites="saqr2024a">[<a href="#ref-saqr2024a" role="doc-biblioref">8</a>]</span>, which has been a central interest of researchers in learning analytics and artificial intelligence (AI) in education <span class="citation" data-cites="LABOOK2_Chapter_2">[<a href="#ref-LABOOK2_Chapter_2" role="doc-biblioref">9</a>]</span>.</p>
<p>In the previous chapters we studied modeling full datasets and explained them <span class="citation" data-cites="LABOOK2_Chapter_3 LABOOK2_Chapter_4 LABOOK2_Chapter_6 LABOOK2_Chapter_7">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">10</a>–<a href="#ref-LABOOK2_Chapter_7" role="doc-biblioref">13</a>]</span>. In this chapter we will learn how to model each student individually as a whole unit of analysis. In other words, the full dataset belongs to a single student. This is done by collecting several data points from the same student over time that is enough for building a predictive model for the student. These models are known as idiographic e.g., <span class="citation" data-cites="saqr2024a LABOOK2_Chapter_20 LABOOK2_Chapter_18">[<a href="#ref-saqr2024a" role="doc-biblioref">8</a>, <a href="#ref-LABOOK2_Chapter_20" role="doc-biblioref">14</a>, <a href="#ref-LABOOK2_Chapter_18" role="doc-biblioref">15</a>]</span>. Idiographic models are novel and promise accurate insights at the resolution of single students. For a detailed reading about the these models, interested readers can resort to chapter <span class="citation" data-cites="LABOOK2_Chapter_18">[<a href="#ref-LABOOK2_Chapter_18" role="doc-biblioref">15</a>]</span> or these papers <span class="citation" data-cites="saqr2024a">[<a href="#ref-saqr2024a" role="doc-biblioref">8</a>]</span>, <span class="citation" data-cites="saqr2021 ito2024 saqr2023 saqr2024">[<a href="#ref-saqr2021" role="doc-biblioref">16</a>–<a href="#ref-saqr2024" role="doc-biblioref">19</a>]</span>.</p>
<p>Given the need to model students individually, the process needs to be automated to process multiple datasets. Therefore, in this chapter, we will learn how to implement AutoML for a large number of idiographic datasets using <code>h2o</code>, which is a cross-platform open-source, scalable machine learning framework that supports a wide range of algorithms <span class="citation" data-cites="h2o">[<a href="#ref-h2o" role="doc-biblioref">20</a>]</span>. Among the algorithms that <code>h2o</code> supports are generalized linear models (GLM), gradient boosting machines (GBM), random forests (RF), deep learning (DL), k-means clustering, and extreme gradient boosting (XGBoost). H2O is designed to handle large datasets can efficiently use distributed computing capabilities. The <code>h2o</code> package works seamlessly with R and is also available for Python among others. It performs automation of the ML process from model selection and hyperparameter tuning and reporting of results. Also, <code>h2o</code> includes tools for model explanation and supports easy visualization and plotting of results <span class="citation" data-cites="h2o">[<a href="#ref-h2o" role="doc-biblioref">20</a>]</span>.</p>
</section>
<section id="automated-machine-learning-automl" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="automated-machine-learning-automl"><span class="header-section-number">2</span> Automated Machine Learning (AutoML)</h2>
<p>The core of predictive analytics lies in building predictive models, which are often built using techniques such as regression analysis, decision trees, and neural networks <span class="citation" data-cites="jovanovic2024 saqr2022">[<a href="#ref-jovanovic2024" role="doc-biblioref">2</a>, <a href="#ref-saqr2022" role="doc-biblioref">4</a>]</span>. These models are trained to recognize complex relationships within the data, making it possible to forecast future trends with a degree of confidence <span class="citation" data-cites="jovanovic2024 Olaniyi2023-hc">[<a href="#ref-jovanovic2024" role="doc-biblioref">2</a>, <a href="#ref-Olaniyi2023-hc" role="doc-biblioref">7</a>]</span>. Constructing such predictive models entails several steps which are often repetitive which roughly includes data pre-processing and preparation for analysis, feature engineering and selection to identify the relevant variables. Next, model selection, training and evaluation of model’s performance . Based on these results, the model is tuned and optimized for better accuracy <span class="citation" data-cites="LABOOK2_Chapter_3 LABOOK2_Chapter_4">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">10</a>, <a href="#ref-LABOOK2_Chapter_4" role="doc-biblioref">11</a>]</span>.</p>
<p>Since the steps to conduct the predictive analytics workflow are mostly the same each time, it is possible to automate them using AutoML <span class="citation" data-cites="Tornede2023-ex Garmpis2022-vk Shen2018-eb">[<a href="#ref-Tornede2023-ex" role="doc-biblioref">21</a>–<a href="#ref-Shen2018-eb" role="doc-biblioref">23</a>]</span>. AutoML is a relatively novel and growing area in machine learning (ML) that aims to —as the name implies— automate the process of applying ML to real-world problems <span class="citation" data-cites="he2021 asurvey2023">[<a href="#ref-he2021" role="doc-biblioref">24</a>, <a href="#ref-asurvey2023" role="doc-biblioref">25</a>]</span>. In fast-paced environments, models need to be updated and redeployed regularly to adapt to new data or changing conditions. AutoML automates many steps of the ML life cycle, making it feasible to frequently refresh models as part of a continuous integration pipeline. Furthermore, when working with a large number of similar datasets, it becomes impractical to repeat the ML process for each manually. As such, AutoML allows to automate this process, optimizing ML model to each specific dataset. Besides the obvious scalability benefits, research has found that AutoML can achieve good results as traditional ML with expert tuning <span class="citation" data-cites="saqr2024a he2021 asurvey2023">[<a href="#ref-saqr2024a" role="doc-biblioref">8</a>, <a href="#ref-he2021" role="doc-biblioref">24</a>, <a href="#ref-asurvey2023" role="doc-biblioref">25</a>]</span>.</p>
<p>The core function of AutoML lies in optimizing ML workflows, from data pre-processing to model deployment. Recent advancements in AutoML techniques have led to substantial improvements in predictive performance <span class="citation" data-cites="Elsken2019-ua">[<a href="#ref-Elsken2019-ua" role="doc-biblioref">26</a>]</span>. For example, the framework now encompasses methodologies such as neural architecture search, which automatically designs neural networks tailored to specific tasks. This has led to models that achieve state-of-the-art performance across numerous benchmarks <span class="citation" data-cites="Barbudo2023-of">[<a href="#ref-Barbudo2023-of" role="doc-biblioref">27</a>]</span>. Additionally, the introduction of automated feature engineering techniques enables models to learn relevant features from raw data, enhancing model accuracy without extensive manual intervention <span class="citation" data-cites="Del-Valle2023-lq">[<a href="#ref-Del-Valle2023-lq" role="doc-biblioref">28</a>]</span>.</p>
<p>Furthermore, AutoML streamlines the process of feature selection, making it easier to handle high-dimensional data <span class="citation" data-cites="h2o">[<a href="#ref-h2o" role="doc-biblioref">20</a>]</span>. The automation of hyperparameter tuning and model selection significantly reduces the time required for model development. AutoML systems may outperform traditional methods in terms of efficiency, leading to quicker time-to-insight and facilitating more rapid iterations in model improvement <span class="citation" data-cites="Feurer2015-bb">[<a href="#ref-Feurer2015-bb" role="doc-biblioref">29</a>]</span>. AutoML can also achieve competitive or superior performance compared to human experts. Through exhaustive search strategies and advanced algorithms, AutoML often yield models that may surpass human-crafted solutions <span class="citation" data-cites="Oliveira2024-ce">[<a href="#ref-Oliveira2024-ce" role="doc-biblioref">30</a>]</span>. In doing so, AutoML can make high-quality models accessible to non-experts while also reducing the time and computational costs traditionally associated with ML development <span class="citation" data-cites="Shen2018-eb">[<a href="#ref-Shen2018-eb" role="doc-biblioref">23</a>]</span>. Further, automating the time-consuming aspects of model development allows AutoML tools to lower the barriers for organizations and individuals to utilize ML, enabling a broader range of industries to integrate AI-driven solutions <span class="citation" data-cites="Thirunavukarasu2023-en">[<a href="#ref-Thirunavukarasu2023-en" role="doc-biblioref">31</a>]</span>. This is increasingly relevant, as organizations across various sectors progressively rely on data-driven decision-making to maintain competitive advantage.</p>
<p>There are also several challenges and opportunities within AutoML. One prominent challenge is the computational cost, particularly as the demand for larger and more complex models (such as large language models, LLMs) grows. Applying AutoML to such models, which require enormous computational resources, poses difficulties for scaling and sustainability <span class="citation" data-cites="Tornede2023-ex">[<a href="#ref-Tornede2023-ex" role="doc-biblioref">21</a>]</span>. Another issue is the environmental impact of AutoML processes, as they consume significant energy and computational resources. The integration of “Green AI” principles, which emphasize energy-efficient algorithms and workflows, has been proposed to address these concerns <span class="citation" data-cites="Castellanos-Nieves2023-oz">[<a href="#ref-Castellanos-Nieves2023-oz" role="doc-biblioref">32</a>]</span>.</p>
</section>
<section id="automl-in-education-research" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="automl-in-education-research"><span class="header-section-number">3</span> AutoML in education research</h2>
<p>The use of AutoML has not been very prominent in the education scientific literature. However, an increasing number of studies recognize its potential. The study by Garmpis et al. <span class="citation" data-cites="Garmpis2022-vk">[<a href="#ref-Garmpis2022-vk" role="doc-biblioref">22</a>]</span> addressed the challenges posed by recent policy changes in higher education system in Greece, which led to departmental unification and increased dropout rates. The researchers utilized AutoML to identify the best predictive models and parameters and analyzed a dataset of 23,687 students enrolled in the “Computer Networking” module, employing the open-source data science platform for model development and evaluation. The model’s accuracy was assessed using established evaluation metrics, including precision, recall, and F-measure. Their findings indicated that the model accurately predicted approximately 92% of student performance, specifically identifying students at risk of dropping out or facing delays in graduation. This approach demonstrates the potential of AutoML in enhancing educational outcomes and supporting strategic interventions for student success <span class="citation" data-cites="Garmpis2022-vk">[<a href="#ref-Garmpis2022-vk" role="doc-biblioref">22</a>]</span>. Similarly, Zhao and Wang <span class="citation" data-cites="Zhao2024-kk">[<a href="#ref-Zhao2024-kk" role="doc-biblioref">33</a>]</span> used AutoML to predict online learning adaptability and achieved a high accuracy of 90.9%. Their empirical findings showed that AutoML yielded higher performance than traditional methods for all the evaluated metrics.</p>
<p>In another study, Bosch <span class="citation" data-cites="Bosch2021-ws">[<a href="#ref-Bosch2021-ws" role="doc-biblioref">34</a>]</span> conducted experiments using AutoML to streamline feature engineering for student models in the National Assessment of Educational Progress data mining competition. Bosch compared two AutoML feature engineering methods, Featuretools and TSFRESH (Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests), which had rarely been applied to student interaction log data. The TSFRESH method provides a novel feature selection technique to manage over 4,000 heterogeneous features with a relatively small student sample, The study findings revealed that TSFRESH features were significantly more effective than both Featuretools and expert-engineered features <span class="citation" data-cites="Bosch2021-ws">[<a href="#ref-Bosch2021-ws" role="doc-biblioref">34</a>]</span>. However, the interpretability of these models remains limited. To overcome the limitation of interoperability in Bosch’s study <span class="citation" data-cites="Bosch2021-ws">[<a href="#ref-Bosch2021-ws" role="doc-biblioref">34</a>]</span>, Buñay-Guisñan and colleagues <span class="citation" data-cites="Bunay-Guisnan2024-hx">[<a href="#ref-Bunay-Guisnan2024-hx" role="doc-biblioref">35</a>]</span> developed a dashboard that combines AutoML and Explainable AI to predict student dropout, allowing non-experts to upload datasets and automatically generate predictive models, along with counterfactual explanations to help users understand the factors affecting student dropout.</p>
<p>In another study, Tsiakmaki et al. <span class="citation" data-cites="Tsiakmaki2021-vr">[<a href="#ref-Tsiakmaki2021-vr" role="doc-biblioref">36</a>]</span> focused on predicting students’ academic performance, researchers explored the use of AutoML strategies, a critical area within Educational Data Mining and Learning Analytics. Recognizing the need for accurate learning models at a low cost, they introduced a fuzzy-based active learning method that integrates AutoML practices in a modular fashion. This approach leverages fuzzy logic to create high-performance and transparent models while reducing the time and cost of labeling data by effectively utilizing a small set of labeled data alongside a larger set of unlabeled data. Given the complexity of ML algorithms and the high-dimensional input space, selecting the right method and optimizing parameters can be challenging. To address this, they conducted numerous experiments that demonstrated the efficiency of their proposed method in accurately identifying students at risk of failure. These insights not only have the potential to enhance the learning experience but also contribute significantly to the broader science of learning.</p>
<p>The few existing research studies in AutoML appear to take advantage of this technique to optimize their models and to make ML accessible to non-experts. However, the potential of AutoML to automate the ML pipeline for many individual models to enable idiographic ML, has barely been fulfilled. To the knowledge of the authors, only one article has come close to implementing this technique to automatically create, fit and optimize idiographic models <span class="citation" data-cites="saqr2024a">[<a href="#ref-saqr2024a" role="doc-biblioref">8</a>]</span>, which is the aim of this tutorial. In said study, the authors automated the feature selection, as well as the model training and evaluation of the prediction of students’ variables related to self-regulated learning based on previous measures.</p>
</section>
<section id="tutorial-using-h2o-for-ml-for-idiographic-ml" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="tutorial-using-h2o-for-ml-for-idiographic-ml"><span class="header-section-number">4</span> Tutorial: Using <code>h2o</code> for ML for idiographic ML</h2>
<p>In this tutorial, we will explore how to use the <code>h2o</code> ML platform to build, evaluate, and compare idiographic models. It is assumed that the reader is familiar with the R programming language. If that is not the case, it is recommended to refer to previous tutorials on the basics of R <span class="citation" data-cites="Tikka2024-ph">[<a href="#ref-Tikka2024-ph" role="doc-biblioref">37</a>]</span>, data cleaning <span class="citation" data-cites="Kopra2024-fx">[<a href="#ref-Kopra2024-fx" role="doc-biblioref">38</a>]</span>, basic statistics <span class="citation" data-cites="Tikka2024-wl">[<a href="#ref-Tikka2024-wl" role="doc-biblioref">39</a>]</span>, and visualization <span class="citation" data-cites="Lopez-Pernas2024-ge">[<a href="#ref-Lopez-Pernas2024-ge" role="doc-biblioref">40</a>]</span>, as well as prediction <span class="citation" data-cites="jovanovic2024 LABOOK2_Chapter_3 LABOOK2_Chapter_3 LABOOK2_Chapter_4">[<a href="#ref-jovanovic2024" role="doc-biblioref">2</a>, <a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">10</a>, <a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">10</a>, <a href="#ref-LABOOK2_Chapter_4" role="doc-biblioref">11</a>]</span> and explainable AI <span class="citation" data-cites="LABOOK2_Chapter_6 LABOOK2_Chapter_7">[<a href="#ref-LABOOK2_Chapter_6" role="doc-biblioref">12</a>, <a href="#ref-LABOOK2_Chapter_7" role="doc-biblioref">13</a>]</span>. When working with idiographic analysis, we treat each individual person as an independent dataset and, therefore, we need a separate ML model for each person <span class="citation" data-cites="LABOOK2_Chapter_18">[<a href="#ref-LABOOK2_Chapter_18" role="doc-biblioref">15</a>]</span>. Implementing all steps of the ML pipeline for each individual dataset is extremely time consuming for researchers, and impossible to do in real time if the ML models are to be deployed and regularly updated when new data is collected. Therefore, AutoML is more suitable for idiographic analysis.</p>
<p>As a first step, we need to load the essential R packages. We load the <code>tidyverse</code> package for data manipulation tasks, and the <code>h2o</code> package for AutoML. The next code loads the dataset with the <code>readRDS()</code> function. We also set a random seed that ensures the split is reproducible, helping to maintain consistency in results.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">265</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)  <span class="co"># For data manipulation</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(h2o)    <span class="co"># For H2O ML platform</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>synthetic_data <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">"https://github.com/lamethods/data2/raw/main/srl/srl.RDS"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<p>The dataset used in this tutorial is a synthetic dataset based on the work by <span class="citation" data-cites="saqr2024a">[<a href="#ref-saqr2024a" role="doc-biblioref">8</a>]</span> which collected data using the Concise Self-Regulation Survey (CSRL) <span class="citation" data-cites="saqr2024b">[<a href="#ref-saqr2024b" role="doc-biblioref">41</a>]</span>, as well as phone sensor and contextual data. However, we will use only the a combination of CSRL and sensor data here. In the next step, we select and define the variables that we will use as inputs for our ML models. We start by categorizing the variables into two groups: phone activity variables and self-regulated learning (SRL) variables.</p>
<p>The phone activity variables represent various physical and behavioral patterns related to daily activities, giving us insights into a person’s physical and digital behavior, which may affect learning performance.</p>
<p>These include the following features:</p>
<ul>
<li><strong><code>"meanpace"</code></strong>: average pace of movement</li>
<li><strong><code>"steps"</code></strong>: the number of steps taken</li>
<li><strong><code>"freqscreen"</code></strong>: frequency of screen use</li>
<li><strong><code>"duration"</code></strong>: duration of screen usage</li>
<li><strong><code>"scrrenoff"</code></strong>: time the screen is off</li>
<li><strong><code>"nightduroff"</code></strong>: duration of screen-off time during the night</li>
<li><strong><code>"maxoffscreennight"</code></strong>: the longest period during which the screen is off at night.</li>
</ul>
<p>The <strong>SRL variables</strong> capture key aspects of cognitive and emotional self-regulation, which are crucial for understanding how learners manage and control their learning processes. These variables are derived from self-reported data reflecting various self-regulated learning strategies. They include:</p>
<ul>
<li><strong><code>"efficacy"</code></strong>: The belief in one’s ability to complete learning tasks effectively.</li>
<li><strong><code>"value"</code></strong>: The perceived importance or value of learning tasks.</li>
<li><strong><code>"planning"</code></strong>: The ability to plan and organize learning activities ahead of time.</li>
<li><strong><code>"monitoring"</code></strong>: Keeping track of learning progress and task completion.</li>
<li><strong><code>"effort"</code></strong>: The amount of effort put into learning tasks.</li>
<li><strong><code>"control"</code></strong>: The ability to resist distractions and stay focused on learning.</li>
<li><strong><code>"help"</code></strong>: Seeking help from teachers, friends, or other resources when needed.</li>
<li><strong><code>"social"</code></strong>: Interactions and feelings of belonging within the college or learning community.</li>
<li><strong><code>"organizing"</code></strong>: Organizing and structuring study time and materials.</li>
<li><strong><code>"motivated"</code></strong>: The level of motivation and enthusiasm towards learning and achieving better grades.</li>
<li><strong><code>"feedback"</code></strong>: Learning from feedback to improve performance.</li>
<li><strong><code>"evaluating"</code></strong>: Self-evaluating one’s work to improve skills and performance.</li>
<li><strong><code>"anxiety"</code></strong>: The level of anxiety or stress experienced during learning or in tasks.</li>
<li><strong><code>"enjoyment"</code></strong>: The amount of enjoyment and satisfaction gained from completing tasks and achieving goals.</li>
</ul>
<p>Next, we combine both the self-regulated learning (SRL) variables and the phone activity variables into a single vector of predictors. We then define the response variable as <code>"learning"</code> (how much the student learnt during this day or period or gained knowledge), which serves as the target variable that the model will attempt to predict based on the input predictors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the phone activity variables</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>phone_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"meanpace"</span>, <span class="st">"steps"</span>, <span class="st">"freqscreen"</span>, <span class="st">"duration"</span>, </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                <span class="st">"scrrenoff"</span>, <span class="st">"nightduroff"</span>, <span class="st">"maxoffscreennight"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the SRL variables</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>srl_vars <span class="ot">&lt;-</span> <span class="fu">colnames</span>(<span class="fu">select</span>(synthetic_data, efficacy<span class="sc">:</span>enjoyment))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine all variables into the Predictors list</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> <span class="fu">c</span>(srl_vars, phone_vars)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the response variable</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>response_variable <span class="ot">&lt;-</span> <span class="st">"learning"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="building-an-idiographic-model" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="building-an-idiographic-model"><span class="header-section-number">4.1</span> Building an idiographic model</h3>
<p>Before working with the H2O AutoML framework, we need to initialize the <code>h2o</code> cluster. This involves allocating resources such as the number of threads and the maximum memory size for the computation. Here, initialize <code>h2o</code> with the <code>nthreads</code> parameter set to <code>6</code>, which allows <code>h2o</code> to utilize 6 CPU cores. Additionally, the <code>max_mem_size</code> parameter is set to <code>"12G"</code>, specifying that up to 12GB of memory can be used for model training and processing. You can adjust these settings based on your system’s resources to ensure optimal performance during model training and evaluation. The initialization results in a “Connection successful!” message and <code>h2o</code> prints the <code>h2o</code> cluster information which include the up time, the timezone and detailed version information.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Initialize h2o with specified resources</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">h2o.init</span>(<span class="at">nthreads =</span> <span class="dv">12</span>, <span class="at">max_mem_size =</span> <span class="st">"12G"</span>)  <span class="co"># Adjust memory and threads if necessary</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Given that idiographic models are single-subject by definition, we need to select a single student from the dataset who will be the target of our initial analysis. Using the <code>unique()</code> function, we extract a list of unique student names and choose a particular student by specifying their index (e.g., the 5th student which carries the fake name Alice). Once Alice is selected, we filter the dataset using the <code>filter()</code> function from the <code>dplyr</code> package to include only the rows that correspond to Alice’s data (the 5th student). After filtering, we remove the <code>"name"</code> column, as it is no longer needed with the <code>select()</code> function. This results in a filtered dataset that contains only the relevant variables for Alice for further analysis. If we know the student already, we could of course use a simpler way by filtering only Alice data like the code below using <code>synthetic_data %&gt;% filter(name == "Alice")</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Retrieve the specific name (e.g., the first unique name)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>specific_name <span class="ot">&lt;-</span> <span class="fu">unique</span>(synthetic_data<span class="sc">$</span>name)[<span class="dv">5</span>]  </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Filter the dataset for the selected person and remove the 'name' column</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>filtered_data <span class="ot">&lt;-</span> synthetic_data <span class="sc">%&gt;%</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(name <span class="sc">==</span> specific_name) <span class="sc">%&gt;%</span>  <span class="co"># Filter rows where 'name' matches the selected person</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>name)  <span class="co"># Exclude the 'name' column from the data</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># An alternative approach to selecting</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>filtered_data <span class="ot">&lt;-</span> synthetic_data <span class="sc">%&gt;%</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(name <span class="sc">==</span> <span class="st">"Alice"</span>) <span class="sc">%&gt;%</span>  <span class="co"># Filter rows where 'name' matches the selected person</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>name)  <span class="co"># Exclude the 'Alice' column from the data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following steps are similar to traditional ML with some minor differences. We prepare the data by first converting it into an <code>h2o</code> data frame by splitting it into training and testing sets, and defining the predictors and response variable. The data transformation into an <code>h2o</code> format is done using <code>as.h2o()</code> function. This transformation is necessary because <code>h2o</code> can only work with <code>h2o</code> data format. <code>h2o</code>’s requires this format for better optimization and efficient distributed processing and parallel computations which standard R data frames cannot provide.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Disable progress bar for clarity</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">h2o.no_progress</span>()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Convert the filtered data into an h2o frame</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>h2o_data <span class="ot">&lt;-</span> <span class="fu">as.h2o</span>(filtered_data)  <span class="co"># Convert into an h2o format for processing</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we split the data into training and testing sets using <code>h2o.splitFrame()</code> and ratios = 0.8, which means 80% of the data and will be used to train the model, while the remaining 20% is reserved for testing. Splitting the data is standard procedure for evaluating the model’s performance on unseen data and ensuring it generalizes well, also, we will use the testing set to evaluate the model. We also ensure that the seed is set using <code>seed = 256</code> for reproduciblity.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Split the h2o frame into training (80%) and testing (20%) sets</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use seed for reproducibility</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>splits <span class="ot">&lt;-</span> <span class="fu">h2o.splitFrame</span>(<span class="at">data =</span> h2o_data, <span class="at">ratios =</span> <span class="fl">0.8</span>, <span class="at">seed =</span> <span class="dv">256</span>)  </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>train_data_h2o <span class="ot">&lt;-</span> splits[[<span class="dv">1</span>]]  <span class="co"># Training data (80%)</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>test_data_h2o <span class="ot">&lt;-</span> splits[[<span class="dv">2</span>]]   <span class="co"># Testing data (20%)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we define the predictors and the response variable. The predictors include all the relevant features in the dataset except the target outcome, which is the <code>"learning"</code> variable. The model will use these predictors to learn and make predictions, with the response variable representing the learning outcome we aim to predict.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Define predictors and response variable for model training</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(<span class="fu">names</span>(filtered_data), <span class="st">"learning"</span>)  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>response_variable <span class="ot">&lt;-</span> <span class="st">"learning"</span>  <span class="co"># Specify the response variable name</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we will use <code>h2o</code>’s AutoML which will automate the complete ML pipeline for us. The function <code>h2o.automl()</code> simplifies the process of model training and evaluation by automatically testing multiple algorithms and performing hyperparameter tuning within a user-defined time limit. It stores all the models in the results, allowing us to easily compare their performance. Let’s go through the parameters one by one.</p>
<ul>
<li><p><strong><code>x = predictors</code></strong>: This specifies the <strong>predictor variables</strong> or features that the model will use to make predictions. The <code>predictors</code> list includes all the variables we want the model to learn from, excluding the target variable which are the SRL and phone activity data.</p></li>
<li><p><strong><code>y = response_variable</code></strong>: This is the <strong>response variable</strong>, also known as the target or dependent variable. In this case, it’s set to <code>"learning"</code>, which represents the outcome we are trying to predict.</p></li>
<li><p><strong><code>training_frame = train_data_h2o</code></strong>: The <code>training_frame</code> is the dataset used to train the model, which must be an <code>h2o</code> Frame. In this case, it’s the 80% split of the filtered data that we converted into an <code>h2o</code> Frame.</p></li>
<li><p><strong><code>nfolds = 5</code></strong>: This specifies the number of <strong>cross-validation folds</strong>. Cross-validation is a technique where the data is split into multiple parts, or “folds,” and the model is trained on different subsets of the data while being validated on the remaining parts. By setting <code>nfolds = 5</code>, the training data is split into 5 folds, helping ensure that the model generalizes well to new data and doesn’t over-fit and gives an average of the five training folds.</p></li>
<li><p><strong><code>max_runtime_secs = 900</code></strong>: This sets the <strong>maximum time</strong> (in seconds) that the AutoML process can run. It limits the overall time spent on training and evaluating models. In this case, we set a short time limit of 900 seconds, so the process will stop once this limit is reached, even if all possible models haven’t been trained. This parameter can be adjusted based on the available computational resources and the task.</p></li>
<li><p><strong><code>seed = 256</code></strong>: When you specify a seed, the model training process can be repeated with the same results. This is important when you want to compare results or ensure consistency across different runs.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 7: Train the model using h2o AutoML</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>automl_model <span class="ot">&lt;-</span> <span class="fu">h2o.automl</span>(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> predictors,  <span class="co"># Predictor variables</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> response_variable,  <span class="co"># Response variable</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">training_frame =</span> train_data_h2o,  <span class="co"># Training data</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">nfolds =</span> <span class="dv">5</span>,  <span class="co"># Number of cross-validation folds</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">max_runtime_secs =</span> <span class="dv">900</span>,  <span class="co"># Maximum runtime in seconds</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">256</span>  <span class="co"># Random seed for reproducibility</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<p>After <code>h2o</code> AutoML completes the job of training the models, it creates a leaderboard (a list models ranked from best to worst performing model). The leaderboard allows us to rank the resulting models that were estimated with different algorithms and hyperparameters. Given that there are multiple metrics to evaluate performance, there are several ways also to rank the algorithms. The <code>h2o</code> default methods for regression is Root Mean Squared Error (RMSE). To get the leaderboard, we use <code>h2o.get_leaderboard</code> we supply the <code>automl_model</code> given that it the object that contains the models, and set <code>extra_columns = "ALL"</code> to get all the possible evaluation parameters. To view the top 10 models in the leaderboard, we use the <code>head(leaderboard, 10)</code> function which will display a ranked list of models trained by <code>AutoML</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 8: View the leaderboard of models</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>leaderboard <span class="ot">&lt;-</span> <span class="fu">h2o.get_leaderboard</span>(automl_model, <span class="at">extra_columns =</span> <span class="st">"ALL"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(leaderboard, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-leaderboard" class="anchored">
<table class="table table-sm table-striped">
<caption>Table&nbsp;1<strong>.</strong> Leaderboard showing a list models ranked from best to worst performing model.</caption>
<colgroup>
<col style="width: 46%">
<col style="width: 4%">
<col style="width: 5%">
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 10%">
<col style="width: 9%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">model_id</th>
<th style="text-align: right;">rmse</th>
<th style="text-align: right;">mse</th>
<th style="text-align: right;">mae</th>
<th style="text-align: right;">rmsle</th>
<th style="text-align: right;">mean_res_dev</th>
<th style="text-align: right;">training_ms</th>
<th style="text-align: left;">algo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">GBM_grid_1_AutoML_93_20240930_00046_model_57</td>
<td style="text-align: right;">9.03</td>
<td style="text-align: right;">81.53</td>
<td style="text-align: right;">3.07</td>
<td style="text-align: right;">0.39</td>
<td style="text-align: right;">81.53</td>
<td style="text-align: right;">384</td>
<td style="text-align: left;">GBM</td>
</tr>
<tr class="even">
<td style="text-align: left;">StackedEnsemble_BestOfFamily_3_AutoML_93_20240930_00046</td>
<td style="text-align: right;">9.16</td>
<td style="text-align: right;">83.91</td>
<td style="text-align: right;">3.50</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">83.91</td>
<td style="text-align: right;">110</td>
<td style="text-align: left;">StackedEnsemble</td>
</tr>
<tr class="odd">
<td style="text-align: left;">StackedEnsemble_BestOfFamily_5_AutoML_93_20240930_00046</td>
<td style="text-align: right;">9.41</td>
<td style="text-align: right;">88.57</td>
<td style="text-align: right;">3.95</td>
<td style="text-align: right;">0.45</td>
<td style="text-align: right;">88.57</td>
<td style="text-align: right;">215</td>
<td style="text-align: left;">StackedEnsemble</td>
</tr>
<tr class="even">
<td style="text-align: left;">StackedEnsemble_BestOfFamily_4_AutoML_93_20240930_00046</td>
<td style="text-align: right;">9.64</td>
<td style="text-align: right;">92.88</td>
<td style="text-align: right;">5.15</td>
<td style="text-align: right;">0.53</td>
<td style="text-align: right;">92.88</td>
<td style="text-align: right;">514</td>
<td style="text-align: left;">StackedEnsemble</td>
</tr>
<tr class="odd">
<td style="text-align: left;">GBM_grid_1_AutoML_93_20240930_00046_model_2</td>
<td style="text-align: right;">9.68</td>
<td style="text-align: right;">93.80</td>
<td style="text-align: right;">3.39</td>
<td style="text-align: right;">0.39</td>
<td style="text-align: right;">93.80</td>
<td style="text-align: right;">472</td>
<td style="text-align: left;">GBM</td>
</tr>
<tr class="even">
<td style="text-align: left;">GBM_grid_1_AutoML_93_20240930_00046_model_54</td>
<td style="text-align: right;">9.76</td>
<td style="text-align: right;">95.30</td>
<td style="text-align: right;">3.24</td>
<td style="text-align: right;">0.40</td>
<td style="text-align: right;">95.30</td>
<td style="text-align: right;">354</td>
<td style="text-align: left;">GBM</td>
</tr>
<tr class="odd">
<td style="text-align: left;">GBM_grid_1_AutoML_93_20240930_00046_model_3</td>
<td style="text-align: right;">10.02</td>
<td style="text-align: right;">100.38</td>
<td style="text-align: right;">3.45</td>
<td style="text-align: right;">0.42</td>
<td style="text-align: right;">100.38</td>
<td style="text-align: right;">284</td>
<td style="text-align: left;">GBM</td>
</tr>
<tr class="even">
<td style="text-align: left;">GBM_grid_1_AutoML_93_20240930_00046_model_63</td>
<td style="text-align: right;">10.34</td>
<td style="text-align: right;">106.96</td>
<td style="text-align: right;">3.23</td>
<td style="text-align: right;">0.40</td>
<td style="text-align: right;">106.96</td>
<td style="text-align: right;">462</td>
<td style="text-align: left;">GBM</td>
</tr>
<tr class="odd">
<td style="text-align: left;">GBM_grid_1_AutoML_93_20240930_00046_model_35</td>
<td style="text-align: right;">10.36</td>
<td style="text-align: right;">107.31</td>
<td style="text-align: right;">3.33</td>
<td style="text-align: right;">0.41</td>
<td style="text-align: right;">107.31</td>
<td style="text-align: right;">265</td>
<td style="text-align: left;">GBM</td>
</tr>
<tr class="even">
<td style="text-align: left;">GBM_5_AutoML_93_20240930_00046</td>
<td style="text-align: right;">10.41</td>
<td style="text-align: right;">108.45</td>
<td style="text-align: right;">3.64</td>
<td style="text-align: right;">0.40</td>
<td style="text-align: right;">108.45</td>
<td style="text-align: right;">204</td>
<td style="text-align: left;">GBM</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>The leaderboard has several fields which we will discuss (<a href="#tbl-leaderboard">Table&nbsp;<span>22.1</span></a>). The <strong>model ID</strong> identifies each model and specifies the algorithm used for training. For instance, the model named <strong>GBM_grid_1_AutoML_93_20240930_00046_model_57</strong> refers to a <strong>Gradient Boosting Machine (GBM)</strong> model while <strong>StackedEnsemble_BestOfFamily_3_AutoML_93_20240930</strong> uses the <strong>StackedEnsemble</strong> algorithm. The <code>h2o</code> package uses a naming convention that can provide insights about the model. In that, <strong>StackedEnsemble_BestOfFamily_3_AutoML_93_20240930</strong> indicates a <strong>stacked ensemble model</strong> that selects the best-performing models from the AutoML run, as indicated by “BestOfFamily.” The number “3” shows that it is the third iteration of the model. “AutoML_93” means it is part of the 93rd AutoML run, and “20240930” is the date the AutoML process was executed, formatted as YYYYMMDD (September 30, 2024). The next field, <strong>RMSE</strong> (Root Mean Squared Error), is a well-known metric for evaluating regression models that measures the average prediction error. For example, the model <strong>GBM_grid_1_AutoML_93_20240930_00046_model_57</strong> has an <strong>RMSE of 9.03</strong>, which indicates that its predictions deviate by an average of 9.03 units from the actual values of the target variable (learning). Since it has the lowest RMSE on the leaderboard, this model is the best-performing model in our analysis. Please note that our variables scale ranges from 0-100 so, 9 points is still small. <strong>MSE</strong> (Mean Squared Error) is another evaluation metric that refers to the squared average prediction error. The <strong>GBM_grid_1_AutoML_93_20240930_00046_model_57</strong> model has a value of 81.53 and confirming its strong performance. <strong>MAE</strong> (Mean Absolute Error) measures the average magnitude of the errors in the predictions, without considering their direction. In this case, <strong>GBM_grid_1_AutoML_93_20240930_00046_model_57</strong> has the lowest MAE at <strong>3.07</strong>, indicating that its absolute prediction errors are smaller, on average, compared to other models, which have MAEs around 3.50–5.15. <strong>RMSLE</strong> (Root Mean Squared Logarithmic Error) is particularly useful when the target variable exhibits large variations. The <strong>StackedEnsemble_BestOfFamily_3_AutoML_93_20240930</strong> has an RMSLE of <strong>0.38</strong>, showing good performance in scenarios with varying target values. <strong>Mean Residual Deviance</strong> is similar to MSE and represents the average error per prediction. The <strong>GBM_grid_1_AutoML_93_20240930_00046_model_57</strong> has the lowest value at <strong>81.53</strong>, indicating strong predictive accuracy. Finally, the <strong>training time (ms)</strong> measures how long it took to train the model. The <strong>StackedEnsemble_BestOfFamily_3_AutoML_93_20240930</strong> model trained in <strong>110 milliseconds</strong>, while the <strong>GBM_grid_1_AutoML_93_20240930_00046_model_57</strong> took <strong>384 milliseconds</strong>.</p>
<div class="cell">

</div>
<section id="best-models" class="level4" data-number="4.1.1">
<h4 data-number="4.1.1" class="anchored" data-anchor-id="best-models"><span class="header-section-number">4.1.1</span> Best models</h4>
<p>To retrieve the best model based on pre-set criteria we can use the function <code>h2o.get_best_model</code>, which allow us to specify the metric that we want to use to select the best model or the algorithm (e.g., RF, GBM or GLM). To do so, we use the function <code>h2o.get_best_model()</code> with the parameter <code>automl_model</code> to obtain the best model and assign it to an R object <code>best_model</code>. In that case, <code>h2o</code> will retrieve the best model based on RMSE since it is the default ranking criteria. If you want to change that, you can use <code>criterion = "MAE"</code> for instance or other metrics e.g., RMSE.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 9: Extract the best-performing model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">h2o.get_best_model</span>(automl_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
</section>
<section id="evaluation-of-the-model" class="level4" data-number="4.1.2">
<h4 data-number="4.1.2" class="anchored" data-anchor-id="evaluation-of-the-model"><span class="header-section-number">4.1.2</span> Evaluation of the model</h4>
<p>To evaluate how the model could perform in the wild we need to use completely new data that the model has not seen before. To test the model performance with data that the model has not seen before we can use <code>h2o.performance(best_model)</code> with the parameter <code>newdata = test_data_h2o</code>. This enables us to understand what the model can do in real-life applications. The <code>h2o.performance</code> function calculates several metrics such as MSE, RMSE, MAE, and RMSLE.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 9.1: Evaluate the best model's performance on the test data</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>best_model_performance <span class="ot">&lt;-</span> <span class="fu">h2o.performance</span>(best_model, <span class="at">newdata =</span> test_data_h2o)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 9.2: Print the performance metrics on test data</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(best_model_performance)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 9.3: Generate predictions on the test data</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">h2o.predict</span>(best_model, test_data_h2o)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In our case, the metrics for the best <strong>GBM</strong> model were:</p>
<ul>
<li><strong>MSE</strong>: 159.6543</li>
<li><strong>RMSE</strong>: 12.63544</li>
<li><strong>MAE</strong>: 4.978724</li>
<li><strong>RMSLE</strong>: 0.2364497</li>
<li><strong>Mean Residual Deviance</strong>: 159.6543</li>
</ul>
<p>The <strong>RMSE</strong> indicates that the GBM model’s predictions were <strong>12.64 points</strong> on average different from the values of the target variable (learning). This RMSE suggests that the model has a reasonable level of error in predicting the target variable. Similarly, the <strong>MSE</strong> (Mean Squared Error) is <strong>159.65</strong>, which reflects the squared average of the errors, while the <strong>MAE</strong> is <strong>4.98</strong>, showing the average absolute difference between predicted and actual values. The <strong>RMSLE</strong> is <strong>0.24</strong>, which is helpful for understanding the model’s performance when the target variable has large variations. The <strong>Mean Residual Deviance</strong> is also <strong>159.65</strong>, representing the average error per prediction, which aligns with the MSE. Please note that these parameters are different than the above ones in the leaderboard table, since we evaluated the model with unseen data, and it is expected to see some drop in model performance.</p>
<p>To visualize the evaluation, we can create predictions on the test data using <code>h2o.predict(best_model, test_data_h2o)</code> to visualize the model predictions with the new data. We do so by plotting the predicted versus actual values using a scatter plot, as demonstrated below. Note that we must convert the <code>h2o</code> data frames into standard data frames to use them with traditional R packages. It may be also helpful to analyze the residuals (the differences between the actual and predicted values). Ideally, residuals should be randomly distributed around zero without any clear patterns. The code below computes the residuals, and plots them. As the figure shows, we can see that most observations are around 0 however, some extreme values are also there indicating that the model fared bad in some days. This is of course expected given the variability of daily performance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Step 2: Convert the test data and predictions to R data frames}</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>test_data_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(test_data_h2o) <span class="co"># Convert h2o test data to dataframe</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>predictions_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(predictions)<span class="co"># Convert h2o predictions to dataframe</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Combine the predictions with the original test data</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>result_df <span class="ot">&lt;-</span> <span class="fu">cbind</span>(test_data_df, <span class="at">Predicted_Learning =</span> predictions_df<span class="sc">$</span>predict)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot of actual vs predicted values</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(result_df, <span class="fu">aes</span>(<span class="at">x =</span> learning, <span class="at">y =</span> Predicted_Learning)) <span class="sc">+</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span>  <span class="co"># Scatter points</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Ideal line (y = x)</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span>  </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Actual Learning"</span>,</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Predicted Learning"</span>) <span class="sc">+</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a residual column</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>result_df <span class="ot">&lt;-</span> result_df <span class="sc">%&gt;%</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Residuals =</span> learning <span class="sc">-</span> Predicted_Learning)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatterplot of residuals vs predicted values</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(result_df, <span class="fu">aes</span>(<span class="at">x =</span> Predicted_Learning, <span class="at">y =</span> Residuals)) <span class="sc">+</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkred"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Predicted Learning"</span>,</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Residuals"</span>) <span class="sc">+</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-charts" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-charts-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-charts-1.png" class="img-fluid figure-img" data-ref-parent="fig-charts" width="576"></p>
<p></p><figcaption class="figure-caption">(a) Actual vs.&nbsp;Predicted Learning</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-charts-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-charts-2.png" class="img-fluid figure-img" data-ref-parent="fig-charts" width="576"></p>
<p></p><figcaption class="figure-caption">(b) Residuals vs.&nbsp;Predicted Learning</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;1<strong>.</strong> Visualization of the evaluation</figcaption><p></p>
</figure>
</div>
<p>However, the best model chosen automatically by <code>h2o</code> may not be the optimal solution for every case. One has to balance accuracy, training time, and model interpretability. For instance, GBM and XGBoost are capable of handling complex relationships and often provide good predictive performance maybe computationally expensive. Random Forest (DRF) is a faster algorithm and is particularity distinguished for its inherent interpretability making it suitable when simplicity and explainaility are needed. Deep Learning is adept at capturing non-linear patterns is also computationally expensive and harder to explain. Stacked ensembles combine several models to enhance performance but increases complexity and training time. In our case, we need a model that offers performance and be explainable e.g., GBM or DRF.</p>
<p>To select a certain model, <code>h2o</code> also allows us to extract top algorithms by type by specifying them in the function call e.g., GBM, XGBoost, DRF, DeepLearning, and StackedEnsemble. To do so, we call the function <code>h2o.get_best_model</code> with the parameter <code>algorithm = "algorithm_name"</code>. For example, to get the best GBM model, we call <code>h2o.get_best_model(automl_model, algorithm = "gbm")</code> and then we store it in the object <code>best_gbm</code>. In the same way, we can get other models like the code below.</p>
<p>The next code retrieves the best performing models for various ML algorithms. Specifically, it gets the best GBM, XGBoost, Distributed Random Forest, Deep Learning, and Stacked Ensemble models, and stores them in the <code>best_gbm</code>, <code>best_xgboost</code>, <code>best_drf</code>, <code>best_deeplearning</code>, and <code>best_stackedensemble</code> variables respectively.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>best_gbm <span class="ot">&lt;-</span> <span class="fu">h2o.get_best_model</span>(automl_model, <span class="at">algorithm =</span> <span class="st">"gbm"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>best_xgboost <span class="ot">&lt;-</span> <span class="fu">h2o.get_best_model</span>(automl_model, <span class="at">algorithm =</span> <span class="st">"xgboost"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>best_drf <span class="ot">&lt;-</span> <span class="fu">h2o.get_best_model</span>(automl_model, <span class="at">algorithm =</span> <span class="st">"drf"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>best_deeplearning <span class="ot">&lt;-</span> <span class="fu">h2o.get_best_model</span>(automl_model, <span class="at">algorithm =</span> <span class="st">"deeplearning"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>best_stackedensemble <span class="ot">&lt;-</span> <span class="fu">h2o.get_best_model</span>(automl_model, <span class="at">algorithm =</span> <span class="st">"stackedensemble"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<p>Explainability offers better transparency and helps build trust in the model’s decisions. This is especially useful when making critical decisions based on ML predictions. The <code>h2o</code> package offers several well-crafted functions for evaluating the models with rich visualizations through <code>h2o.explain()</code>. Besides basic model performance metrics, it provides a wide range of diagnostic information and visualizations, such as variable importance, residual analysis, and prediction explanations plots. See <span class="citation" data-cites="LABOOK2_Chapter_7 LABOOK2_Chapter_6">[<a href="#ref-LABOOK2_Chapter_6" role="doc-biblioref">12</a>, <a href="#ref-LABOOK2_Chapter_7" role="doc-biblioref">13</a>]</span> for a full explanation on explainable ML models and techniques.</p>
<p>The code below runs <code>h2o.explain()</code> function to analyze and explain the behavior of the model. We here choose another model, given that we already seen the GBM model. We choose the <code>best_drf</code> (a previously trained model) to be evaluated on the <code>test_data_h2o</code>. The function generates a detailed explanation of each plot and what it means, so we will not repeat them here. Of interest to our case is the Variable Importance Plot, which ranks the variables based on their contribution to the model’s predictions. The variable importance plot shows that feedback, effort, and duration are the most influential variables in predicting learning outcomes. Other variables like help, mean pace, and steps also contribute, while factors such as planning, evaluating, and social engagement have comparatively less impact.</p>
<p>The SHAP summary plot provides detailed visualization of individual predictions by showing how much each feature contributed to pushing a prediction higher or lower for a specific observation. In SHAP plots, the x-axis represents the SHAP value (i.e., the contribution to the prediction) where positive values increasing predictions and negative values lowering them. The color scale is the normalized value of each feature (where blue is low and red is high). For instance, when effort has higher values (in red), it tends to push predictions towards the positive side of the SHAP axis, suggesting that greater effort is associated with improved learning. In contrast, lower values of effort (in blue) push the prediction towards the negative side, indicating that less effort is linked to lower predicted outcomes. Another example is the mean pace feature. Higher values of mean pace (red points) are associated with positive contributions to the prediction, while lower values (blue points) show a negative contribution. This indicates that faster pacing positively influences learning.</p>
<p><strong>Partial Dependence Plots (PDPs)</strong> show how specific variables affect predictions (given that all other variables are held constant). In other words, PDPs allow us to see to which extent a change in a certain feature influences the predicted outcome if all other variables did not change. The green line indicates that <strong>feedback</strong> has a relatively consistent impact on predictions, with a slight increase at higher values. The histogram below highlights that most feedback values fall between 50 and 80, where the predictions remain stable, suggesting minimal change in the outcome based on feedback levels within this range.</p>
<p>The <strong>Individual Conditional Expectation (ICE) plot</strong> shows how a variable affects the model’s predictions across different percentiles. For instance, in the duration plot, the x-axis represents <strong>duration</strong>, and the y-axis shows the predicted response. Each colored line represents a different percentile, with the <strong>partial dependence</strong> (dashed black line) indicating the average relationship between <strong>duration</strong> and the response. At lower <strong>duration</strong> values, predictions remain flat across percentiles, meaning the feature has little impact. However, around the 20,000 mark, predictions increase, especially for lower percentiles (e.g., the 0th percentile). This suggests that longer duration significantly improve predictions for these groups.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run h2o.explain to explain the model's behavior</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>explanained_drf <span class="ot">&lt;-</span> <span class="fu">h2o.explain</span>(best_drf, test_data_h2o)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># View the explanation output</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(explanained_drf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-printss" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-1.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(a) Residual Analysis</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-2.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(b) Learning Curve Plot</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-3.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(c) Variable Importance</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-4.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(d) SHAP Summary</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-5.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(e) Partial Dependence Plot (feedback)</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-6" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-6.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(f) Partial Dependence Plot (effort)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-7" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-7.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(g) Partial Dependence Plot (duration)</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-8" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-8.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(h) Partial Dependence Plot (help)</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-9" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-9.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(i) Partial Dependence Plot (meanpace)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-10" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-10.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(j) Individual Conditional Expectations (feedback)</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-11" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-11.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(k) Individual Conditional Expectations (effort)</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-12" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-12.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(l) Individual Conditional Expectations (duration)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-13" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-13.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(m) Individual Conditional Expectations (help)</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-printss-14" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-printss-14.png" class="img-fluid figure-img" data-ref-parent="fig-printss" width="672"></p>
<p></p><figcaption class="figure-caption">(n) Individual Conditional Expectations (meanpace)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;2<strong>.</strong> Explainer</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="multiple-idiographic-models" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="multiple-idiographic-models"><span class="header-section-number">4.2</span> Multiple idiographic models</h3>
<p>In the previous steps, we have automated the process of finding the best performing model for one of our students (Alice). As mentioned before, manually creating —and fine tuning— a unique model for each individual is an exhausting time-consuming process and can be impractical when done for several dozens of students as in our case. The AutoML implemented by <code>h2o</code> automates this process by handling model selection, hyperparameter tuning, evaluating and reporting the best models (<a href="#fig-idio-method">Figure&nbsp;<span>22.3</span></a>). This is where precise <code>h2o</code> AutoML offers an efficient solution that require little interference and offers individualized ML. In fact, this is the case in most of the cases where idiographic models are estimated when we have to deal with multiple people and here where <code>h2o</code> and AutoML becomes more compelling to use.</p>
<div id="fig-idio-method" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/idio.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;3<strong>.</strong> AutoML as a tool for idiographic ML</figcaption><p></p>
</figure>
</div>
<p>Since each student’s data patterns may be rather different, the best algorithm may vary from one to another. One student might have better results with GBM, while another might see more accurate predictions from an RF model. AutoML ensures that the best-performing model is chosen based on the characteristics of each person’s data, optimizing the predictions on a per-person basis (idiographically). Also, each individual’s dataset may require different hyperparameter tuning—a functionality that AutoML handles efficiently. Thus, <code>h2o</code> ensures that the model for each individual is not only correctly selected but also fine-tuned for best performance for each individual. The next code, goes through finding the best model for each student in our dataset. The process is technically similar to before, however, with a main difference is that we will <strong>loop</strong> through each person and use <code>h2o</code> to find the best model as we did before for the single individual.</p>
<section id="estimating-multiple-algorithms" class="level4" data-number="4.2.1">
<h4 data-number="4.2.1" class="anchored" data-anchor-id="estimating-multiple-algorithms"><span class="header-section-number">4.2.1</span> Estimating multiple algorithms</h4>
<p>Similar to what we did in training of the single idiographic model, we begin by loading the necessary libraries: <code>dplyr</code> for data manipulation and <code>h2o</code> for model training. We read the <code>synthetic_Data_share.RDS</code> using <code>readRDS()</code> which contains the data for the individual students. We the define the predictors, the phone activity variables that capture aspects like mean pace, steps, and screen frequency, and the SRL variables which captures students’ SRL as well as self-efficacy and emotions e.g., anxiety and enjoyment. We then combine the variables into a single vector and define the response variable, <code>learning</code> as the target for our prediction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)  <span class="co"># For data manipulation</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(h2o)    <span class="co"># For H2O ML platform</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">265</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in the dataset</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>synthetic_data <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"synthetic_Data_share.RDS"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the phone activity variables</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>phone_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"meanpace"</span>, <span class="st">"steps"</span>, <span class="st">"freqscreen"</span>, <span class="st">"duration"</span>, </span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"scrrenoff"</span>, <span class="st">"nightduroff"</span>, <span class="st">"maxoffscreennight"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the SRL variables</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>srl_vars <span class="ot">&lt;-</span> <span class="fu">colnames</span>(<span class="fu">select</span>(synthetic_data, efficacy<span class="sc">:</span>enjoyment))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine all variables into the Predictors list</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> <span class="fu">c</span>(srl_vars, phone_vars)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the response variable</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>response_variable <span class="ot">&lt;-</span> <span class="st">"learning"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, to do the estimation, we begin by initializing the <code>h2o</code> cluster with <code>h2o.init(nthreads = -1, max_mem_size = "12G")</code>. This command ensures that <code>h2o</code> uses all available CPU threads (<code>nthreads = -1</code>) and caps memory usage at 12GB (<code>max_mem_size = "12G"</code>). Since we are creating idiographic models for each person individually we need to allocate sufficient computational resources for the intensive tasks of fitting several hundred models running on multiple datasets.</p>
<p>Our dataset has a name field <code>name</code> that identifies each student dataset. Here, we use <code>unique(synthetic_data$name)</code> to extract all distinct names and later isolate their data. We will later use the list of <code>dataset_names</code> to loop through each person’s data. Inside the loop, we start by filtering the current person data person data. Given that the name is not a predictor, we need to remove the name column too, we do so by using <code>filtered_data &lt;- synthetic_data %&gt;% filter(name == specific_name)</code> to isolate the rows for the individual currently being processed, and <code>select(-name)</code> to remove the <code>name</code> column since it’s no longer needed in the modeling process. After we have filtered the data for the currently modeled student, it needs to be converted to <code>h2o</code>’s data frame format. For that we use the function <code>as.h2o(filtered_data)</code> as we did before in the individual model. The next steps are familiar by now, and entail splitting the data into training and testing datasets using <code>h2o.splitFrame(data = h2o_data, ratios = 0.8, seed = 256)</code>. We split the data here into 80% for training and 20% for testing (so the the model can be evaluated on new unseen data). We also seed <code>seed = 256</code> to ensure that the split remains consistent if we run the model again.</p>
<p>Next, we run <code>h2o.automl()</code> for that student to automatically train multiple ML models on the individual’s training data. We use the <code>predictors</code> list with all the input features (the self-regulated learning variables and phone activity data), and <code>response_variable</code> is set to <code>learning</code> the outcome we want to predict. We also set <code>max_runtime_secs = 300</code> to specify how long the AutoML process runs for each individual, please that this number is used here for demonstration purposes and you are advised to use higher numbers.</p>
<p>Having trained the model, we can get the best model using <code>h2o.get_best_model(automl_model)</code> to retrieve the best-performing model for the individual. This model is chosen based on its performance (and more specifically based on RMSE which is the default criterion). The next step, we evaluate the model performance on the test data (the unseen data) using <code>h2o.performance(best_model, newdata = test_data_h2o).</code></p>
<p>In the last step, we store each student’s data, the best model, and the evaluation results into a list named <code>results</code> which contains for each <code>specific_name</code>:</p>
<ul>
<li><strong>TrainingData</strong>: The data used to train the model.</li>
<li><strong>TestData</strong>: The data used to evaluate the model’s performance.</li>
<li><strong>AutoMLModel</strong>: The full AutoML object containing all the models tried during the AutoML process.</li>
<li><strong>BestModel</strong>: The best performing model chosen by AutoML.</li>
<li><strong>Performance</strong>: The performance metrics of the best model on the test data.</li>
</ul>
<p>Storing these components helps to easily access and compare the models across individuals. For example, we can later retrieve the best model for any individual and review its performance on the test data and compare or aggregate or study the patterns.</p>
<p>The last two lines of code print the performance of each model for each student. As the reader can see, we created a loop that iterates through the data and performs the basic steps of analysis that we learned in the single person example for each person in our sample, and stores the results in the R object <code>results.</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize h2o with specified resources</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">h2o.init</span>(<span class="at">nthreads =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">max_mem_size =</span> <span class="st">"60G"</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get unique dataset names (subsets)</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>dataset_names <span class="ot">&lt;-</span> <span class="fu">unique</span>(synthetic_data<span class="sc">$</span>name)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2202</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a list to store results for each subset</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through each unique dataset (name)</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (specific_name <span class="cf">in</span> dataset_names) {</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Filter the dataset for the current subset and remove the 'name' column</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>  filtered_data <span class="ot">&lt;-</span> synthetic_data <span class="sc">%&gt;%</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(name <span class="sc">==</span> specific_name) <span class="sc">%&gt;%</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>name)  <span class="co"># Exclude the 'name' column</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Convert the filtered data into an h2o frame</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>  h2o_data <span class="ot">&lt;-</span> <span class="fu">as.h2o</span>(filtered_data)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Split the h2o frame into training (80%) and testing (20%) sets</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  splits <span class="ot">&lt;-</span> <span class="fu">h2o.splitFrame</span>(<span class="at">data =</span> h2o_data, <span class="at">ratios =</span> <span class="fl">0.8</span>, <span class="at">seed =</span> <span class="dv">256</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>  train_data_h2o <span class="ot">&lt;-</span> splits[[<span class="dv">1</span>]]  <span class="co"># Training data (80%)</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>  test_data_h2o <span class="ot">&lt;-</span> splits[[<span class="dv">2</span>]]   <span class="co"># Testing data (20%)</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Train the model using h2o AutoML</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>  automl_model <span class="ot">&lt;-</span> <span class="fu">h2o.automl</span>(</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> predictors,</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> response_variable,</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">training_frame =</span> train_data_h2o,</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">nfolds =</span> <span class="dv">5</span>,</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">max_runtime_secs =</span> <span class="dv">300</span>,  <span class="co"># Adjust this as needed</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">256</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get the best model</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>  best_model <span class="ot">&lt;-</span> <span class="fu">h2o.get_best_model</span>(automl_model,<span class="at">algorithm=</span> <span class="fu">c</span>( <span class="st">"drf"</span>, <span class="st">"gbm"</span>,</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>                                                              <span class="st">"glm"</span>, <span class="st">"xgboost"</span>))</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Evaluate the best model on the test data</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>  performance <span class="ot">&lt;-</span> <span class="fu">h2o.performance</span>(best_model, <span class="at">newdata =</span> test_data_h2o)</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Store the data, models, and performance for the current subset</span></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>  results[[specific_name]] <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    <span class="at">TrainingData =</span> train_data_h2o,</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">TestData =</span> test_data_h2o,</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">AutoMLModel =</span> automl_model,</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">BestModel =</span> best_model,</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>    <span class="at">Performance =</span> performance</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
</section>
<section id="extracting-and-plotting-performance-metrics-for-multiple-data-sets" class="level4" data-number="4.2.2">
<h4 data-number="4.2.2" class="anchored" data-anchor-id="extracting-and-plotting-performance-metrics-for-multiple-data-sets"><span class="header-section-number">4.2.2</span> Extracting and Plotting Performance Metrics for Multiple Data sets</h4>
<p>After training all the models, now we extract the performance metrics for the multiple datasets and visualize them. We will do so by iterating through the results to extract the performance metrics, and create plots to visualize the distributions of metrics. To store the metrics, we need to create an empty data frame with columns corresponding to the metrics we want to collect: <strong>RMSE</strong>, <strong>MSE</strong>, <strong>MAE</strong>, and <strong>R²</strong>. The <code>Dataset</code> column will store the names of each student to be able to link the results to students. We retrieve the performance object we computed before for the student: <code>results[[dataset_name]]$Performance</code> and then use the function <code>h2o.rmse()</code>, <code>h2o.mse()</code>, <code>h2o.mae()</code>, and <code>h2o.r2()</code> to we extract the values and store it <code>performance_data</code>. To plot the data, we will have to reshape it: convert it from wide to long format to make it easier plotting with <strong>ggplot2</strong>. In doing so, each row will represent one metric and its corresponding value for a dataset which allows us to have a single graph with multiple facets (sub-plots). Finally, we use <strong>ggplot2</strong> to create histograms for each metric (see last step in <a href="#fig-idio-method">Figure&nbsp;<span>22.3</span></a>).</p>
<p>The plots show the distribution of the best idiographic individualized models e.g., <strong>MAE, MSE, RMSE, R².</strong> In the <strong>MAE</strong> plot, which measures the average absolute difference between predicted and actual values, we can see a relatively even spread across values ranging from around 2.5 to 7.5. This spread suggests that most models have a moderate error rate. Similarly, the <strong>RMSE</strong> plot, which places greater emphasis on larger errors, shows a wide range of values from around 4 to 16, indicating variability in prediction quality across different models. The <strong>MSE</strong> plot reflects squared errors, showing a heavier concentration between 0 and 150, with only a few outliers, meaning that while most models are performing relatively well, a few may struggle with larger errors. The <strong>R²</strong> (Coefficient of Determination) plot indicates the proportion of variance explained by the model, shows an interesting spread where most <strong>R²</strong> values are concentrated between 0.5 and 1.0, indicating that the models perform well in explaining the variance for most datasets, excluding “Diana.”</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize an empty dataframe to store performance metrics</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>performance_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Dataset =</span> <span class="fu">character</span>(), <span class="at">RMSE =</span> <span class="fu">numeric</span>(), </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>                               <span class="at">MSE =</span> <span class="fu">numeric</span>(), <span class="at">MAE =</span> <span class="fu">numeric</span>(), </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>                               <span class="at">R2 =</span> <span class="fu">numeric</span>(), <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through the results list and extract performance metrics directly</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># from results$Performance</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (dataset_name <span class="cf">in</span> <span class="fu">names</span>(results)) {</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Extract performance metrics directly from the results list</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  performance <span class="ot">&lt;-</span> results[[dataset_name]]<span class="sc">$</span>Performance</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Extract individual performance metrics (RMSE, MSE, MAE, R2) from </span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># already computed data</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  rmse_value <span class="ot">&lt;-</span> <span class="fu">h2o.rmse</span>(performance)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>  mse_value <span class="ot">&lt;-</span> <span class="fu">h2o.mse</span>(performance)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>  mae_value <span class="ot">&lt;-</span> <span class="fu">h2o.mae</span>(performance)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>  r2_value <span class="ot">&lt;-</span> <span class="fu">h2o.r2</span>(performance)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Append the extracted metrics to the performance dataframe</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>  performance_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(performance_data, <span class="fu">data.frame</span>(</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">Dataset =</span> dataset_name,</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">RMSE =</span> rmse_value,</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">MSE =</span> mse_value,</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">MAE =</span> mae_value,</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">R2 =</span> r2_value</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape the data to long format for easier plotting with ggplot</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>performance_data_long <span class="ot">&lt;-</span> performance_data <span class="sc">%&gt;%</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(<span class="at">key =</span> <span class="st">"Metric"</span>, <span class="at">value =</span> <span class="st">"Value"</span>, <span class="sc">-</span>Dataset) <span class="sc">%&gt;%</span> </span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span>(Metric <span class="sc">==</span> <span class="st">"R2"</span> <span class="sc">&amp;</span> Dataset <span class="sc">==</span> <span class="st">"Diana"</span>)) </span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(performance_data_long, <span class="fu">aes</span>(<span class="at">x =</span> Value)) <span class="sc">+</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">10</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"skyblue"</span>) <span class="sc">+</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> Metric, <span class="at">scales =</span> <span class="st">"free"</span>) <span class="sc">+</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Distribution of Performance Metrics"</span>, </span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-distper" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-distper-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;4<strong>.</strong> Distribution of Performance Metrics</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="explanatory-variables" class="level4" data-number="4.2.3">
<h4 data-number="4.2.3" class="anchored" data-anchor-id="explanatory-variables"><span class="header-section-number">4.2.3</span> Explanatory variables</h4>
<p>Having plotted the evaluation metrics, now we extract the top five most important variables for each student based on the best model stored in the <code>results</code> list that we created before. The code similarly loops through each student’s data, retrieves the variable importance from their best model, and stores the top variables in the <code>top_variables</code> list. The code begins by creating an empty list called <code>top_variables</code>. This list will serve as a container for storing the top five variables for each student as we loop through the <code>results</code> list. As the loop iterates over the <code>results</code> list, it first extracts the name of each student and the corresponding “best” model for that student. This model is extracted using <code>results[[student_name]]$BestModel</code>. Then we extract the important variables using <code>h2o.varimp(best_model)</code> function. This function returns the variables ranked by their contribution to the model’s predictive power.</p>
<p>From this table of variables, the script selects the top five variables by using the <code>head(varimp[, "variable"], 5)</code> function. These variables are then stored in the <code>top_variables</code> list under the student’s name making it easy to analyze and compare across different models.</p>
<p>The process is repeated for each student in the dataset, so that every individual’s top variables are extracted and stored. Once the loop has finished, the <code>top_variables</code> list contains a detailed mapping of the top five variables for every student. At the end of the script, we can view or inspect the <code>top_variables</code> list to see the most important variables for each student. We offer a summary plot also for the most frequent variables and their ranking to examine which variables were most frequent, for instance, at frist position.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize an empty dataframe to store variable positions for plotting</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>variable_positions <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Variable =</span> <span class="fu">character</span>(), <span class="at">Position =</span> <span class="fu">integer</span>(), </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop through each student and collect variable positions</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (student_name <span class="cf">in</span> <span class="fu">names</span>(top_variables)) {</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get the top 5 variables for the student</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  top_vars <span class="ot">&lt;-</span> top_variables[[student_name]]</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Ensure we only process students with valid top 5 variables</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.null</span>(top_vars) <span class="sc">||</span> <span class="fu">length</span>(top_vars) <span class="sc">==</span> <span class="dv">0</span>) <span class="cf">next</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Assign position 1 to 5 to each variable and store in dataframe</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(top_vars)) {</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    variable_positions <span class="ot">&lt;-</span> <span class="fu">rbind</span>(variable_positions, </span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>                                <span class="fu">data.frame</span>(<span class="at">Variable =</span> top_vars[i], <span class="at">Position =</span> i))</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the total frequency of each variable and arrange them in descending order</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>variable_positions <span class="ot">&lt;-</span> variable_positions <span class="sc">%&gt;%</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Variable) <span class="sc">%&gt;%</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Frequency =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(Frequency))</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up a color palette using RColorBrewer</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>my_colors <span class="ot">&lt;-</span> <span class="fu">brewer.pal</span>(<span class="dv">10</span>, <span class="st">"Set3"</span>)  <span class="co"># Choose a color palette with 5 colors</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the frequency of variables in each position, arranged by overall frequency</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(variable_positions, </span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="sc">-</span>Frequency), <span class="at">fill =</span> <span class="fu">as.factor</span>(Position))) <span class="sc">+</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position =</span> <span class="st">"stack"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> my_colors) <span class="sc">+</span>  <span class="co"># Apply the selected color palette</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Variable"</span>, </span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Frequency"</span>, </span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>       <span class="at">fill =</span> <span class="st">"Position"</span>) <span class="sc">+</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>)) <span class="co"># Rotate x-axis labels </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-freqvar" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch22-automl_files/figure-html/fig-freqvar-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;5<strong>.</strong> Frequency of Variables in Top 5 Positions (Sorted by Frequency)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">

</div>
</section>
</section>
</section>
<section id="conclusion" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">5</span> Conclusion</h2>
<p>In this chapter, we have learned how to implement an AutoML pipeline covering several common ML algorithms. The tutorial has illustrated how to replicate this pipeline across multiple datasets belonging to different individuals, each resulting into an optimized model that most accurately predicts said individual. As exemplified, this technique is very suitable to be able to scale up idiographic analysis <span class="citation" data-cites="LABOOK2_Chapter_18">[<a href="#ref-LABOOK2_Chapter_18" role="doc-biblioref">15</a>]</span>, since it requires that each individual has its very own model: a task that becomes unfeasible as the number of individuals increases. We demonstrate how AutoML simplifies the ML pipeline, enabling the creation of individually optimized models for multiple datasets efficiently. Moreover, we illustrate how to apply explainable AI techniques to automate the description of the main features and characteristics of each model. The complete pipeline demonstrated in the chapter holds potential to provide automated real-time insights based on idiographic analysis in a transparent and trustable way <span class="citation" data-cites="Lopez-Pernas_undated-qd">[<a href="#ref-Lopez-Pernas_undated-qd" role="doc-biblioref">42</a>]</span>.</p>
<p>However, idiographic analysis is not the only use case for AutoML. AutoML can be used as an alternative to manual analysis <span class="citation" data-cites="LABOOK2_Chapter_3 LABOOK2_Chapter_4">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">10</a>, <a href="#ref-LABOOK2_Chapter_4" role="doc-biblioref">11</a>]</span> in any other case since, as mentioned before, empirical results show AutoML models perform better than —or at least on par with– human-made models. AutoML is especially useful in scenarios that require continuous update of the models, for example real-time dashboards or adaptive learning systems, where it is impossible for a person to perform all of the steps of the ML pipeline in time to provide useful insights. Lastly, it should be noted that AutoML can be used for use cases beyond prediction, such as clustering <span class="citation" data-cites="Saqr2025-tu">[<a href="#ref-Saqr2025-tu" role="doc-biblioref">43</a>]</span>, for example, enabling the automatic detection of students’ groups or profiles.</p>


</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-mishra2012predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Mishra N, Silakari S (2012) Predictive analytics: A survey, trends, applications, oppurtunities &amp; challenges. International Journal of Computer Science and Information Technologies 3:4434–4438</div>
</div>
<div id="ref-jovanovic2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Jovanovic J, López-Pernas S, Saqr M (2024) <a href="https://doi.org/10.1007/978-3-031-54464-4_7">Predictive Modelling in Learning Analytics: A Machine Learning Approach in R</a>. Springer Nature Switzerland, pp 197–229</div>
</div>
<div id="ref-predicti2017" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Brooks C, Thompson C (2017) <a href="https://doi.org/10.18608/hla17.005">Predictive modelling in teaching and learning</a>. Society for Learning Analytics Research (SoLAR), pp 61–68</div>
</div>
<div id="ref-saqr2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Saqr M, Jovanovic J, Viberg O, Gašević D (2022) Is there order in the mess? A single paper meta-analysis approach to identification of predictors of success in learning analytics. Studies in Higher Education 47:2370–2391. https://doi.org/<a href="https://doi.org/10.1080/03075079.2022.2061450">10.1080/03075079.2022.2061450</a></div>
</div>
<div id="ref-Shmueli2011-cn" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Shmueli G, Koppius OR (2011) <a href="https://misq.umn.edu/predictive-analytics-in-information-systems-research.html">Predictive analytics in information systems research</a>. MIS Quarterly 35:553–572</div>
</div>
<div id="ref-Adesina2024-dc" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Adesina AA, Iyelolu TV, Paul PO (2024) Leveraging predictive analytics for strategic decision-making: Enhancing business performance through data-driven insights. World J Adv Res Rev 22:1927–1934. https://doi.org/<a href="https://doi.org/10.30574/wjarr.2024.22.3.1961">10.30574/wjarr.2024.22.3.1961</a></div>
</div>
<div id="ref-Olaniyi2023-hc" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Olaniyi O, Shah NH, Abalaka A, Olaniyi FG (2023) Harnessing predictive analytics for strategic foresight: A comprehensive review of techniques and applications in transforming raw data to actionable insights. SSRN Electron J. <a href="https://doi.org/10.2139/ssrn.4635189">https://doi.org/10.2139/ssrn.4635189</a></div>
</div>
<div id="ref-saqr2024a" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Saqr M, Cheng R, López-Pernas S, Beck ED (2024) Idiographic artificial intelligence to explain students’ self-regulation: Toward precision education. Learning and Individual Differences 114:102499. https://doi.org/<a href="https://doi.org/10.1016/j.lindif.2024.102499">10.1016/j.lindif.2024.102499</a></div>
</div>
<div id="ref-LABOOK2_Chapter_2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">López-Pernas S, Oliveira E, Song Y, Saqr M (2025) AI, explainable AI and evaluative AI: An introduction to informed data-driven decision-making in education. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_3" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Saqr M, Misiejuk K, Tikka S, López-Pernas S (2025) Artificial intelligence: Using machine learning to predict students’ performance. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Saqr M, Misiejuk K, Tikka S, López-Pernas S (2025) Artificial intelligence: Using machine learning to classify students and predict low achievers. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2025) Explainable artificial intelligence in education: A tutorial for identifying the variables that matter. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2025) Individualized explainable artificial intelligence: A tutorial for identifying local and individual predictions. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_20" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Saqr M, Dever D, López-Pernas S (2025) Idiographic networks: A tutorial on graphical vector autoregression and unified structural equation modeling. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_18" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">Saqr M, Ito H, López-Pernas S (2025) A comprehensive introduction to idiographic and within-person analytics. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-saqr2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Saqr M, Lopez-Pernas S (2021) Idiographic learning analytics: A definition and a case study. 2021 International Conference on Advanced Learning Technologies (ICALT) 163–165. https://doi.org/<a href="https://doi.org/10.1109/icalt52272.2021.00056">10.1109/icalt52272.2021.00056</a></div>
</div>
<div id="ref-ito2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Ito H, López-Pemas S, Saqr M (2024) A scoping review of idiographic research in education: Too little, but not too late. 2024 IEEE International Conference on Advanced Learning Technologies (ICALT) 10–12. https://doi.org/<a href="https://doi.org/10.1109/icalt61570.2024.00010">10.1109/icalt61570.2024.00010</a></div>
</div>
<div id="ref-saqr2023" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Saqr M (2023) Modelling within<span>-</span>person idiographic variance could help explain and individualize learning. British Journal of Educational Technology 54:1077–1094. https://doi.org/<a href="https://doi.org/10.1111/bjet.13309">10.1111/bjet.13309</a></div>
</div>
<div id="ref-saqr2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">Saqr M (2024) Group-level analysis of engagement poorly reflects individual students<span>’</span> processes: Why we need idiographic learning analytics. Computers in Human Behavior 150:107991. https://doi.org/<a href="https://doi.org/10.1016/j.chb.2023.107991">10.1016/j.chb.2023.107991</a></div>
</div>
<div id="ref-h2o" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Fryda T, LeDell E, Gill N, Aiello S, Fu A, Candel A, Click C, Kraljevic T, Nykodym T, Aboyoun P, Kurka M, Malohlava M, Poirier S, Wong W (2024) <a href="https://github.com/h2oai/h2o-3">h2o: R interface for the ’H2O’ scalable machine learning platform</a></div>
</div>
<div id="ref-Tornede2023-ex" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Tornede A, Deng D, Eimer T, Giovanelli J, Mohan A, Ruhkopf T, Segel S, Theodorakopoulos D, Tornede T, Wachsmuth H, Lindauer M (2023) <a href="http://arxiv.org/abs/2306.08107"><span>AutoML</span> in the age of large language models: Current challenges, future opportunities and risks</a>. arXiv [csLG]</div>
</div>
<div id="ref-Garmpis2022-vk" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline">Garmpis S, Maragoudakis M, Garmpis A (2022) Assisting educational analytics with <span>AutoML</span> functionalities. Computers 11:97. https://doi.org/<a href="https://doi.org/10.3390/computers11060097">10.3390/computers11060097</a></div>
</div>
<div id="ref-Shen2018-eb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline">Shen Z, Zhang Y, Wei L, Zhao H, Yao Q (2018) <a href="http://arxiv.org/abs/1810.13306">Automated machine learning: From principles to practices</a>. arXiv [csAI]</div>
</div>
<div id="ref-he2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline">He X, Zhao K, Chu X (2021) AutoML: A survey of the state-of-the-art. Knowledge-Based Systems 212:106622. https://doi.org/<a href="https://doi.org/10.1016/j.knosys.2020.106622">10.1016/j.knosys.2020.106622</a></div>
</div>
<div id="ref-asurvey2023" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline">(2023) A survey of the state-of-the-art AutoML tools and their comparisons. International Journal of Advanced Natural Sciences and Engineering Researches. <a href="https://doi.org/10.59287/as-ijanser.570">https://doi.org/10.59287/as-ijanser.570</a></div>
</div>
<div id="ref-Elsken2019-ua" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline">Elsken T, Metzen JH, Hutter F (2019) <a href="http://jmlr.org/papers/v20/18-598.html">Neural architecture search: A survey</a>. J Mach Learn Res 20:1–21</div>
</div>
<div id="ref-Barbudo2023-of" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline">Barbudo R, Ventura S, Romero JR (2023) Eight years of <span>AutoML</span>: Categorisation, review and trends. Knowl Inf Syst 65:5097–5149. https://doi.org/<a href="https://doi.org/10.1007/s10115-023-01935-1">10.1007/s10115-023-01935-1</a></div>
</div>
<div id="ref-Del-Valle2023-lq" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline">Del Valle AM, Mantovani RG, Cerri R (2023) A systematic literature review on <span>AutoML</span> for multi-target learning tasks. Artif Intell Rev 56:2013–2052. https://doi.org/<a href="https://doi.org/10.1007/s10462-023-10569-2">10.1007/s10462-023-10569-2</a></div>
</div>
<div id="ref-Feurer2015-bb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline">Feurer M, Klein A, Eggensperger K, Springenberg J, Blum M, Hutter F (2015) <a href="https://proceedings.neurips.cc/paper_files/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf">Efficient and robust automated machine learning</a>. Advances in Neural Information Processing Systems 28:</div>
</div>
<div id="ref-Oliveira2024-ce" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline">Oliveira S de, Topsakal O, Toker O (2024) Benchmarking automated machine learning (<span>AutoML</span>) frameworks for object detection. Information (Basel) 15:63. https://doi.org/<a href="https://doi.org/10.3390/info15010063">10.3390/info15010063</a></div>
</div>
<div id="ref-Thirunavukarasu2023-en" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline">Thirunavukarasu AJ, Elangovan K, Gutierrez L, Li Y, Tan I, Keane PA, Korot E, Ting DSW (2023) Democratizing artificial intelligence imaging analysis with automated machine learning: tutorial. J Med Internet Res 25:e49949. https://doi.org/<a href="https://doi.org/10.2196/49949">10.2196/49949</a></div>
</div>
<div id="ref-Castellanos-Nieves2023-oz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline">Castellanos-Nieves D, García-Forte L (2023) Improving automated machine-learning systems through green <span>AI</span>. Appl Sci (Basel) 13:11583. https://doi.org/<a href="https://doi.org/10.3390/app132011583">10.3390/app132011583</a></div>
</div>
<div id="ref-Zhao2024-kk" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">33. </div><div class="csl-right-inline">Zhao Y, Wang P (2024) <a href="https://doi.org/10.1109/eebda60612.2024.10485809">The investigation of student’s online learning adaptability level prediction based on <span>AutoML</span></a>. In: 2024 IEEE 3rd international conference on electrical engineering, big data and algorithms (EEBDA). IEEE, pp 74–79</div>
</div>
<div id="ref-Bosch2021-ws" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">34. </div><div class="csl-right-inline">Bosch N (2021) <span>AutoML</span> feature engineering for student modeling yields high accuracy, but limited interpretability. JEDM 13:55–79. https://doi.org/<a href="https://doi.org/10.5281/ZENODO.5275314">10.5281/ZENODO.5275314</a></div>
</div>
<div id="ref-Bunay-Guisnan2024-hx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">35. </div><div class="csl-right-inline">Buñay-Guisñan P, Lara JA, Cano A, Cerezo R, Romero C (2024) <a href="https://doi.org/10.5281/ZENODO.12729972">Easing the prediction of student dropout for everyone integrating <span>AutoML</span> and explainable artificial intelligence</a>. 857–861</div>
</div>
<div id="ref-Tsiakmaki2021-vr" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">36. </div><div class="csl-right-inline">Tsiakmaki M, Kostopoulos G, Kotsiantis S, Ragos O (2021) Fuzzy-based active learning for predicting student academic performance using <span class="nocase">autoML</span>: A step-wise approach. J Comput High Educ 33:635–667. https://doi.org/<a href="https://doi.org/10.1007/s12528-021-09279-x">10.1007/s12528-021-09279-x</a></div>
</div>
<div id="ref-Tikka2024-ph" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">37. </div><div class="csl-right-inline">Tikka S, Kopra J, Heinäniemi M, López-Pernas S, Saqr M (2024) Getting started with <span>R</span> for education research. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Kopra2024-fx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">38. </div><div class="csl-right-inline">Kopra J, Tikka S, Heinäniemi M, López-Pernas S, Saqr M (2024) An <span>R</span> approach to data cleaning and wrangling for education research. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Tikka2024-wl" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">39. </div><div class="csl-right-inline">Tikka S, Kopra J, Heinäniemi M, López-Pernas S, Saqr M (2024) Introductory statistics with <span>R</span> for educational researchers. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Lopez-Pernas2024-ge" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">40. </div><div class="csl-right-inline">López-Pernas S, Misiejuk K, Tikka S, Kopra J, Heinäniemi M, Saqr M (2024) <a href="https://doi.org/10.1007/978-3-031-54464-4\_6">Visualizing and reporting educational data with <span>R</span></a>. In: Learning analytics methods and tutorials. Springer Nature Switzerland, Cham, pp 151–194</div>
</div>
<div id="ref-saqr2024b" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">41. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2024) Mapping the self in self<span>-</span>regulation using complex dynamic systems approach. British Journal of Educational Technology 55:1376–1397. https://doi.org/<a href="https://doi.org/10.1111/bjet.13452">10.1111/bjet.13452</a></div>
</div>
<div id="ref-Lopez-Pernas_undated-qd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">42. </div><div class="csl-right-inline">López-Pernas S, Saqr M (2021) <a href="https://www.researchgate.net/profile/Sonsoles-Lopez-Pernas/publication/350886273_Idiographic_Learning_Analytics_A_Within-Person_Ethical_Perspective/links/607839718ea909241efea6f5/Idiographic-Learning-Analytics-A-Within-Person-Ethical-Perspective.pdf">Idiographic learning analytics: A within-person ethical perspective</a>. researchgatenet</div>
</div>
<div id="ref-Saqr2025-tu" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">43. </div><div class="csl-right-inline">Saqr M, López-Pernas S, Törmänen T, Vogelsmeier LVDE (2025) Stability within and heterogeneity between: An idiographic approach to the temporal dynamics of momentary self-regulated learning. In: Proceedings of the 15th international conference on learning analytics and knowledge. SoLAR; ACM, pp in–press</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/ch21-mle/ch21-mle.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimator</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
  </div>
</footer>
<script>
  document.querySelector(".quarto-title").innerHTML =  '<div class="badge bs-warning bg-warning text-dark" style="float:right;">Pre-print</div>' +  document.querySelector(".quarto-title").innerHTML
  var keywords = document.querySelector('meta[name="keywords"]')
  if (keywords && keywords.content) {
    document.getElementById("title-block-header").innerHTML = document.getElementById("title-block-header").innerHTML + 
      '<div class="abstract"><div class="abstract-title">Keywords</div><div class="quarto-title-meta-contents"><p>'+
      keywords.content +
      '</p></div></div>'
  }
  function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(newNode, referenceNode.nextSibling);
  }
  var authors = document.querySelectorAll('meta[name="author"]')
  if (authors) {
    var authorlist = Array.from(authors).map(e=>e.content).reduce((accum, curr) =>  accum + curr + ", ", "","").replace(/\,\s$/,"")
    var citt = `<div class="card border-primary mb-3" style=;">
      <div class="card-header bg-primary">To cite this chapter</div>
      <div class="card-body small">
        <p class="card-text">${authorlist} (2025).
        <b>${document.getElementsByClassName("chapter-title")[0].innerText}</b>. 
        In M. Saqr & S. López-Pernas (Eds.), <i>Advanced Learning Analytics Methods: AI, Precision and Complexity</i> 
        (in – press). Springer. <a href="${window.location.href}">${window.location.href}</a></p>
      </div>
    </div>`;
    insertAfter(document.getElementsByTagName("HEADER")[1],new DOMParser().parseFromString(citt, 'text/html').body.childNodes[0])
  }
</script>



</body></html>
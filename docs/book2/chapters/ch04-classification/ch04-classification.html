<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mohammed Saqr">
<meta name="author" content="Kamila Misiejuk">
<meta name="author" content="Santtu Tikka">
<meta name="author" content="Sonsoles López-Pernas">
<meta name="keywords" content="learning analytics, predictive modeling, classification, machine learning, artificial intelligence">

<title>Advanced learning analytics methods - 4&nbsp; Artificial Intelligence: Using Machine Learning to Classify Students and Predict Low Achievers</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/ch05-regularization/ch05-regularization.html" rel="next">
<link href="../../chapters/ch03-prediction/ch03-prediction.html" rel="prev">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y4VBV3J9WD"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y4VBV3J9WD', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  

<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Advanced learning analytics methods - 4&nbsp; Artificial Intelligence: Using Machine Learning to Classify Students and Predict Low Achievers">
<meta name="twitter:description" content="This chapter addresses the classification of at-risk students in educational settings using machine learning approaches in R.">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="[4]{.chapter-number}&nbsp; [Artificial Intelligence: Using Machine Learning to Classify Students and Predict Low Achievers]{.chapter-title}">
<meta name="citation_abstract" content="This chapter addresses the classification of at-risk students in educational settings using machine learning approaches in R. Transitioning from regression-based predictions of students’ grades covered by the previous chapter, the focus here shifts to identifying broader categories of academic performance, such as low achievers or potential dropouts. Early identification of such students enables timely interventions, one of the main goals of learning analytics. The process is first illustrated through a Random Forest classifier, using engagement indicators to classify students into high and low achievers. The chapter demonstrates the complete modeling workflow, including data preparation, model training, and evaluation using performance metrics. Additionally, the `tidymodels` framework is explored as a more modern alternative that enables easy comparison with other AI / machine learning algorithms like Naive Bayes or Support Vector Machine.">
<meta name="citation_keywords" content="learning analytics, predictive modeling, classification, machine learning, artificial intelligence">
<meta name="citation_author" content="Mohammed Saqr">
<meta name="citation_author" content="Kamila Misiejuk">
<meta name="citation_author" content="Santtu Tikka">
<meta name="citation_author" content="Sonsoles López-Pernas">
<meta name="citation_fulltext_html_url" content="https://lamethods.github.io/ch04-classification.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Students matter the most in learning analytics: The effects of internal and instructional conditions in predicting academic success;,citation_abstract=Predictive modelling of academic success and retention has been a key research theme in Learning Analytics. While the initial work on predictive model…;,citation_author=Jelena Jovanović;,citation_author=Mohammed Saqr;,citation_author=Srećko Joksimović;,citation_author=Dragan Gašević;,citation_publication_date=2021-10;,citation_cover_date=2021-10;,citation_year=2021;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.compedu.2021.104251;,citation_issue=104251;,citation_doi=10.1016/j.compedu.2021.104251;,citation_issn=0360-1315,1873-782X;,citation_volume=172;,citation_journal_title=Comput. Educ.;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=An r approach to data cleaning and wrangling for education research;,citation_author=Juho Kopra;,citation_author=Santtu Tikka;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Introductory statistics with r for educational researchers;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics;,citation_author=Anuradha Mathrani;,citation_author=Teo Susnjak;,citation_author=Gomathy Ramaswami;,citation_author=Andre Barczak;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=2;,citation_journal_title=Computers and Education Open;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Predictive modelling in learning analytics: A machine learning approach in r;,citation_author=Jelena Jovanovic;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Implementing a learning analytics intervention and evaluation framework: What works?;,citation_author=Bart Rienties;,citation_author=Simon Cross;,citation_author=Zdenek Zdrahal;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Big data and learning analytics in higher education: Current theory and practice;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Learning analytics dashboards are increasingly becoming about learning and not just analytics-a systematic review;,citation_author=Lucas Paulsen;,citation_author=Euan Lindsay;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_journal_title=Education and Information Technologies;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Use of predictive analytics within learning analytics dashboards: A review of case studies;,citation_author=Gomathy Ramaswami;,citation_author=Teo Susnjak;,citation_author=Anuradha Mathrani;,citation_author=Rahila Umer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=3;,citation_volume=28;,citation_journal_title=Technology, Knowledge and Learning;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Early alert of academically at-risk students: An open source analytics initiative;,citation_author=Sandeep M Jayaprakash;,citation_author=Erik W Moody;,citation_author=Eitel JM Lauría;,citation_author=James R Regan;,citation_author=Joshua D Baron;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=1;,citation_journal_title=Journal of Learning Analytics;">
<meta name="citation_reference" content="citation_title=Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics;,citation_author=Anuradha Mathrani;,citation_author=Teo Susnjak;,citation_author=Gomathy Ramaswami;,citation_author=Andre Barczak;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=2;,citation_journal_title=Computers and Education Open;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=A systematic review of learning analytics intervention contributing to student success in online learning;,citation_author=Kew Si Na;,citation_author=Zaidatun Tasir;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 international conference on learning and teaching in computing and engineering (LaTICE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Predicting at-risk students using clickstream data in the virtual learning environment;,citation_author=Naif Radi Aljohani;,citation_author=Ayman Fayoumi;,citation_author=Saeed-Ul Hassan;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=24;,citation_volume=11;,citation_journal_title=Sustainability;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Do predictive analytics dream of risk-free education? The politics of risk mitigation;,citation_author=Irina Zakharova;,citation_author=Juliane Jarke;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=6;,citation_journal_title=Postdigital Science and Education;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=A predictive analytics framework as a countermeasure for attrition of students;,citation_author=Andreas F Gkontzis;,citation_author=Sotiris Kotsiantis;,citation_author=Christos T Panagiotakopoulos;,citation_author=Vassilios S Verykios;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=6;,citation_volume=30;,citation_journal_title=Interactive Learning Environments;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Elements of success: Supporting at-risk student resilience through learning analytics;,citation_author=Jae-Eun Russell;,citation_author=Anna Smith;,citation_author=Russell Larsen;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=152;,citation_journal_title=Computers &amp;amp;amp; Education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Improving retention: Predicting at-risk students by analysing clicking behaviour in a virtual learning environment;,citation_author=Annika Wolff;,citation_author=Zdenek Zdrahal;,citation_author=Andriy Nikolov;,citation_author=Michal Pantucek;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the third international conference on learning analytics and knowledge;">
<meta name="citation_reference" content="citation_title=From prediction to impact: Evaluation of a learning analytics retention program;,citation_author=Shane Dawson;,citation_author=Jelena Jovanovic;,citation_author=Dragan Gašević;,citation_author=Abelardo Pardo;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=Proceedings of the seventh international learning analytics &amp;amp;amp; knowledge conference;">
<meta name="citation_reference" content="citation_title=Predictive learning analytics in online education: A deeper understanding through explaining algorithmic errors;,citation_author=Martin Hlosta;,citation_author=Christothea Herodotou;,citation_author=Tina Papathoma;,citation_author=Anna Gillespie;,citation_author=Per Bergamin;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=3;,citation_journal_title=Computers and Education: Artificial Intelligence;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Detecting students-at-risk in computer programming classes with learning analytics from students’ digital footprints;,citation_author=David Azcona;,citation_author=I-Han Hsiao;,citation_author=Alan F Smeaton;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=29;,citation_journal_title=User Modeling and User-Adapted Interaction;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=The effectiveness of learning analytics for identifying at-risk students in higher education;,citation_author=Ed Foster;,citation_author=Rebecca Siddle;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=6;,citation_volume=45;,citation_journal_title=Assessment &amp;amp;amp; Evaluation in Higher Education;,citation_publisher=Taylor &amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Early prediction of at-risk students in secondary education: A countrywide k-12 learning analytics initiative in uruguay;,citation_author=Emanuel Marques Queiroga;,citation_author=Matheus Francisco Batista Machado;,citation_author=Virgı́nia Rodés Paragarino;,citation_author=Tiago Thompsen Primo;,citation_author=Cristian Cechinel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=9;,citation_volume=13;,citation_journal_title=Information;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Predicting at-risk students in an online flipped anatomy course using learning analytics;,citation_author=Alper Bayazit;,citation_author=Nihal Apaydin;,citation_author=Ipek Gonullu;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=9;,citation_volume=12;,citation_journal_title=Education Sciences;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=How learning analytics can early predict under-achieving students in a blended medical education course;,citation_author=Mohammed Saqr;,citation_author=Uno Fors;,citation_author=Matti Tedre;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=7;,citation_volume=39;,citation_journal_title=Medical teacher;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Predictive analytics study to determine undergraduate students at risk of dropout;,citation_author=Andres Gonzalez-Nucamendi;,citation_author=Julieta Noguez;,citation_author=Luis Neri;,citation_author=Víctor Robledo-Rella;,citation_author=Rosa María Guadalupe García-Castelán;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=8;,citation_conference_title=Frontiers in education;">
<meta name="citation_reference" content="citation_title=A learning analytics dashboard for moodle: Implementing machine learning techniques to early detect students at risk of failure;,citation_author=Cristian Cechinel;,citation_author=Mateus De Freitas Dos Santos;,citation_author=Caio Barrozo;,citation_author=Jesiel Emerim Schardosim;,citation_author=Eduardo Vila;,citation_author=Vinicius Ramos;,citation_author=Tiago Primo;,citation_author=Roberto Munoz;,citation_author=Emanuel Marques Queiroga;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=2021 XVI latin american conference on learning technologies (LACLO);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Identifying at-risk students in online learning by analysing learning behaviour: A systematic review;,citation_author=Kew Si Na;,citation_author=Zaidatun Tasir;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE conference on big data and analytics (ICBDA);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Predicting at-risk students at different percentages of course length for early intervention using machine learning models;,citation_author=Muhammad Adnan;,citation_author=Asad Habib;,citation_author=Jawad Ashraf;,citation_author=Shafaq Mussadiq;,citation_author=Arsalan Ali Raza;,citation_author=Muhammad Abid;,citation_author=Maryam Bashir;,citation_author=Sana Ullah Khan;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=9;,citation_journal_title=IEEE Access;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=How does learning analytics contribute to prevent students’ dropout in higher education: A systematic literature review;,citation_author=Catarina Félix Oliveira;,citation_author=Sónia Rolland Sobral;,citation_author=Maria João Ferreira;,citation_author=Fernando Moreira;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=4;,citation_volume=5;,citation_journal_title=Big Data and Cognitive Computing;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Intelligent predictive analytics for identifying students at risk of failure in moodle courses;,citation_author=Theodoros Anagnostopoulos;,citation_author=Christos Kytagias;,citation_author=Theodoros Xanthopoulos;,citation_author=Ioannis Georgakopoulos;,citation_author=Ioannis Salmon;,citation_author=Yannis Psaromiligkos;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=Intelligent tutoring systems: 16th international conference, ITS 2020, athens, greece, june 8–12, 2020, proceedings 16;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=A learning analytics approach to identify students at risk of dropout: A case study with a technical distance education course;,citation_author=Emanuel Marques Queiroga;,citation_author=João Ladislau Lopes;,citation_author=Kristofer Kappel;,citation_author=Marilton Aguiar;,citation_author=Ricardo Matsumura Araújo;,citation_author=Roberto Munoz;,citation_author=Rodolfo Villarroel;,citation_author=Cristian Cechinel;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=11;,citation_volume=10;,citation_journal_title=Applied Sciences;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Learning analytics at low cost: At-risk student prediction with clicker data and systematic proactive interventions;,citation_author=Samuel PM Choi;,citation_author=Sze Sing Lam;,citation_author=Kam Cheong Li;,citation_author=Billy TM Wong;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=2;,citation_volume=21;,citation_journal_title=Journal of Educational Technology &amp;amp;amp; Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Recent advances in predictive learning analytics: A decade systematic review (2012–2022);,citation_author=Nabila Sghir;,citation_author=Amina Adadi;,citation_author=Mohammed Lahmer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=7;,citation_volume=28;,citation_journal_title=Education and information technologies;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Six practical recommendations enabling ethical use of predictive learning analytics in distance education.;,citation_author=Irina Rets;,citation_author=Christothea Herodotou;,citation_author=Anna Gillespie;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=1;,citation_volume=10;,citation_journal_title=Journal of Learning Analytics;,citation_publisher=ERIC;">
<meta name="citation_reference" content="citation_title=Learning analytics should not promote one size fits all: The effects of instructional conditions in predicting academic success;,citation_author=Dragan Gašević;,citation_author=Shane Dawson;,citation_author=Tim Rogers;,citation_author=Danijela Gasevic;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=28;,citation_journal_title=The Internet and Higher Education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Student performance prediction via online learning behavior analytics;,citation_author=Wei Zhang;,citation_author=Xujun Huang;,citation_author=Shengming Wang;,citation_author=Jiangbo Shu;,citation_author=Hai Liu;,citation_author=Hao Chen;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 international symposium on educational technology (ISET);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Relations between student online learning behavior and academic achievement in higher education: A learning analytics approach;,citation_author=Il-Hyun Jo;,citation_author=Taeho Yu;,citation_author=Hyeyun Lee;,citation_author=Yeonjoo Kim;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Emerging issues in smart learning;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Applying learning analytics to predict the student’s learning outcome based on online learning activities;,citation_author=Viet Anh Nguyen;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=Proceedings of the 2024 10th international conference on frontiers of educational technologies;">
<meta name="citation_reference" content="citation_title=Educational data mining for predicting students’ academic performance using machine learning algorithms;,citation_author=Pranav Dabhade;,citation_author=Ravina Agarwal;,citation_author=KP Alameen;,citation_author=AT Fathima;,citation_author=R Sridharan;,citation_author=G Gopakumar;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=47;,citation_journal_title=Materials Today: Proceedings;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Predicting academic success in higher education: Literature review and best practices;,citation_author=Eyman Alyahyan;,citation_author=Dilek Düştegör;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=17;,citation_journal_title=International Journal of Educational Technology in Higher Education;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Resampling strategies for imbalanced regression: A survey and empirical analysis;,citation_author=Juscimara G Avelino;,citation_author=George DC Cavalcanti;,citation_author=Rafael MO Cruz;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=4;,citation_volume=57;,citation_journal_title=Artificial Intelligence Review;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Student performance prediction using support vector machine and k-nearest neighbor;,citation_author=Huda Al-Shehri;,citation_author=Amani Al-Qarni;,citation_author=Leena Al-Saati;,citation_author=Arwa Batoaq;,citation_author=Haifa Badukhen;,citation_author=Saleh Alrashed;,citation_author=Jamal Alhiyafi;,citation_author=Sunday O Olatunji;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE 30th canadian conference on electrical and computer engineering (CCECE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Contextualizing the current state of research on the use of machine learning for student performance prediction: A systematic literature review;,citation_author=Khalid Alalawi;,citation_author=Rukshan Athauda;,citation_author=Raymond Chiong;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=12;,citation_volume=5;,citation_journal_title=Engineering Reports;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Learning models for student performance prediction;,citation_author=Rafael Cavazos;,citation_author=Sara Elena Garza;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Advances in computational intelligence: 16th mexican international conference on artificial intelligence, MICAI 2017, enseneda, mexico, october 23-28, 2017, proceedings, part II 16;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=An overview and comparison of supervised data mining techniques for student exam performance prediction;,citation_author=Nikola Tomasevic;,citation_author=Nikola Gvozdenovic;,citation_author=Sanja Vranes;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=143;,citation_journal_title=Computers &amp;amp;amp; education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Generating actionable predictive models of academic performance;,citation_author=Abelardo Pardo;,citation_author=Negin Mirriahi;,citation_author=Roberto Martinez-Maldonado;,citation_author=Jelena Jovanovic;,citation_author=Shane Dawson;,citation_author=Dragan Gašević;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the sixth international conference on learning analytics &amp;amp;amp; knowledge;">
<meta name="citation_reference" content="citation_title=Construct and consequential validity for learning analytics based on trace data;,citation_author=Philip H. Winne;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=112;,citation_journal_title=Computers in Human Behavior;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics;,citation_author=Anuradha Mathrani;,citation_author=Teo Susnjak;,citation_author=Gomathy Ramaswami;,citation_author=Andre Barczak;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=2;,citation_journal_title=Computers and Education Open;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=A systematic meta-review and analysis of learning analytics research;,citation_author=Xu Du;,citation_author=Juan Yang;,citation_author=Brett E Shelton;,citation_author=Jui-Long Hung;,citation_author=Mingyan Zhang;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=1;,citation_volume=40;,citation_journal_title=Behaviour &amp;amp;amp; information technology;,citation_publisher=Taylor &amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Predicting student performance using data mining and learning analytics techniques: A systematic literature review;,citation_author=Abdallah Namoun;,citation_author=Abdullah Alshanqiti;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=11;,citation_journal_title=Applied Sciences;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Predictive modelling in teaching and learning;,citation_author=Christopher Brooks;,citation_author=Craig Thompson;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Handbook of learning analytics;,citation_publisher=Society for Learning Analytics Research Beaumont;">
<meta name="citation_reference" content="citation_title=Predictive analytics;,citation_author=Wayne W Eckerson;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=1;,citation_journal_title=Extending the Value of Your Data Warehousing Investment. TDWI Best Practices Report;">
<meta name="citation_reference" content="citation_title=Designing learning analytics experiences;,citation_author=Abelardo Pardo;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_inbook_title=Learning analytics: From research to practice;">
<meta name="citation_reference" content="citation_title=Random forests;,citation_abstract=Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund &amp;amp;amp; R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.;,citation_author=Leo Breiman;,citation_publication_date=2001-10;,citation_cover_date=2001-10;,citation_year=2001;,citation_fulltext_html_url=https://doi.org/10.1023/A:1010933404324;,citation_issue=1;,citation_doi=10.1023/A:1010933404324;,citation_issn=0885-6125,1573-0565;,citation_volume=45;,citation_journal_title=Mach. Learn.;">
<meta name="citation_reference" content="citation_title=The longitudinal association between engagement and achievement varies by time, students’ profiles, and achievement state: A full program study;,citation_abstract=There is a paucity of longitudinal studies in online learning across courses or throughout programs. Our study intends to add to this emerging body of research by analyzing the longitudinal trajectories of interaction between student engagement and achievement over a full four-year program. We use learning analytics and life-course methods to study how achievement and engagement are intertwined and how such relationship evolves over a full program for 106 students. Our findings have indicated that the association between engagement and achievement varies between students and progresses differently between such groups over time. Our results showed that online engagement at any single time-point is not a consistent indicator for high achievement. It takes more than a single point of time to reliably forecast high achievement throughout the program. Longitudinal high grades, or longitudinal high levels of engagement (either separately or combined) were indicators of a stable academic trajectory in which students remained engaged —at least on average— and had a higher level of achievement. On the other hand, disengagement at any time point was consistently associated with lower achievement among low-engaged students. Improving to a higher level of engagement was associated with —at least— acceptable achievement levels and rare dropouts. Lack of improvement or “catching up” may be a more ominous sign that should be proactively addressed.;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Satu Helske;,citation_author=Stefan Hrastinski;,citation_publication_date=2023-07;,citation_cover_date=2023-07;,citation_year=2023;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0360131523000647;,citation_doi=10.1016/j.compedu.2023.104787;,citation_issn=0360-1315;,citation_volume=199;,citation_journal_title=Comput. Educ.;">
<meta name="citation_reference" content="citation_title=Visualizing and reporting educational data with R;,citation_abstract=AbstractVisualizing data is central in learning analytics research, underpins learning dashboards, and is a prime method for reporting results and insights to stakeholders. In this chapter, the reader will be guided through the process of generating meaningful and aesthetically pleasing visualizations of different types of student data using well-known R packages. The main visualization types will be demonstrated with an explanation of their usage and use cases. Furthermore, learning-related examples will be discussed in detail. For instance, readers will learn how to visualize learners’ logs extracted from learning management systems to show how trace data can be used to track students’ learning activities. In addition to creating compelling plots, readers will also be able to generate professional-looking tables with summary statistics.;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://link.springer.com/chapter/10.1007/978-3-031-54464-4_6;,citation_doi=10.1007/978-3-031-54464-4\_6;,citation_isbn=9783031544637,9783031544644;,citation_inbook_title=Learning analytics methods and tutorials;">
<meta name="citation_reference" content="citation_title=Welcome to the tidyverse;,citation_author=Hadley Wickham;,citation_author=Mara Averick;,citation_author=Jennifer Bryan;,citation_author=Winston Chang;,citation_author=Lucy D’Agostino McGowan;,citation_author=Romain François;,citation_author=Garrett Grolemund;,citation_author=Alex Hayes;,citation_author=Lionel Henry;,citation_author=Jim Hester;,citation_author=Max Kuhn;,citation_author=Thomas Lin Pedersen;,citation_author=Evan Miller;,citation_author=Stephan Milton Bache;,citation_author=Kirill Müller;,citation_author=Jeroen Ooms;,citation_author=David Robinson;,citation_author=Dana Paige Seidel;,citation_author=Vitalie Spinu;,citation_author=Kohske Takahashi;,citation_author=Davis Vaughan;,citation_author=Claus Wilke;,citation_author=Kara Woo;,citation_author=Hiroaki Yutani;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=43;,citation_doi=10.21105/joss.01686;,citation_volume=4;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=Methods and algorithms for correlation analysis in R;,citation_author=Dominique Makowski;,citation_author=Mattan Ben-Shachar;,citation_author=Indrajeet Patil;,citation_author=Daniel Lüdecke;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_fulltext_html_url=https://joss.theoj.org/papers/10.21105/joss.02306;,citation_issue=51;,citation_doi=10.21105/joss.02306;,citation_issn=2475-9066;,citation_volume=5;,citation_journal_title=J. Open Source Softw.;,citation_publisher=The Open Journal;">
<meta name="citation_reference" content="citation_title=Skimr: Compact and flexible summaries of data;,citation_author=Elin Waring;,citation_author=Michael Quinn;,citation_author=Amelia McNamara;,citation_author=Eduardo Arino de la Rubia;,citation_author=Hao Zhu;,citation_author=Shannon Ellis;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=skimr;">
<meta name="citation_reference" content="citation_title=Rio: A swiss-army knife for data file i/o;,citation_author=Chung-hong Chan;,citation_author=Thomas J. Leeper;,citation_author=Jason Becker;,citation_author=David Schoch;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://cran.r-project.org/package=rio;">
<meta name="citation_reference" content="citation_title=Performance: An R package for assessment, comparison and testing of statistical models;,citation_author=Daniel Lüdecke;,citation_author=Mattan Ben-Shachar;,citation_author=Indrajeet Patil;,citation_author=Philip Waggoner;,citation_author=Dominique Makowski;,citation_publication_date=2021-04;,citation_cover_date=2021-04;,citation_year=2021;,citation_fulltext_html_url=https://joss.theoj.org/papers/10.21105/joss.03139;,citation_issue=60;,citation_doi=10.21105/joss.03139;,citation_issn=2475-9066;,citation_volume=6;,citation_journal_title=J. Open Source Softw.;,citation_publisher=The Open Journal;">
<meta name="citation_reference" content="citation_title=Classification and regression by randomForest;,citation_author=Andy Liaw;,citation_author=Matthew Wiener;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://CRAN.R-project.org/doc/Rnews/;,citation_issue=3;,citation_volume=2;,citation_journal_title=R News;">
<meta name="citation_reference" content="citation_title=Building predictive models in r using the caret package;,citation_author=Kuhn;,citation_author=Max;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_fulltext_html_url=https://www.jstatsoft.org/index.php/jss/article/view/v028i05;,citation_issue=5;,citation_doi=10.18637/jss.v028.i05;,citation_volume=28;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Rsample: General resampling infrastructure;,citation_author=Hannah Frick;,citation_author=Fanny Chow;,citation_author=Max Kuhn;,citation_author=Michael Mahoney;,citation_author=Julia Silge;,citation_author=Hadley Wickham;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=rsample;">
<meta name="citation_reference" content="citation_title=Yardstick: Tidy characterizations of model performance;,citation_author=Max Kuhn;,citation_author=Davis Vaughan;,citation_author=Emil Hvitfeldt;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=yardstick;">
<meta name="citation_reference" content="citation_title=Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles.;,citation_author=Max Kuhn;,citation_author=Hadley Wickham;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://www.tidymodels.org;">
<meta name="citation_reference" content="citation_title=pROC: An open-source package for r and s+ to analyze and compare ROC curves;,citation_author=Xavier Robin;,citation_author=Natacha Turck;,citation_author=Alexandre Hainard;,citation_author=Natalia Tiberti;,citation_author=Frédérique Lisacek;,citation_author=Jean-Charles Sanchez;,citation_author=Markus Müller;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=BMC Bioinformatics;">
<meta name="citation_reference" content="citation_title=Xgboost: Extreme gradient boosting;,citation_author=Tianqi Chen;,citation_author=Tong He;,citation_author=Michael Benesty;,citation_author=Vadim Khotilovich;,citation_author=Yuan Tang;,citation_author=Hyunsu Cho;,citation_author=Kailong Chen;,citation_author=Rory Mitchell;,citation_author=Ignacio Cano;,citation_author=Tianyi Zhou;,citation_author=Mu Li;,citation_author=Junyuan Xie;,citation_author=Min Lin;,citation_author=Yifeng Geng;,citation_author=Yutian Li;,citation_author=Jiaming Yuan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=xgboost;">
<meta name="citation_reference" content="citation_title=Kernlab – an S4 package for kernel methods in R;,citation_author=Alexandros Karatzoglou;,citation_author=Alex Smola;,citation_author=Kurt Hornik;,citation_author=Achim Zeileis;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=9;,citation_doi=10.18637/jss.v011.i09;,citation_volume=11;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Kknn: Weighted k-nearest neighbors;,citation_author=Klaus Schliep;,citation_author=Klaus Hechenbichler;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=https://CRAN.R-project.org/package=kknn;">
<meta name="citation_reference" content="citation_title=Modern applied statistics with s;,citation_author=W. N. Venables;,citation_author=B. D. Ripley;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://www.stats.ox.ac.uk/pub/MASS4/;">
<meta name="citation_reference" content="citation_title=Rpart: Recursive partitioning and regression trees;,citation_author=Terry Therneau;,citation_author=Beth Atkinson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=rpart;">
<meta name="citation_reference" content="citation_title=Naivebayes: High performance implementation of the naive bayes algorithm in r;,citation_author=Michal Majka;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=naivebayes;">
<meta name="citation_reference" content="citation_title=Modern applied statistics with s;,citation_author=W. N. Venables;,citation_author=B. D. Ripley;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://www.stats.ox.ac.uk/pub/MASS4/;">
<meta name="citation_reference" content="citation_title=Earth: Multivariate adaptive regression splines;,citation_author=Stephen Milborrow. Derived Trevor Hastie;,citation_author=Rob Tibshirani. Uses Alan Miller’s Fortran Thomas Lumley’s leaps wrapper.;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=earth;">
<meta name="citation_reference" content="citation_title=Dbarts: Discrete bayesian additive regression trees sampler;,citation_author=Vincent Dorie;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=dbarts;">
<meta name="citation_reference" content="citation_title=ranger: A fast implementation of random forests for high dimensional data in C++ and R;,citation_author=Marvin N. Wright;,citation_author=Andreas Ziegler;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_doi=10.18637/jss.v077.i01;,citation_volume=77;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Gbm: Generalized boosted regression models;,citation_author=Greg Ridgeway;,citation_author=GBM Developers;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=gbm;">
<meta name="citation_reference" content="citation_title=e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien;,citation_author=David Meyer;,citation_author=Evgenia Dimitriadou;,citation_author=Kurt Hornik;,citation_author=Andreas Weingessel;,citation_author=Friedrich Leisch;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=e1071;">
<meta name="citation_reference" content="citation_title=Earliest possible global and local interpretation of students’ performance in virtual learning environment by leveraging explainable AI;,citation_author=Muhammad Adnan;,citation_author=M. Irfan Uddin;,citation_author=Emel Khan;,citation_author=Fahd S. Alharithi;,citation_author=Samina Amin;,citation_author=Ahmad A. Alzahrani;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issn=2169-3536;,citation_volume=10;,citation_journal_title=IEEE Access;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Practical early prediction of students’ performance using machine learning and eXplainable AI;,citation_author=Yeonju Jang;,citation_author=Seongyune Choi;,citation_author=Heeseok Jung;,citation_author=Hyeoncheol Kim;,citation_publication_date=2022-11;,citation_cover_date=2022-11;,citation_year=2022;,citation_issue=9;,citation_issn=1360-2357;,citation_volume=27;,citation_journal_title=Education and information technologies;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Explainable artificial intelligence in education;,citation_author=Hassan Khosravi;,citation_author=Simon Buckingham Shum;,citation_author=Guanliang Chen;,citation_author=Cristina Conati;,citation_author=Yi-Shan Tsai;,citation_author=Judy Kay;,citation_author=Simon Knight;,citation_author=Roberto Martinez-Maldonado;,citation_author=Shazia Sadiq;,citation_author=Dragan Gašević;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issn=2666-920X;,citation_volume=3;,citation_journal_title=Computers and Education: Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Learner-centred analytics of feedback content in higher education;,citation_author=Jionghao Lin;,citation_author=Wei Dai;,citation_author=Lisa-Angelique Lim;,citation_author=Yi-Shan Tsai;,citation_author=Rafael Ferreira Mello;,citation_author=Hassan Khosravi;,citation_author=Dragan Gasevic;,citation_author=Guanliang Chen;,citation_publication_date=2023-03;,citation_cover_date=2023-03;,citation_year=2023;,citation_isbn=9781450398657;,citation_conference_title=LAK23: 13th international learning analytics and knowledge conference;,citation_conference=Association for Computing Machinery;,citation_series_title=LAK2023;">
<meta name="citation_reference" content="citation_title=Early detection of dropout factors in vocational education: A large-scale case study from finland;,citation_author=Sonsoles López-Pernas;,citation_author=Riina Kleimola;,citation_author=Sanna Väisänen;,citation_author=Laura Hirsto;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the 1st finnish learning analytics and artificial intelligence in education conference (FLAIEC22);">
<meta name="citation_reference" content="citation_title=Interpretable dropout prediction: Towards XAI-based personalized intervention;,citation_author=Marcell Nagy;,citation_author=Roland Molontay;,citation_publication_date=2023-03;,citation_cover_date=2023-03;,citation_year=2023;,citation_fulltext_html_url=https://doi.org/10.1007/s40593-023-00331-8;,citation_doi=10.1007/s40593-023-00331-8;,citation_issn=1560-4306;,citation_journal_title=International Journal of Artificial Intelligence in Education;">
<meta name="citation_reference" content="citation_title=Generalized mixed‐effects random forest: A flexible approach to predict university student dropout;,citation_author=Massimo Pellagatti;,citation_author=Chiara Masci;,citation_author=Francesca Ieva;,citation_author=Anna M. Paganoni;,citation_publication_date=2021-06;,citation_cover_date=2021-06;,citation_year=2021;,citation_issue=3;,citation_issn=1932-1872;,citation_volume=14;,citation_journal_title=Statistical analysis and data mining;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Explainable learning analytics: Assessing the stability of student success prediction models by means of explainable AI;,citation_author=Elena Tiukhova;,citation_author=Pavani Vemuri;,citation_author=Nidia López Flores;,citation_author=Anna Sigridur Islind;,citation_author=María Óskarsdóttir;,citation_author=Stephan Poelmans;,citation_author=Bart Baesens;,citation_author=Monique Snoeck;,citation_publication_date=2024-07;,citation_cover_date=2024-07;,citation_year=2024;,citation_issue=114229;,citation_issn=0167-9236;,citation_volume=182;,citation_journal_title=Decision support systems;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Why explainable AI may not be enough: Predictions and mispredictions in decision making in education;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1186/s40561-024-00343-4;,citation_issue=in-press;,citation_doi=10.1186/s40561-024-00343-4;,citation_issn=2196-7091;,citation_journal_title=Smart Learn. Environ.;">
<meta name="citation_reference" content="citation_title=Prospects in the field of learning and individual differences: Examining the past to forecast the future using bibliometrics;,citation_abstract=Over two centuries, research has delved into individual differences in learning across educational and professional contexts. This commentary conducts a bibliometric analysis of 6556 articles, identifying key research keywords, topics and themes, and their historical evolution. The findings revealed a longstanding emphasis on educational psychology, particularly motivation and achievement, rather than cross-curricular competencies and learner’s well-being and socio-economic background. Notably, self-regulated learning (SRL) emerged as an overarching research subject in terms of motivation and achievement, but, surprisingly, not (meta)cognition. Prospects for the field build on cross-disciplinary research, theoretical refinement, and methodological advances. Further, the field is expected to maintain academic rigor, address diversity among learners, foster global collaboration, and focus on underprivileged populations.;,citation_author=Katarzyna Bobrowicz;,citation_author=Sonsoles López-Pernas;,citation_author=Ziwen Teuber;,citation_author=Mohammed Saqr;,citation_author=Samuel Greiff;,citation_publication_date=2024-01;,citation_cover_date=2024-01;,citation_year=2024;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S1041608023001437;,citation_doi=10.1016/j.lindif.2023.102399;,citation_issn=1041-6080;,citation_volume=109;,citation_journal_title=Learn. Individ. Differ.;">
<meta name="citation_reference" content="citation_title=The 2011 horizon report;,citation_abstract=The internationally recognized series of;,citation_author=L Johnson;,citation_author=R Smith;,citation_author=H Willis;,citation_author=A Levine;,citation_author=K Haywood;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://files.eric.ed.gov/fulltext/ED515956.pdf;,citation_isbn=9780982829059;,citation_inbook_title=New media consortium;">
<meta name="citation_reference" content="citation_title=Explanatory model analysis: Explore, explain, and examine predictive models;,citation_abstract=Explanatory Model Analysis Explore, Explain and Examine Predictive Models is a set of methods and tools designed to build better predictive models and to monitor their behaviour in a changing environment. Today, the true bottleneck in predictive modelling is neither the lack of data, nor the lack of computational power, nor inadequate algorithms, nor the lack of flexible models. It is the lack of tools for model exploration (extraction of relationships learned by the model), model explanation (u;,citation_author=Przemyslaw Biecek;,citation_author=Tomasz Burzykowski;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_fulltext_html_url=https://www.routledge.com/Explanatory-Model-Analysis-Explore-Explain-and-Examine-Predictive-Models/Biecek-Burzykowski/p/book/9780367693923;,citation_isbn=9780367693923;,citation_series_title=Chapman &amp;amp;amp; hall/CRC data science series;">
<meta name="citation_reference" content="citation_title=17. A value for n-person games;,citation_abstract=17. A Value for n-Person Games was published in Contributions to the Theory of Games, Volume II on page 307.;,citation_author=L S Shapley;,citation_editor=Harold William Kuhn;,citation_editor=Albert William Tucker;,citation_publication_date=1953-12;,citation_cover_date=1953-12;,citation_year=1953;,citation_fulltext_html_url=https://www.degruyter.com/document/doi/10.1515/9781400881970-018/html?srsltid=AfmBOorG_5LaIyv5mGEqzs3IceyrU2CT3X910-__bMT6ZxIMydFWmZls;,citation_doi=10.1515/9781400881970-018;,citation_isbn=9781400881970;,citation_inbook_title=Contributions to the theory of games (AM-28), volume II;">
<meta name="citation_reference" content="citation_title=Why should I trust you?: Explaining the predictions of any classifier;,citation_author=Marco Tulio Ribeiro;,citation_author=Sameer Singh;,citation_author=Carlos Guestrin;,citation_publication_date=2016-08;,citation_cover_date=2016-08;,citation_year=2016;,citation_fulltext_html_url=https://dl.acm.org/doi/10.1145/2939672.2939778;,citation_doi=10.1145/2939672.2939778;,citation_isbn=9781450342322;,citation_conference_title=Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=DALEX: Explainers for complex predictive models in r;,citation_author=Przemyslaw Biecek;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://jmlr.org/papers/v19/18-416.html;,citation_issue=84;,citation_volume=19;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Parsnip: A common API to modeling and analysis functions;,citation_author=Max Kuhn;,citation_author=Davis Vaughan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=parsnip;">
<meta name="citation_reference" content="citation_title=Recipes: Preprocessing and feature engineering steps for modeling;,citation_author=Max Kuhn;,citation_author=Hadley Wickham;,citation_author=Emil Hvitfeldt;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=recipes;">
<meta name="citation_reference" content="citation_title=Unpacking learning in the age of AI: Bridging AI, complexity, and precision education;,citation_author=Sonsoles López-Pernas;,citation_author=Ahmed Tlili;,citation_author=Rwitajit Majumdar;,citation_author=Sami Heikkinen;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=AI, explainable AI and evaluative AI: An introduction to informed data-driven decision-making in education;,citation_author=Sonsoles López-Pernas;,citation_author=Eduardo Oliveira;,citation_author=Yige Song;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Artificial intelligence: Using machine learning to predict students’ performance;,citation_author=Mohammed Saqr;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Artificial intelligence: Using machine learning to classify students and predict low achievers;,citation_author=Mohammed Saqr;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Comparative analysis of regularization methods for predicting student certification in online courses;,citation_author=Tian Li;,citation_author=Feifei Han;,citation_author=Jiesi Guo;,citation_author=Jinran Wu;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Explainable artificial intelligence in education: A tutorial for identifying the variables that matter;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Individualized explainable artificial intelligence: A tutorial for identifying local and individual predictions;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=An introduction to large language models in education;,citation_author=Eduardo Oliveira;,citation_author=Yige Song;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The use of natural language processing in learning analytics;,citation_author=Tarid Wongvorachan;,citation_author=Okan Bulut;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Using language models for automated discourse coding: A primer and tutorial;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=LLMs for explainable artificial intelligence: Automating natural language explanations of predictive analytics models;,citation_author=Sonsoles López-Pernas;,citation_author=Yige Song;,citation_author=Eduardo Oliveira;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Complex dynamic systems in education: Beyond the static, the linear and the causal reductionism;,citation_author=Mohammed Saqr;,citation_author=Daryn Dever;,citation_author=Sonsoles López-Pernas;,citation_author=Christophe Gernigon;,citation_author=Gwen Marchand;,citation_author=Avi Kaplan;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The advanced applications of psychological networks with EGA;,citation_author=Tarid Wongvorachan;,citation_author=Okan Bulut;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Detecting nonlinear patterns in education research: A tutorial on recurrence quantification analysis;,citation_author=Daryn Dever;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Mapping relational dynamics with transition network analysis: A primer and tutorial;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Capturing the breadth and dynamics of the temporal processes with frequency transition network analysis: A primer and tutorial;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Mining patterns and clusters with transition network analysis: A heterogeneity approach;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=A comprehensive introduction to idiographic and within-person analytics;,citation_author=Mohammed Saqr;,citation_author=Hibiki Ito;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The three levels of analysis: Variable-centered, person-centered and person-specific analysis in education;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Idiographic networks: A tutorial on graphical vector autoregression and unified structural equation modeling;,citation_author=Mohammed Saqr;,citation_author=Daryn Dever;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Detecting long-memory psychological processes in academic settings using whittle’s maximum likelihood estimator: An application with r;,citation_author=Rémi Altamore;,citation_author=Clément Roume;,citation_author=Anne Teboul;,citation_author=Christophe Gernigon;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Automating individualized machine learning and AI prediction using AutoML: The case of idiographic predictions;,citation_author=Mohammed Saqr;,citation_author=Ahmed Tlili;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Getting started with R for education research;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Introductory statistics with R for educational researchers;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=An R approach to data cleaning and wrangling for education research;,citation_author=Juho Kopra;,citation_author=Santtu Tikka;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Visualizing and reporting educational data with R;,citation_abstract=AbstractVisualizing data is central in learning analytics research, underpins learning dashboards, and is a prime method for reporting results and insights to stakeholders. In this chapter, the reader will be guided through the process of generating meaningful and aesthetically pleasing visualizations of different types of student data using well-known R packages. The main visualization types will be demonstrated with an explanation of their usage and use cases. Furthermore, learning-related examples will be discussed in detail. For instance, readers will learn how to visualize learners’ logs extracted from learning management systems to show how trace data can be used to track students’ learning activities. In addition to creating compelling plots, readers will also be able to generate professional-looking tables with summary statistics.;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://link.springer.com/chapter/10.1007/978-3-031-54464-4_6;,citation_doi=10.1007/978-3-031-54464-4\_6;,citation_isbn=9783031544637,9783031544644;,citation_inbook_title=Learning analytics methods and tutorials;">
<meta name="citation_reference" content="citation_title=Is there order in the mess? A single paper meta-analysis approach to identification of predictors of success in learning analytics;,citation_author=Mohammed Saqr;,citation_author=Jelena Jovanovic;,citation_author=Olga Viberg;,citation_author=Dragan Gašević;,citation_publication_date=2022-04-11;,citation_cover_date=2022-04-11;,citation_year=2022;,citation_fulltext_html_url=http://dx.doi.org/10.1080/03075079.2022.2061450;,citation_issue=12;,citation_doi=10.1080/03075079.2022.2061450;,citation_volume=47;,citation_language=en;,citation_journal_title=Studies in Higher Education;">
<meta name="citation_reference" content="citation_title=High resolution temporal network analysis to understand and improve collaborative learning;,citation_author=Mohammed Saqr;,citation_author=Jalal Nouri;,citation_publication_date=2020-03-23;,citation_cover_date=2020-03-23;,citation_year=2020;,citation_fulltext_html_url=http://dx.doi.org/10.1145/3375462.3375501;,citation_doi=10.1145/3375462.3375501;,citation_journal_title=Proceedings of the Tenth International Conference on Learning Analytics &amp;amp;amp; Knowledge;">
<meta name="citation_reference" content="citation_title=Big data and the emerging ethical challenges;,citation_author=Mohammed Saqr;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=4;,citation_volume=11;,citation_journal_title=International journal of health sciences;,citation_publisher=Qassim University;">
<meta name="citation_reference" content="citation_title=Predicting student performance from LMS data: A comparison of 17 blended courses using moodle LMS;,citation_author=Rianne Conijn;,citation_author=Chris Snijders;,citation_author=Ad Kleingeld;,citation_author=Uwe Matzat;,citation_publication_date=2017-01-01;,citation_cover_date=2017-01-01;,citation_year=2017;,citation_fulltext_html_url=http://dx.doi.org/10.1109/tlt.2016.2616312;,citation_issue=1;,citation_doi=10.1109/tlt.2016.2616312;,citation_volume=10;,citation_journal_title=IEEE Transactions on Learning Technologies;">
<meta name="citation_reference" content="citation_title=A systematic review of literature reviews on artificial intelligence in education (AIED): a roadmap to a future research agenda;,citation_author=Muhammad Yasir Mustafa;,citation_author=Ahmed Tlili;,citation_author=Georgios Lampropoulos;,citation_author=Ronghuai Huang;,citation_author=Petar Jandrić;,citation_author=Jialu Zhao;,citation_author=Soheil Salha;,citation_author=Lin Xu;,citation_author=Santosh Panda;,citation_author=undefined Kinshuk;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024-12-09;,citation_cover_date=2024-12-09;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1186/s40561-024-00350-5;,citation_issue=1;,citation_doi=10.1186/s40561-024-00350-5;,citation_volume=11;,citation_language=en;,citation_journal_title=Smart Learning Environments;">
<meta name="citation_reference" content="citation_title=Idiographic artificial intelligence to explain students’ self-regulation: Toward precision education;,citation_author=Mohammed Saqr;,citation_author=Rongxin Cheng;,citation_author=Sonsoles López-Pernas;,citation_author=Emorie D Beck;,citation_publication_date=2024-08;,citation_cover_date=2024-08;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.lindif.2024.102499;,citation_doi=10.1016/j.lindif.2024.102499;,citation_volume=114;,citation_language=en;,citation_journal_title=Learning and Individual Differences;">
<meta name="citation_reference" content="citation_title=Have learning analytics dashboards lived up to the hype? A systematic review of impact on students’ achievement, motivation, participation and attitude;,citation_author=Rogers Kaliisa;,citation_author=Kamila Misiejuk;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammad Khalil;,citation_author=Mohammed Saqr;,citation_publication_date=2024-03-18;,citation_cover_date=2024-03-18;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1145/3636555.3636884;,citation_doi=10.1145/3636555.3636884;,citation_journal_title=Proceedings of the 14th Learning Analytics and Knowledge Conference;">
<meta name="citation_reference" content="citation_title=How social network analysis can be used to monitor online collaborative learning and guide an informed intervention;,citation_author=Mohammed Saqr;,citation_author=Uno Fors;,citation_author=Matti Tedre;,citation_author=Jalal Nouri;,citation_editor=Petter Holme;,citation_publication_date=2018-03-22;,citation_cover_date=2018-03-22;,citation_year=2018;,citation_fulltext_html_url=http://dx.doi.org/10.1371/journal.pone.0194777;,citation_issue=3;,citation_doi=10.1371/journal.pone.0194777;,citation_volume=13;,citation_language=en;,citation_journal_title=PLOS ONE;">
<meta name="citation_reference" content="citation_title=The longitudinal trajectories of online engagement over a full program;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.compedu.2021.104325;,citation_doi=10.1016/j.compedu.2021.104325;,citation_volume=175;,citation_language=en;,citation_journal_title=Computers &amp;amp;amp; Education;">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">LA Methods</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../book1/index.html">
 <span class="menu-text">Learning Analytics Methods and Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../book2/index.html">
 <span class="menu-text">Advanced Learning Analytics Methods</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/lamethods/code2/"><i class="bi bi-github" role="img" aria-label="Source Code">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Artificial Intelligence: Using Machine Learning to Classify Students and Predict Low Achievers</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contributors.html" class="sidebar-item-text sidebar-link">Contributors</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch01-intro/ch01-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Artificial Intelligence</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch02-AIxAI/ch02-aixai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI and XAI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch03-prediction/ch03-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Prediction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch04-classification/ch04-classification.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch05-regularization/ch05-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regularization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch06-xai-global/ch06-xai-global.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Global XAI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch07-xai-local/ch07-xai-local.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Local XAI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Large Language Models</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch08-llms/ch08-llms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Large Language Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch09-nlp/ch09-nlp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch10-bert/ch10-bert.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Classification with BERT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch11-llmsxai/ch11-llmsxai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Automated feedback with XAI and LLMs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Complex Systems</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch12-cds/ch12-cds.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Complex Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch13-ega/ch13-ega.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Exploratory Graph Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch14-rqa/ch14-rqa.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Recurrent Quantification Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch15-tna/ch15-tna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Transition Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch16-ftna/ch16-ftna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Frequency-based Transition Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch17-tna-clusters/ch17-tna-clusters.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Transition Network Analysis Clusters</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Idiographic</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch18-idio/ch18-idio.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Within-person analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch19-three-levels/ch19-three-levels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Heterogeneity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch20-var/ch20-var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Vector Autoregression and uSEM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch21-mle/ch21-mle.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch22-automl/ch22-automl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Automated Machine Learning</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">1</span>  Introduction</a></li>
  <li><a href="#previous-research-on-identifying-at-risk-students" id="toc-previous-research-on-identifying-at-risk-students" class="nav-link" data-scroll-target="#previous-research-on-identifying-at-risk-students"><span class="toc-section-number">2</span>  Previous research on identifying at-risk students</a></li>
  <li><a href="#classifying-students-with-r" id="toc-classifying-students-with-r" class="nav-link" data-scroll-target="#classifying-students-with-r"><span class="toc-section-number">3</span>  Classifying students with R</a>
  <ul class="collapse">
  <li><a href="#tutorial-1-a-traditional-classification-approach-with-random-forest" id="toc-tutorial-1-a-traditional-classification-approach-with-random-forest" class="nav-link" data-scroll-target="#tutorial-1-a-traditional-classification-approach-with-random-forest"><span class="toc-section-number">3.1</span>  Tutorial 1: A traditional classification approach with Random Forest</a></li>
  <li><a href="#splitting-the-data-into-training-and-testing-sets" id="toc-splitting-the-data-into-training-and-testing-sets" class="nav-link" data-scroll-target="#splitting-the-data-into-training-and-testing-sets"><span class="toc-section-number">3.2</span>  Splitting the data into training and testing sets</a></li>
  <li><a href="#creating-and-training-the-model" id="toc-creating-and-training-the-model" class="nav-link" data-scroll-target="#creating-and-training-the-model"><span class="toc-section-number">3.3</span>  Creating and training the model</a></li>
  <li><a href="#evaluating-the-model" id="toc-evaluating-the-model" class="nav-link" data-scroll-target="#evaluating-the-model"><span class="toc-section-number">3.4</span>  Evaluating the model</a></li>
  <li><a href="#tutorial-2-an-alternative-implementation-of-random-forests-with-tidymodels" id="toc-tutorial-2-an-alternative-implementation-of-random-forests-with-tidymodels" class="nav-link" data-scroll-target="#tutorial-2-an-alternative-implementation-of-random-forests-with-tidymodels"><span class="toc-section-number">3.5</span>  Tutorial 2: An alternative implementation of random forests with <code>tidymodels</code></a></li>
  <li><a href="#tutorial-3-evaluating-multiple-models-with-tidymodels" id="toc-tutorial-3-evaluating-multiple-models-with-tidymodels" class="nav-link" data-scroll-target="#tutorial-3-evaluating-multiple-models-with-tidymodels"><span class="toc-section-number">3.6</span>  Tutorial 3: Evaluating multiple models with <code>tidymodels</code></a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="toc-section-number">4</span>  Discussion</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
</nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<a href="https://github.com/lamethods/code2" target="_blank"> <button class="btn btn-outline-dark"> <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 496 512" style="width: 22px;vertical-align: text-top;margin-right: 9px;"> <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" style="width: 24px;"> </path> </svg>Download code </button> </a>
<div style="padding: 10px;">
Check out our previous book! <br> <a href="../../../book1/index.html"><img src="../../../book1/1712067211600.jpeg" style="
     width: 70%;
 "></a>
</div>
<p><br> <small>© 2025 The authors</small></p>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Artificial Intelligence: Using Machine Learning to Classify Students and Predict Low Achievers</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Mohammed Saqr </p>
             <p>Kamila Misiejuk </p>
             <p>Santtu Tikka </p>
             <p>Sonsoles López-Pernas </p>
          </div>
  </div>
    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    This chapter addresses the classification of at-risk students in educational settings using machine learning approaches in R. Transitioning from regression-based predictions of students’ grades covered by the previous chapter, the focus here shifts to identifying broader categories of academic performance, such as low achievers or potential dropouts. Early identification of such students enables timely interventions, one of the main goals of learning analytics. The process is first illustrated through a Random Forest classifier, using engagement indicators to classify students into high and low achievers. The chapter demonstrates the complete modeling workflow, including data preparation, model training, and evaluation using performance metrics. Additionally, the <code>tidymodels</code> framework is explored as a more modern alternative that enables easy comparison with other AI / machine learning algorithms like Naive Bayes or Support Vector Machine.
  </div>
</div>

</header>

<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>In the previous chapter <span class="citation" data-cites="LABOOK2_Chapter_3">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">1</a>]</span>, we implemented machine learning to predict students’ grades as a continuous outcome, i.e., predicted the numerical final grades, which is often referred to as a regression problem. However, more often than not, we are not interested in the specific grade but rather in a broad range or category such as drop-outs (students who abandon the course) or low achievers (students who will score below a certain grade or fail the course). In that, we want to identify whether a student is at risk of dropping out or failing a course and, therefore, may need support. Hence, in this chapter we address this achievement classification problem. The most common achievement classification problem is to classify or in fact predict low achievers <span class="citation" data-cites="jovanovic2024predictive">[<a href="#ref-jovanovic2024predictive" role="doc-biblioref">2</a>]</span>. This is commonly done with early course data given that there will be an opportunity for remedial and support before the end of the course. Similar to the previous chapter, we will start by demonstrating the code for a random forest model <span class="citation" data-cites="LABOOK2_Chapter_3">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">1</a>]</span>. Random forest is chosen because it is robust and offers insights (explanation) into the important variables that drove the algorithm to take a decision <span class="citation" data-cites="randomForest">[<a href="#ref-randomForest" role="doc-biblioref">3</a>]</span>. The analysis process involves a sequence of steps similar to the previous chapter with two notable differences. First, we have to prepare the data in a slightly different manner and the evaluation and the metrics follow a different approach given that it is a classification problem. Also, similar to the previous chapter, we will begin with the traditional approach and then we will proceed with the <code>tidymodels</code> approach.</p>
</section>
<section id="previous-research-on-identifying-at-risk-students" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="previous-research-on-identifying-at-risk-students"><span class="header-section-number">2</span> Previous research on identifying at-risk students</h2>
<p>There are several aims in research on the identification of at-risk students: 1) to develop a model to identify the at-risk students, 2) to identify attributes or indicators for the identification of at-risk students, 3) to develop and evaluate intervention methods to prevent student dropout or failure <span class="citation" data-cites="na2017identifying deoliveira2021does saqr2017learning">[<a href="#ref-na2017identifying" role="doc-biblioref">4</a>–<a href="#ref-saqr2017learning" role="doc-biblioref">6</a>]</span>.</p>
<p>Several studies compared the performance of several algorithms to predict at-risk students. For example, <span class="citation" data-cites="bayazit2022predicting">[<a href="#ref-bayazit2022predicting" role="doc-biblioref">7</a>]</span> reported that Naïve Bayes (NB) outperformed k-Nearest Neighbors (KNN), Decision Tree (DT), Random Forest (RF), and Support Vector Machines (SVM). <span class="citation" data-cites="queiroga2020learning">[<a href="#ref-queiroga2020learning" role="doc-biblioref">8</a>]</span> developed a predictive model using genetic algorithms that performed better than DT, RF, Multilayer Perceptron, Logistic Regression (LG), and the AdaBoost algorithm (ADA). The Deep Long Short-Term Memory Model by <span class="citation" data-cites="aljohani2019predicting">[<a href="#ref-aljohani2019predicting" role="doc-biblioref">9</a>]</span> outperformed LG and artificial neural networks. RF was the best-performing algorithm in <span class="citation" data-cites="adnan2021predicting">[<a href="#ref-adnan2021predicting" role="doc-biblioref">10</a>]</span> compared to SVM, KNN, ET, ADA, Gradient boosting classifier, and Deep Feed Forward Neural Network, in <span class="citation" data-cites="gonzalez2023predictive">[<a href="#ref-gonzalez2023predictive" role="doc-biblioref">11</a>]</span> compared to SVM, KNN, DT, ADA, Extreme Gradient, Bayesian Classifier, and Linear Discriminant Analysis, and in <span class="citation" data-cites="jayaprakash2014early">[<a href="#ref-jayaprakash2014early" role="doc-biblioref">12</a>]</span> compared to DT, SVM and NB. <span class="citation" data-cites="azcona2019detecting">[<a href="#ref-azcona2019detecting" role="doc-biblioref">13</a>]</span> reported that KNN had a higher performance than LG, SVM with different kernels, DT, and RF. Finally, instead of comparing different methods, <span class="citation" data-cites="anagnostopoulos2020intelligent">[<a href="#ref-anagnostopoulos2020intelligent" role="doc-biblioref">14</a>]</span> combined five base classifiers (NB, SVM, KNN, Repeated Incremental Pruning to Produce Error Reduction classifier and C4.5 classifier) into the Majority Voting ensemble classifier. As the diversity of potential classification algorithms and the differing performance results indicate, the portability of predictive models from one context to another can be challenging <span class="citation" data-cites="jayaprakash2014early mathrani2021perspectives">[<a href="#ref-jayaprakash2014early" role="doc-biblioref">12</a>, <a href="#ref-mathrani2021perspectives" role="doc-biblioref">15</a>]</span>. In addition, model interpretability and transparency are important in the practical implementations of predictive models. However, there is a trade-off in predictive accuracy and the ability to generate generalizable models of low transparency models to take into consideration <span class="citation" data-cites="mathrani2021perspectives">[<a href="#ref-mathrani2021perspectives" role="doc-biblioref">15</a>]</span>.</p>
<p>The selection of data and development of appropriate indicators used in a predictive model is a subject of extensive research. Most studies use student log data to determine student performance <span class="citation" data-cites="queiroga2020learning saqr2022 Jovanovic2021-et">[e.g., <a href="#ref-queiroga2020learning" role="doc-biblioref">8</a>, <a href="#ref-saqr2022" role="doc-biblioref">16</a>, <a href="#ref-Jovanovic2021-et" role="doc-biblioref">17</a>]</span>. Several studies complement student activity data with additional data sources. For example, <span class="citation" data-cites="foster2020effectiveness">[<a href="#ref-foster2020effectiveness" role="doc-biblioref">18</a>]</span> included not only student log data but also library book loans or card swipes into buildings. <span class="citation" data-cites="bayazit2022predicting">[<a href="#ref-bayazit2022predicting" role="doc-biblioref">7</a>]</span> used the pre-test scores and formative assessment scores in their predictive model. <span class="citation" data-cites="wolff2013improving">[<a href="#ref-wolff2013improving" role="doc-biblioref">19</a>]</span> found that demographic data improved prediction. <span class="citation" data-cites="queiroga2022early">[<a href="#ref-queiroga2022early" role="doc-biblioref">20</a>]</span> included a bias analysis in order to include three protected demographic attributes into their predictive model. <span class="citation" data-cites="choi2018learning">[<a href="#ref-choi2018learning" role="doc-biblioref">21</a>]</span> collected clicker data, as the learning management system was not popular to use by students. It is important to remember that every predictive model needs to be complemented by human judgment and contextual information. The research reported in <span class="citation" data-cites="hlosta2022predictive">[<a href="#ref-hlosta2022predictive" role="doc-biblioref">22</a>]</span>, where the authors focused on examining false positive and false negative errors of a predictive model, showed that there are many events that can influence student behavior and performance that are not captured by the predictive models, such as family or work responsibilities and health issues.</p>
<p>The typical definitions of at-risk students include students who are likely to drop out of a class or students who may fail a particular exam. A vast body of research reported indicators of struggling students identified by their predictive models. For example, <span class="citation" data-cites="anagnostopoulos2020intelligent">[<a href="#ref-anagnostopoulos2020intelligent" role="doc-biblioref">14</a>]</span> found that the strongest predictors of performance are connected to the successful completion of a set of course activities, such as watching videos or completing self-assessment quizzes. Similarly, <span class="citation" data-cites="saqr2017learning">[<a href="#ref-saqr2017learning" role="doc-biblioref">6</a>]</span> reported that student engagement and the consistency of using online resources were the strongest performance predictors. <span class="citation" data-cites="adnan2021predicting">[<a href="#ref-adnan2021predicting" role="doc-biblioref">10</a>]</span> found that clickstream and assessment variables had the most significant impact on student performance. <span class="citation" data-cites="jayaprakash2014early">[<a href="#ref-jayaprakash2014early" role="doc-biblioref">12</a>]</span> reported the highest predictive power of formative assessment scores and cumulative GPA. <span class="citation" data-cites="gkontzis2022predictive">[<a href="#ref-gkontzis2022predictive" role="doc-biblioref">23</a>]</span> highlighted the importance of the first written assignment and quiz for student attrition. A similar finding was reported in <span class="citation" data-cites="gonzalez2023predictive">[<a href="#ref-gonzalez2023predictive" role="doc-biblioref">11</a>]</span>, who reported the average grade obtained in the first period of the first semester as the strongest dropout predictor. Other conceptualizations of at-risk students include tracking when a student suddenly changes their typical behavior in an online learning system <span class="citation" data-cites="wolff2013improving">[<a href="#ref-wolff2013improving" role="doc-biblioref">19</a>]</span> or defining a specific threshold to consider a student at risk, e.g., scores below 5% over the passing mark <span class="citation" data-cites="saqr2017learning">[<a href="#ref-saqr2017learning" role="doc-biblioref">6</a>]</span>.</p>
<p>The temporal dimension is crucial in developing predictive models. It includes several aspects, such as how often predictions should be calculated, how long the data should be collected to ensure accurate predictions, when predictions should take place in order to be actionable, or how long a student should be inactive to trigger an intervention. For example, <span class="citation" data-cites="anagnostopoulos2020intelligent">[<a href="#ref-anagnostopoulos2020intelligent" role="doc-biblioref">14</a>]</span> used data from the first cohort of students to develop a classifier for another cohort of students. <span class="citation" data-cites="queiroga2020learning">[<a href="#ref-queiroga2020learning" role="doc-biblioref">8</a>]</span> generated a prediction model every two weeks, while <span class="citation" data-cites="foster2020effectiveness">[<a href="#ref-foster2020effectiveness" role="doc-biblioref">18</a>]</span> generated an alert of no-engagement after a period of two weeks of inactivity. Others calculate predictions every week <span class="citation" data-cites="cechinel2021learning saqr2020">[e.g., <a href="#ref-cechinel2021learning" role="doc-biblioref">24</a>, <a href="#ref-saqr2020" role="doc-biblioref">25</a>]</span> or every four weeks <span class="citation" data-cites="jayaprakash2014early">[<a href="#ref-jayaprakash2014early" role="doc-biblioref">12</a>]</span> or sometimes even on daily basis <span class="citation" data-cites="saqr2024">[<a href="#ref-saqr2024" role="doc-biblioref">26</a>]</span>. The intervals can also vary depending of the purpose of the predictive model. <span class="citation" data-cites="azcona2019detecting">[<a href="#ref-azcona2019detecting" role="doc-biblioref">13</a>]</span> developed predictions of passing or failing the next formative exam once a week, and, in addition, the classifiers from the first six weeks of classes were trained to predict the outcome of the mid-term exam, and the classifiers from weeks 7 to 12 were used to predict the end-of-semester’s exam outcome. <span class="citation" data-cites="aljohani2019predicting">[<a href="#ref-aljohani2019predicting" role="doc-biblioref">9</a>]</span> developed a classifier that has shown around 90% accuracy within the first 10 weeks of student interaction in an online learning environment, <span class="citation" data-cites="gkontzis2022predictive">[<a href="#ref-gkontzis2022predictive" role="doc-biblioref">23</a>]</span> reported a satisfactory prediction probability after week 5, while <span class="citation" data-cites="adnan2021predicting">[<a href="#ref-adnan2021predicting" role="doc-biblioref">10</a>]</span> showed almost 80% precision and accuracy score at 20% of the course length.</p>
<p>The predictions can be displayed directly to a student in the form of a dashboard or an alert. Another option is to inform a teacher about struggling students in a teacher-facing dashboard or through notifications <span class="citation" data-cites="kaliisa2024">[<a href="#ref-kaliisa2024" role="doc-biblioref">27</a>]</span>. Learning analytics dashboards that include predictive analytics are not widely implemented <span class="citation" data-cites="paulsen2024learning">[<a href="#ref-paulsen2024learning" role="doc-biblioref">28</a>]</span>. In addition, these dashboards often present only the prediction in the form of a visualization (e.g., signal lights) or percentage score without any explanation <span class="citation" data-cites="ramaswami2023use">[<a href="#ref-ramaswami2023use" role="doc-biblioref">29</a>]</span>. However, there is evidence that awareness of being at risk is not enough to improve student outcomes, and predictions need to be connected to be connected to an intervention <span class="citation" data-cites="jayaprakash2014early">[<a href="#ref-jayaprakash2014early" role="doc-biblioref">12</a>]</span>. The interventions can have different forms. For example, based on the analytics shown in a teacher-facing dashboard, a teacher can contact at-risk students personally to provide additional support <span class="citation" data-cites="saqr2018">[<a href="#ref-saqr2018" role="doc-biblioref">30</a>]</span>. Automated interventions embedded within the predictive analytics can include an adaptive feedback system that sends students custom messages based on their performance <span class="citation" data-cites="azcona2019detecting">[<a href="#ref-azcona2019detecting" role="doc-biblioref">13</a>]</span> or sending student-specific recommendations for learning materials and additional mentoring <span class="citation" data-cites="jayaprakash2014early">[<a href="#ref-jayaprakash2014early" role="doc-biblioref">12</a>]</span>. The evaluation of the interventions can be measured in reduced drop-out or increased performance. A comprehensive implementation of predictive analytics includes several iterations of improving the predictive model, adjusting an effective and transparent representation of the predictive results, and evaluating several intervention approaches <span class="citation" data-cites="rienties2017implementing">[<a href="#ref-rienties2017implementing" role="doc-biblioref">31</a>]</span>.</p>
</section>
<section id="classifying-students-with-r" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="classifying-students-with-r"><span class="header-section-number">3</span> Classifying students with R</h2>
<p>In this section we present two approaches to implement classification with R: one following a more classic procedure (tutorial 1), and the second one following a more updated procedure (tutorial 2) based on <code>tidymodels</code>. Broadly, the workflow followed is depicted in <a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>, aligned with the common steps that are performed in any ML pipeline. First, we explore the data to gain an idea of the magnitude, format and content of the data, explore the relationships between the different variables, etc. This step is called exploratory data analysis. Next, we prepare the data (B) for subsequent steps. This might include removing or fixing incomplete records, converting data to different types, unifying values that are close to one another, or rescaling the data. The transformations that we need to do are commonly dictated by the type of data and the ML models that we will be using in subsequent steps. After data preparation, the next step is data splitting (C). Here, the dataset is divided into training and testing sets. The training set is used to fit the model, while the testing set is reserved for evaluating its performance. It is crucial to ensure that the testing set remains untouched until the evaluation stage to provide an unbiased estimate of the model’s generalization ability. Once the data is split, the process moves to model fitting (D). During this stage, the training data is used to train the selected machine learning models. This involves finding the optimal parameters that minimize error or maximize predictive accuracy for the given task. Depending on the algorithm, the model may identify different patterns, such as decision boundaries or relationships between features and the target variable. Finally, in the model evaluation step (E), the trained model is tested on the unseen testing data. Performance metrics that quantify the accuracy and precision of the model are computed to determine how well the model performs on new data. This step ensures that the model is not overfitting the training data and can generalize well to other datasets. We can repeat this process for several models with different underlying ML algorithms (tutorial 3), or using only a subset of features of the data and compare the performance metrics among different models to select the one with the best fit.</p>
<div id="fig-workflow" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/workflowclas.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;1<strong>.</strong> ML workflow implemented in the tutorial</figcaption><p></p>
</figure>
</div>
<section id="tutorial-1-a-traditional-classification-approach-with-random-forest" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="tutorial-1-a-traditional-classification-approach-with-random-forest"><span class="header-section-number">3.1</span> Tutorial 1: A traditional classification approach with Random Forest</h3>
<p>The first example follows the workflow depicted in <a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>– We will estimate a Random Forest model to classify students into <strong><em>high achievers and low achievers</em></strong> based on their final grades and the engagement indicators as predictors. It is assumed that the reader is familiar with the R programming language. If that is not the case, it is recommended to refer to previous tutorials on the basics of R <span class="citation" data-cites="Tikka2024-ph">[<a href="#ref-Tikka2024-ph" role="doc-biblioref">32</a>]</span>, data cleaning <span class="citation" data-cites="Kopra2024-fx">[<a href="#ref-Kopra2024-fx" role="doc-biblioref">33</a>]</span>, basic statistics <span class="citation" data-cites="Tikka2024-wl">[<a href="#ref-Tikka2024-wl" role="doc-biblioref">34</a>]</span>, and visualization <span class="citation" data-cites="Lopez-Pernas2024-ge">[<a href="#ref-Lopez-Pernas2024-ge" role="doc-biblioref">35</a>]</span>. In this chapter we will use a dataset that was used in the previous chapter <span class="citation" data-cites="LABOOK2_Chapter_3">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">1</a>]</span> and based on this paper <span class="citation" data-cites="Jovanovic2021-et">[<a href="#ref-Jovanovic2021-et" role="doc-biblioref">17</a>]</span>.</p>
<p>In <strong>Step 1</strong>, we start by loading the necessary R packages. We use <code>randomForest</code> <span class="citation" data-cites="randomForest">[<a href="#ref-randomForest" role="doc-biblioref">3</a>]</span> to estimate a random forest model, <code>tidyverse</code> <span class="citation" data-cites="tidyverse">[<a href="#ref-tidyverse" role="doc-biblioref">36</a>]</span> for data manipulation and visualization, <code>rsample</code> <span class="citation" data-cites="rsample">[<a href="#ref-rsample" role="doc-biblioref">37</a>]</span> for splitting the data, <code>caret</code> <span class="citation" data-cites="caret">[<a href="#ref-caret" role="doc-biblioref">38</a>]</span> for model evaluation, and <code>pROC</code> to visualize this evaluation. We also use the package <code>rio</code> <span class="citation" data-cites="rio">[<a href="#ref-rio" role="doc-biblioref">39</a>]</span> to import the data. To ensure reproducibility, we set the seed to a random number (<em>1410)</em>. Setting the seed ensures that the code will produce identical results every time it is run. For instance, the data will be randomly split in the same way each time.</p>
<p>The next step would be conducting exploratory data analysis (EDA) to better understand the dataset and identify possible relationships between variables or problems in the data (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–A). We implemented this step in detail with the same dataset in Chapter 3 <span class="citation" data-cites="LABOOK2_Chapter_3">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">1</a>]</span> so we will not repeat it here for the sake of brevity. Therefore, we can move on to the next step, which is data preparation (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–B). We prepare the data by creating a new binary classification target variable named <strong><em>Achievement</em></strong> by categorizing students into <em>High_Achievers</em> and <em>Low_Achievers</em> based on their <code>Final_Grade</code>. Those who are above the median (top 50%) will be classified as high achievers and the others will be classified as lower achievers. This categorical variable is coded as a factor as it is required by several functions. Of course, there are several ways to label students as at risk; for instance, based on a threshold score of 60% or even higher.</p>
<p>In <strong>Step 2</strong>, we split the dataset into training and testing sets using an 80/20 split where we will use 80% of the data to train the model and 20% for evaluation (corresponding to <a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–C). We use the argument <code>strata = "Achievement"</code> to make sure that both the training and testing datasets have balanced classes of low and high achievers.</p>
<p>Having prepared the data we will then, define and fit the random forest model (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–D) to predict <code>Achievement</code> based on engagement indicators e.g., lecture views, forum activity, session counts, total duration of activities, and active days.</p>
<p>Lastly, to evaluate the model (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–e), we make predictions on the test dataset using the fitted model. For binary classification models, the evaluation commonly includes a confusion matrix as well as other metrics e.g., accuracy, precision, and recall as well as a visual evaluation through the receiver operating characteristic (ROC) curve, which we will explain in context with the estimation code.</p>
<p>The first chunk of code loads the necessary libraries and the data that we will use for building the model and sets a random seed as described earlier.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)  <span class="co"># For Random Forest model</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)     <span class="co"># For data manipulation and visualization</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)    <span class="co"># For data splitting and modeling workflow</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)      <span class="co"># For model evaluation</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC) <span class="co"># For visualizing receiver operating characteristic (ROC curves) </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rio)  <span class="co"># For importing data files </span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1410</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="preparing-the-data" class="level4" data-number="3.1.1">
<h4 data-number="3.1.1" class="anchored" data-anchor-id="preparing-the-data"><span class="header-section-number">3.1.1</span> Preparing the data</h4>
<p>As a first step in our analysis, we prepare the data (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–B) by creating a binary target variable, <code>Achievement</code>, which categorizes students based on their <code>Final_Grade</code>. Specifically, students with grades above the median are labeled as “High Achievers”, and those below are labeled as “Low Achievers”. This transformation is performed using the <code>mutate</code> function, ensuring the target variable is a factor with appropriate levels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Load and prepare the data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>raw_data <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">"https://github.com/lamethods/data2/raw/main/lms/lms.csv"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a binary classification target variable</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>median_grade <span class="ot">&lt;-</span> <span class="fu">median</span>(raw_data<span class="sc">$</span>Final_Grade)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>student_data <span class="ot">&lt;-</span> raw_data <span class="sc">|&gt;</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Achievement =</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(Final_Grade <span class="sc">&gt;</span> median_grade, </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>                                     <span class="st">"High_Achievers"</span>, <span class="st">"Low_Achievers"</span>), </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>                              <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Low_Achievers"</span>, <span class="st">"High_Achievers"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="splitting-the-data-into-training-and-testing-sets" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="splitting-the-data-into-training-and-testing-sets"><span class="header-section-number">3.2</span> Splitting the data into training and testing sets</h3>
<p>In the second step, we split the dataset into training and testing sets (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–C) using an 80/20 split. To maintain the class distribution, we use stratified sampling by passing the option <code>strata</code> to the <code>initial_split</code> function with the which takes care of distributing the achievement classes (high and low achievers) in the training and testing sets in a balanced way. In doing so, we ensure that both the training and testing sets are representative of the overall class distribution and we create a more balance model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Split the data into training and testing sets</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(student_data, <span class="at">prop =</span> <span class="fl">0.8</span>, <span class="at">strata =</span> <span class="st">"Achievement"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-and-training-the-model" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="creating-and-training-the-model"><span class="header-section-number">3.3</span> Creating and training the model</h3>
<p>In <strong>step 3</strong>, we create and fit a random forest model using the <code>randomForest</code> function (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–D). The model predicts the <code>Achievement</code> variable based on engagement indicators (e.g., course views, lecture views, forum consumption and contribution), regularity indicators (Regularity Course View, Regularity Lecture_View, Regularity Forum Consume, Regularity Forum Contribute), and time indicators (session counts, total duration of activities, active days) <span class="citation" data-cites="saqr2022">[<a href="#ref-saqr2022" role="doc-biblioref">16</a>]</span>. The model is specified using a formula syntax: <code>target_variable ~ predictor_1 + predictor_2 + ... + predictor_n.</code> To ensure model robustness, we set <code>ntree</code> to 1000 (please refer to the previous chapter for more details on the number of trees <span class="citation" data-cites="LABOOK2_Chapter_3">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">1</a>]</span>). Given that we are also interested in explaining the results, we set the <code>importance</code> argument to <code>TRUE</code> to estimate the importance of each variable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Create and fit a Random Forest model</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  Achievement <span class="sc">~</span> Freq_Course_View <span class="sc">+</span> Freq_Lecture_View <span class="sc">+</span> Freq_Forum_Consume <span class="sc">+</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    Freq_Forum_Contribute <span class="sc">+</span> Regularity_Course_View <span class="sc">+</span> </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    Regularity_Lecture_View <span class="sc">+</span> Regularity_Forum_Consume <span class="sc">+</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    Regularity_Forum_Contribute <span class="sc">+</span> Session_Count <span class="sc">+</span> </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    Total_Duration <span class="sc">+</span> Active_Days,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data, </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ntree =</span> <span class="dv">1000</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">importance =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluating-the-model" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="evaluating-the-model"><span class="header-section-number">3.4</span> Evaluating the model</h3>
<p>In <strong>step 4</strong>, we apply the model that we just trained to a new dataset (the test set) to evaluate its performance on new data (unseen by the model) that we held out. This allows us to evaluate how the model perform, or in other words, how likely the results we obtained to replicate in the future. A good model is expected to perform well on both learning and testing data. For the evaluation purpose, we use the <code>predict</code> function to generate predictions from our trained random forest model, <code>rf_model</code> and the <code>test_data</code>. The <code>predict</code> function generates two types of predictions: the probabilities and the classes.</p>
<p>1) Probability Predictions: estimate the probability of a student belonging to each achievement category (Low Achievers or High Achievers), we save these probabilities in a <code>predictions_prob</code> variable. To get these probabilities we specify the argument <code>type = "prob"</code> argument.</p>
<p>2) Class Predictions: predict the most likely achievement category for each student i.e., whether the student is predicted as high or low achiever. We save these class predictions in the <code>predictions_class</code> variable.</p>
<p>In the last step, and for convenience, we we add these prediction as extra columns within the original test dataset to make it easier for further analysis.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Make predictions on the test set for the probabilities and the classes</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>predictions_prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>predictions_class <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, test_data)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Add predictions and probabilities to the test dataset</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> test_data <span class="sc">|&gt;</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Predicted_Class =</span> predictions_class,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">Probability_Low_Achievers =</span> predictions_prob[, <span class="st">"Low_Achievers"</span>],</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">Probability_High_Achievers =</span> predictions_prob[, <span class="st">"High_Achievers"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In Step 5, we evaluate the model’s performance (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–E). For this, we use the <code>confusionMatrix</code> function from the <code>caret</code> package, which provides a detailed evaluation, including the confusion matrix and several other metrics. The confusion matrix is a table that summarizes the model’s predictions compared to the actual outcomes. Specifically, it shows the counts of correctly predicted positive cases (true positives), correctly predicted negative cases (true negatives), incorrectly predicted positive cases (false positives), and incorrectly predicted negative cases (false negatives).</p>
<p>For example, in our case:</p>
<ul>
<li><strong>True Positives (TP)</strong>: 20 Low-achieving students were correctly classified as “Low Achievers”.</li>
<li><strong>True Negatives (TN)</strong>: 23 High-achieving students were correctly classified as “High Achievers”.</li>
<li><strong>False Positives (FP)</strong>: 9 Low-achieving students were incorrectly classified as “High Achievers”.</li>
<li><strong>False Negatives (FN)</strong>: 6 High-achieving students were incorrectly classified as “Low Achievers”.</li>
</ul>
<section id="evaluation-metrics" class="level4" data-number="3.4.1">
<h4 data-number="3.4.1" class="anchored" data-anchor-id="evaluation-metrics"><span class="header-section-number">3.4.1</span> Evaluation metrics</h4>
<p>The <code>confusionMatrix</code> package produces several classification metrics; we will explain them here with equations in light of our results.</p>
<ul>
<li><p><strong>Accuracy:</strong> Measures the proportion of correct predictions (both true positives and true negatives) out of the total number of cases. In our case, <code>accuracy</code> was 0.7414 indicating that approximately 74.14% of the classifications were correct. The 95% CI (Confidence Interval) indicates that the interval (0.6096, 0.8474) likely contains the true accuracy. The accuracy is calculated according to the following equation:</p>
<p><span class="math display">\[
  \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = \frac{20 + 23}{20 + 23 + 9 + 6} = 0.7414
\]</span></p></li>
<li><p><strong>Kappa:</strong> Cohen’s Kappa is a measure of agreement between the observed accuracy and the accuracy expected by chance. In our case, the kappa value was 0.483 indicating a moderate agreement beyond chance. As a practical rule, Kappa of 0–0.20 is considered slight, 0.21–0.40 as fair, 0.41–0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1 as almost perfect.</p>
<p><span class="math display">\[
\kappa = \frac{\text{Accuracy} - \text{Expected Accuracy}}{1 - \text{Expected Accuracy}} = \frac{0.7414 - 0.5}{1 - 0.5} = 0.4828
\]</span></p></li>
<li><p><strong>Mcnemar’s Test P-Value:</strong> This test assesses if FP and FN differ significantly, the high p-value (0.789) in our case suggests no significant difference between the error rates for either class.</p></li>
</ul>
</section>
<section id="sensitivity-and-specificity" class="level4" data-number="3.4.2">
<h4 data-number="3.4.2" class="anchored" data-anchor-id="sensitivity-and-specificity"><span class="header-section-number">3.4.2</span> Sensitivity and Specificity</h4>
<ul>
<li><p><strong>Sensitivity</strong> (True Positive Rate) measures the model’s ability to correctly identify “Low Achievers” (the positive class in this case). A value of 0.6897 indicates that the model were able to correctly identify 68.97% of actual “Low Achievers.”</p>
<p><span class="math display">\[
\text{Sensitivity} = \frac{TP}{TP + FN} = \frac{20}{20 + 9} = 0.6897
\]</span></p></li>
<li><p><strong>Specificity</strong> (True Negative Rate) measures the model’s ability to correctly identify “High Achievers” (the negative class). A value of 0.7931 suggests that the model correctly identified 79.31% of actual “High Achievers.”</p>
<p><span class="math display">\[
  \text{Specificity} = \frac{TN}{TN + FP} = \frac{23}{23 + 6} = 0.7931
\]</span></p></li>
</ul>
<p>Please note that the model was able to identify more of high achievers than low achievers, this is probably due to the fact that high achievers generate more data that can be used to identify them.</p>
<section id="predictive-values" class="level5" data-number="3.4.2.1">
<h5 data-number="3.4.2.1" class="anchored" data-anchor-id="predictive-values"><span class="header-section-number">3.4.2.1</span> Predictive Values</h5>
<ul>
<li><p><strong>Positive Predictive Value (PPV or Precision):</strong> The proportion of positive results that are true positives. The PPV of 0.7692 indicates that 76.92% of the predicted “Low Achievers” are actual “Low Achievers”.</p>
<p><span class="math display">\[
\text{PPV} = \frac{TP}{TP + FP} = \frac{20}{20 + 6} = 0.7692
\]</span></p></li>
<li><p><strong>Negative Predictive Value (NPV):</strong> The proportion of negative results that are true negatives. The NPV of 0.7188 indicates that 71.88% of the predicted “High Achievers” are actual “High Achievers”.</p>
<p><span class="math display">\[
\text{NPV} = \frac{TN}{TN + FN} = \frac{23}{23 + 9} = 0.7188
\]</span></p></li>
</ul>
</section>
<section id="prevalence-and-detection" class="level5" data-number="3.4.2.2">
<h5 data-number="3.4.2.2" class="anchored" data-anchor-id="prevalence-and-detection"><span class="header-section-number">3.4.2.2</span> Prevalence and Detection</h5>
<p>These metrics provide insights into the distribution of the positive class (Low Achievers) in the actual data and in the model’s predictions.</p>
<p><strong>Prevalence:</strong> The proportion of the total number of cases that are positives. The prevalence of 0.5 indicates that 50% of the students are “Low Achievers”. The detection rate of 0.3448 indicates that 34.48% of the total students were correctly identified as “Low Achievers”. The detection prevalence of 0.4483 indicates that 44.83% of the students were predicted to be “Low Achievers”.</p>
<p>The code below computes the confusion_matrix and prints it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Evaluate the model</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confusion matrix</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(test_data<span class="sc">$</span>Predicted_Class, test_data<span class="sc">$</span>Achievement)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print confusion matrix and other metrics</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(confusion_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

                Reference
Prediction       Low_Achievers High_Achievers
  Low_Achievers             21              6
  High_Achievers             8             23
                                          
               Accuracy : 0.7586          
                 95% CI : (0.6283, 0.8613)
    No Information Rate : 0.5             
    P-Value [Acc &gt; NIR] : 5.025e-05       
                                          
                  Kappa : 0.5172          
                                          
 Mcnemar's Test P-Value : 0.7893          
                                          
            Sensitivity : 0.7241          
            Specificity : 0.7931          
         Pos Pred Value : 0.7778          
         Neg Pred Value : 0.7419          
             Prevalence : 0.5000          
         Detection Rate : 0.3621          
   Detection Prevalence : 0.4655          
      Balanced Accuracy : 0.7586          
                                          
       'Positive' Class : Low_Achievers   
                                          </code></pre>
</div>
</div>
</section>
<section id="visual-evaluation" class="level5" data-number="3.4.2.3">
<h5 data-number="3.4.2.3" class="anchored" data-anchor-id="visual-evaluation"><span class="header-section-number">3.4.2.3</span> Visual evaluation</h5>
<p>In <strong>step 6</strong> we evaluate the model performance visually. We use a <code>fourfold</code> plot to visualize the confusion matrix, in which the circles in each quadrant are proportional to the counts in the matrix (<a href="#fig-fourfoldplot">Figure&nbsp;<span>4.2</span></a>). The additional circumferences in each quadrant represent the confidence intervals of each count.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Visualize results</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">fourfoldplot</span>(confusion_matrix<span class="sc">$</span>table)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>roc_obj <span class="ot">&lt;-</span> <span class="fu">roc</span>(test_data<span class="sc">$</span>Achievement, predictions_prob[, <span class="st">"Low_Achievers"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-fourfoldplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-fourfoldplot-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;2<strong>.</strong> Confusion matrix</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Next we plot the ROC curve which is a graphical representation of model’s performance across all possible threshold values (<a href="#fig-roc-mat">Figure&nbsp;<span>4.3</span></a>). The ROC curve plots the True Positive Rate (Sensitivity) against the False Positive Rate (<span class="math inline">\(1 - \text{Specificity}\)</span>). In other words, the ROC curve helps visualize the trade-off between sensitivity and specificity. A good model would have higher values of sensitivity and specificity resulting in a curve above the diagonal line while a bad model would produce a diagonal line. Another related value is the area under the curve (AUC). The AUC quantifies the overall ability of the model to discriminate between positive and negative classes, value ranges from 0 to 1 where AUC = 0.5 indicates the model performs no better than random guessing, values below 0.5 indicate that the model performs worse than random guessing and AUC values more than 0.5 indicates the model performs better than guessing (assuming that there are the same number of high achievers than low achievers). In our case, the value was 0.76 which is a moderate performance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC curve</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(roc_obj, <span class="at">asp =</span> <span class="cn">NA</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>auc_value <span class="ot">&lt;-</span> <span class="fu">auc</span>(roc_obj)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"AUC:"</span>, auc_value))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "AUC: 0.762187871581451"</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-roc-mat" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-roc-mat-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;3<strong>.</strong> ROC Curve for Random Forest Model</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="explainability" class="level5" data-number="3.4.2.4">
<h5 data-number="3.4.2.4" class="anchored" data-anchor-id="explainability"><span class="header-section-number">3.4.2.4</span> Explainability</h5>
<p>Given the importance of intepretability of machine learning models, it is important to understand which of the features of our dataset contribute to the final prediction <span class="citation" data-cites="Saqr2024-ie LABOOK2_Chapter_2">[<a href="#ref-Saqr2024-ie" role="doc-biblioref">40</a>, <a href="#ref-LABOOK2_Chapter_2" role="doc-biblioref">41</a>]</span>. For this purpose, we can extract the variable importance and visualize them. The code below extracts variable <code>importance</code> values from the fitted random forest model (<code>rf_model</code>). The <code>importance</code> values contain two metrics: <code>MeanDecreaseAccurac</code> and <code>MeanDecreaseGini</code>. The <code>MeanDecreaseAccuracy</code> measures how much the accuracy of the model decreases when a particular variable is excluded. Higher values indicate that the variable is more important for maintaining the accuracy of the model. For instance, <code>Freq_Forum_Contribute</code> has the highest <code>MeanDecreaseAccuracy</code> value of 39.6879041, suggesting it is the most critical variable for the model’s accuracy. In contrast, <code>Freq_Lecture_View</code> has a negative value (<span class="math inline">\(-0.2569615\)</span>), indicating that excluding this variable slightly improves the model’s accuracy. Please note that a more detailed explanation of model explainability is offered in next chapters with more comprehensive methods <span class="citation" data-cites="LABOOK2_Chapter_6 LABOOK2_Chapter_7">[<a href="#ref-LABOOK2_Chapter_6" role="doc-biblioref">42</a>, <a href="#ref-LABOOK2_Chapter_7" role="doc-biblioref">43</a>]</span>.</p>
<p>The <code>MeanDecreaseGini</code> measures the total decrease in node impurity that a variable contributes across all the trees in the forest. Higher values signify greater importance. For example, <code>Freq_Forum_Contribute</code> again shows high importance with a <code>MeanDecreaseGini</code> value of 21.348017, emphasizing its importance for predicting students’ achievement. On the other hand, <code>Freq_Lecture_View</code> has a lower <code>MeanDecreaseGini</code> value of 5.959581, indicating it is less influential in reducing impurity.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract variable importance from the fitted model</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>importance_values <span class="ot">&lt;-</span> rf_model<span class="sc">$</span>importance</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to a data frame for plotting</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>importance_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(importance_values)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>importance_df<span class="sc">$</span>Variable <span class="ot">&lt;-</span> <span class="fu">rownames</span>(importance_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot variable importance for MeanDecreaseAccuracy</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(importance_df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, MeanDecreaseAccuracy), </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> MeanDecreaseAccuracy)) <span class="sc">+</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"turquoise"</span>) <span class="sc">+</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Variable"</span>,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Importance"</span>) <span class="sc">+</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot variable importance for MeanDecreaseGini</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(importance_df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, MeanDecreaseGini), </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> MeanDecreaseGini)) <span class="sc">+</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"turquoise"</span>) <span class="sc">+</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Variable"</span>,</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Importance"</span>) <span class="sc">+</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-varimp" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-varimp-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-varimp-1.png" class="img-fluid figure-img" data-ref-parent="fig-varimp" width="672"></p>
<p></p><figcaption class="figure-caption">(a) <code>MeanDecreaseAccuracy</code></figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-varimp-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-varimp-2.png" class="img-fluid figure-img" data-ref-parent="fig-varimp" width="672"></p>
<p></p><figcaption class="figure-caption">(b) <code>MeanDecreaseGini</code></figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;4<strong>.</strong> Variable Importance for the Random Forest Model</figcaption><p></p>
</figure>
</div>
</div>
</section>
</section>
</section>
<section id="tutorial-2-an-alternative-implementation-of-random-forests-with-tidymodels" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="tutorial-2-an-alternative-implementation-of-random-forests-with-tidymodels"><span class="header-section-number">3.5</span> Tutorial 2: An alternative implementation of random forests with <code>tidymodels</code></h3>
<p>In this section, we present an alternative to the process described in the previous example using <code>tidymodels</code> <span class="citation" data-cites="tidymodels">[<a href="#ref-tidymodels" role="doc-biblioref">44</a>]</span> instead of the classic approach. The <code>tidymodels</code> framework offers a unified streamlined interface for machine learning in R that makes it easier to specify models, update them, and compare one against another. Instead of working with different packages for different models, each with its own syntax, <code>tidymodels</code> employs a consistent syntax across all stages of estimation. All the more so, when we need to estimate several models as it is the case in our tutorial, <code>tidymodels</code> makes it easier to estimate and maintain the code. The main packages within <code>tidymodels</code> include <code>rsample</code> <span class="citation" data-cites="rsample">[<a href="#ref-rsample" role="doc-biblioref">37</a>]</span> for data splitting, <code>parsnip</code> for a specifying models <span class="citation" data-cites="parsnip">[<a href="#ref-parsnip" role="doc-biblioref">45</a>]</span>, <code>recipes</code> for data pre-processing and feature engineering <span class="citation" data-cites="recipes">[<a href="#ref-recipes" role="doc-biblioref">46</a>]</span>, <code>workflows</code> for combining pre-processing, modeling, and <code>yardstick</code> <span class="citation" data-cites="yardstick">[<a href="#ref-yardstick" role="doc-biblioref">47</a>]</span> for model evaluation. A more detailed discussion of <code>tidymodels</code> can be found the in the previous chapter.</p>
<p>Performing the classification with <code>tidymodels</code> follows a sequence of steps similar to what we had before with some differences. In general, the first three steps (loading packages, preparing the data and splitting) are the same as before but later steps uses the standard approach of defining models, workflows, training and evaluation. Below is a detailed description of the code and estimation steps.</p>
<section id="preparing-the-data-1" class="level4" data-number="3.5.1">
<h4 data-number="3.5.1" class="anchored" data-anchor-id="preparing-the-data-1"><span class="header-section-number">3.5.1</span> Preparing the data</h4>
<p>The first steps are similar to the traditional approach: we load the necessary packages <code>tidyverse</code> and <code>tidymodels</code>; then we prepare the data (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–B) by creating a binary target variable, which we call <strong><em>Achievement</em></strong> based on <code>Final_Grade</code> to classify students to low and high achievers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1410</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and prepare the data</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming student_data is already loaded into the environment</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>student_data <span class="ot">&lt;-</span> raw_data <span class="sc">|&gt;</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Achievement =</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(Final_Grade <span class="sc">&gt;</span> <span class="fu">median</span>(Final_Grade), </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>                                     <span class="st">"High_Achievers"</span>, <span class="st">"Low_Achievers"</span>),</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>                              <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Low_Achievers"</span>, <span class="st">"High_Achievers"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="splitting-the-data-into-training-and-testing-sets-1" class="level4" data-number="3.5.2">
<h4 data-number="3.5.2" class="anchored" data-anchor-id="splitting-the-data-into-training-and-testing-sets-1"><span class="header-section-number">3.5.2</span> Splitting the data into training and testing sets</h4>
<p>Next, we split the data into training and testing sets (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–C). The training set is then used to make the actual predictions and the testing test is used for model evaluation. We opt again here for stratified sampling <code>strata = Achievement</code> to preserve class distribution (balanced proportion of high and low achievers in the training and testing datasets).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Split the data into training and testing sets</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(student_data, <span class="at">prop =</span> <span class="fl">0.8</span>, <span class="at">strata =</span> Achievement)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-a-recipe" class="level4" data-number="3.5.3">
<h4 data-number="3.5.3" class="anchored" data-anchor-id="creating-a-recipe"><span class="header-section-number">3.5.3</span> Creating a recipe</h4>
<p>Unlike the previous chapter <span class="citation" data-cites="LABOOK2_Chapter_3">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">1</a>]</span>, where we used a formula, we extend it here by using a <em>recipe</em>. A recipe offers more options like including other data preparation and pre-processing steps. In our case, we define a recipe with a formula and also a function for normalizing the predictors so that all variables are on a similar scale. For that, we use <code>step_normalize(all_predictors())</code> function which will create new variables with standard deviation of one and a mean of zero.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a recipe</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>rf_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Achievement <span class="sc">~</span> Freq_Course_View <span class="sc">+</span> Freq_Lecture_View <span class="sc">+</span> </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                    Freq_Forum_Consume <span class="sc">+</span> Freq_Forum_Contribute <span class="sc">+</span> </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>                    Regularity_Course_View <span class="sc">+</span> Regularity_Lecture_View <span class="sc">+</span> </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                    Regularity_Forum_Consume <span class="sc">+</span> Regularity_Forum_Contribute <span class="sc">+</span> </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                    Session_Count <span class="sc">+</span> Total_Duration <span class="sc">+</span> Active_Days,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                    <span class="at">data =</span> train_data) <span class="sc">|&gt;</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_predictors</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-the-model" class="level4" data-number="3.5.4">
<h4 data-number="3.5.4" class="anchored" data-anchor-id="creating-the-model"><span class="header-section-number">3.5.4</span> Creating the model</h4>
<p>Next, we define the random forest model specifications. In this specification, we define the <code>rf_spec</code> object which will store the configuration for our model. The specification sets the <code>trees</code> parameter to 1000 which means the random forest will consist of 1000 decision trees. A larger number of trees generally leads to more stable results. The <code>mtry</code> parameter is set to 5, which means that during each split in the decision trees, the algorithm will randomly select 5 predictors (from the engagement indicators). This randomness helps prevent overfitting and ensures diversity among the trees. Then, we specify the engine for our random forest using the <code>set_engine("ranger")</code>** function. The <code>ranger</code> engine is a fast and efficient engine that can handle large datasets. Most importantly, we specify <code>set_mode("classification")</code>, which means that the random forest model will predict a categorical outcome (high or low achievers), compare this to regression in the previous chapter.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a random forest model specification</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="dv">1000</span>, <span class="at">mtry =</span> <span class="dv">5</span>) <span class="sc">|&gt;</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"ranger"</span>,  <span class="at">importance =</span> <span class="st">"impurity"</span>) <span class="sc">|&gt;</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-a-workflow" class="level4" data-number="3.5.5">
<h4 data-number="3.5.5" class="anchored" data-anchor-id="creating-a-workflow"><span class="header-section-number">3.5.5</span> Creating a workflow</h4>
<p>The next step is to create a workflow which is a container that holds the recipe and the model specifications that we just defined. Workflows provide a way to chain these components together and execute them in a specific order when fitting the algorithm. To create a workflow for a random forest model, we begin by initializing the workflow object using the function <code>workflow()</code> and adding the recipe <code>rf_recipe</code> that that we just created containing the formula and the pre-processing steps. Next, we specify the model that we just defined <code>rf_spec</code>. In the following step, we fit the model (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–D) to the training data by passing it to the <code>fit</code> function and the workflow and we store the fitted model to the object <code>rf_fit_tidy</code>. <code>rf_fit_tidy</code> contains data about how the model predicts the data.</p>
<p>To evaluate the model’s performance (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–E), we generate predictions on the test dataset <code>test_data</code> using the trained model <code>rf_fit_tidy</code>. We enhance our test dataset with these predictions by computing three new columns and adding them to the test_data: <code>Predicted_Class_tidy</code>, which contains the predicted class for each observation; <code>Probability_Low_Achievers_tidy</code>, which gives the probability of an observation being classified as a “Low Achiever”; and <code>Probability_High_Achievers_tidy</code>, which provides the probability of an observation being classified as a “High Achiever”. The resulting augmented dataset combines original features and the predictions and their probabilities which will make it easier to plot and evaluate the data later.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a workflow</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>rf_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(rf_recipe) <span class="sc">|&gt;</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_spec)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>rf_fit_tidy <span class="ot">&lt;-</span> rf_workflow <span class="sc">|&gt;</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> train_data)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>predictions_prob_tidy <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fit_tidy, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>predictions_class_tidy <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fit_tidy, test_data)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Add predictions and probabilities to the test dataset</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> test_data <span class="sc">|&gt;</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">Predicted_Class_tidy =</span> predictions_class_tidy<span class="sc">$</span>.pred_class,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">Probability_Low_Achievers_tidy =</span> predictions_prob_tidy<span class="sc">$</span>.pred_Low_Achievers,</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">Probability_High_Achievers_tidy =</span> predictions_prob_tidy<span class="sc">$</span>.pred_High_Achievers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluating-the-model-1" class="level4" data-number="3.5.6">
<h4 data-number="3.5.6" class="anchored" data-anchor-id="evaluating-the-model-1"><span class="header-section-number">3.5.6</span> Evaluating the model</h4>
<p>In the next step, we evaluate the performance of the model. The process involves creating a confusion matrix and computing several evaluation metrics as before. The first part of the code generates a confusion matrix. This matrix provides a summary of how well the model is performing in distinguishing between the classes.</p>
<p>In the code below, we create the confusion matrix using the <code>conf_mat()</code> function. Computing the evaluation metrics in <code>yardstick</code> <span class="citation" data-cites="yardstick">[<a href="#ref-yardstick" role="doc-biblioref">47</a>]</span> has two steps 1) defining the metrics and then computing them. So, we define the custom set of evaluation metrics using the <code>metric_set</code> function. This set includes the common classification metrics: accuracy, sensitivity, specificity, F1 score, balanced accuracy, positive predictive value, and negative predictive value.</p>
<p>Finally, we compute these custom metrics and add them the test data. The function calculates all the specified metrics, comparing the true <code>Achievement</code> values against the <code>Predicted_Class_tidy</code> predictions. The <code>event_level</code> = <code>"first"</code> parameter specifies which class should be considered the positive class for binary classification metrics, i.e., low achievers. The resulting detailed metrics are stored in ‘detailed_metrics_tidy’ and then printed.</p>
<p>The results of the evaluation shows that the accuracy of the model is 0.741 which means that 74.1% of “High Achievers” and “Low Achievers” were correctly classified. The sensitivity of 0.793 means that in 79.3% of the times, the model correctly identified students who are actually “Low Achievers” and labeled them as such. Specificity shows how the model identified the other category of students: “High Achievers” and identifying them which was approximately 69.0%. The F-measure, around 0.754, combines sensitivity and precision into a single metric, balancing the model’s ability to identify “High Achievers” with how accurate those predictions are. This score indicates a good balance between detecting “High Achievers” and avoiding false positives. In case you are interested, the F-measure is computed as the harmonic mean of precision and recall following this formula.</p>
<p><span class="math display">\[
\text{F1-Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} = 2 \cdot \frac{0.7692 \cdot 0.6897}{0.7692 + 0.6897} = 0.7273
\]</span></p>
<p>Positive Predictive Value (PPV) of 0.719 indicates how often the model’s prediction of “Low Achievers” is correct which was accurate in 71.9% of the time. Negative Predictive Value (NPV) was 0.769, showing the accuracy of predictions for “High Achievers was correct 76.9% of the time. <strong>Balanced Accuracy</strong> was 0.741 and reflects the model’s overall performance across both classes by equally weighting the ability to correctly identify”Low Achievers” and “High Achievers.”</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>conf_mat_tidy <span class="ot">&lt;-</span> <span class="fu">conf_mat</span>(test_data, <span class="at">truth =</span> Achievement, </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">estimate =</span> Predicted_Class_tidy)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(conf_mat_tidy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                Truth
Prediction       Low_Achievers High_Achievers
  Low_Achievers             20              6
  High_Achievers             9             23</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom metric set</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>custom_metrics_tidy <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(accuracy, sens, yardstick<span class="sc">::</span>spec, </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                                  f_meas, bal_accuracy, ppv, npv)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute all metrics</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>detailed_metrics_tidy <span class="ot">&lt;-</span> test_data <span class="sc">|&gt;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">custom_metrics_tidy</span>(</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">truth =</span> Achievement, </span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">estimate =</span> Predicted_Class_tidy,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">event_level =</span> <span class="st">"first"</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(detailed_metrics_tidy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 7 × 3
  .metric      .estimator .estimate
  &lt;chr&gt;        &lt;chr&gt;          &lt;dbl&gt;
1 accuracy     binary         0.741
2 sens         binary         0.690
3 spec         binary         0.793
4 f_meas       binary         0.727
5 bal_accuracy binary         0.741
6 ppv          binary         0.769
7 npv          binary         0.719</code></pre>
</div>
</div>
<p>In the last step, we estimate and plot the AUC and ROC curve. The visualization and estimation follow exactly the same way we did before (<a href="#fig-roc-auc">Figure&nbsp;<span>4.5</span></a>). The only difference is that we use <code>roc_curve()</code> function from the <code>yardstick</code> package <span class="citation" data-cites="yardstick">[<a href="#ref-yardstick" role="doc-biblioref">47</a>]</span>. The function takes two important arguments, the truth argument which represents the class we predicted and the probability of the class we are focusing on which is lower achievers in our case.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute ROC and AUC using yardstick</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>roc_data_tidy <span class="ot">&lt;-</span> test_data <span class="sc">|&gt;</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_curve</span>(<span class="at">truth =</span> Achievement, Probability_Low_Achievers_tidy)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>auc_value_tidy <span class="ot">&lt;-</span> test_data <span class="sc">|&gt;</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_auc</span>(Achievement, Probability_Low_Achievers_tidy) <span class="sc">|&gt;</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(.estimate)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot ROC Curve using ggplot2</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(roc_data_tidy, <span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificity, <span class="at">y =</span> sensitivity)) <span class="sc">+</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"False Positive Rate"</span>, <span class="at">y =</span> <span class="st">"True Positive Rate"</span>) <span class="sc">+</span> </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">0.75</span>, <span class="at">y =</span> <span class="fl">0.25</span>, </span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"AUC ="</span>, <span class="fu">round</span>(auc_value_tidy, <span class="dv">3</span>)), <span class="at">size =</span> <span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-roc-auc" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-roc-auc-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;5<strong>.</strong> ROC Curve for Random Forest Model</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="explainability-1" class="level4" data-number="3.5.7">
<h4 data-number="3.5.7" class="anchored" data-anchor-id="explainability-1"><span class="header-section-number">3.5.7</span> Explainability</h4>
<p>To extract the variable importance we have to pull the data from the model. In the code below we pull the variable importance data, create a data frame and then use <code>ggplot</code> to visualize it. As you can see, variable importance can be plotted and their interpretation could help guide us understand what actions students take that may be associated with better performance (<a href="#fig-varimp-tidymodels">Figure&nbsp;<span>4.6</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the ranger model from the workflow</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>importance_values <span class="ot">&lt;-</span> <span class="fu">pull_workflow_fit</span>(rf_fit_tidy)<span class="sc">$</span>fit<span class="sc">$</span>variable.importance</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to a data frame for plotting</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>importance_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(importance_values)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>importance_df<span class="sc">$</span>Variable <span class="ot">&lt;-</span> <span class="fu">rownames</span>(importance_df)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(importance_df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Importance"</span>, <span class="st">"Variable"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot variable importance</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(importance_df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, Importance), <span class="at">y =</span> Importance)) <span class="sc">+</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"turquoise"</span>) <span class="sc">+</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Variable"</span>, <span class="at">y =</span> <span class="st">"Importance"</span>) <span class="sc">+</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_text</span>(<span class="at">color =</span> <span class="st">"black"</span>),</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.title =</span> <span class="fu">element_text</span>(<span class="at">color =</span> <span class="st">"black"</span>),</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>, <span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">color =</span> <span class="st">"black"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-varimp-tidymodels" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-varimp-tidymodels-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;6<strong>.</strong> Variable Importance (<code>tidymodels</code>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="tutorial-3-evaluating-multiple-models-with-tidymodels" class="level3" data-number="3.6">
<h3 data-number="3.6" class="anchored" data-anchor-id="tutorial-3-evaluating-multiple-models-with-tidymodels"><span class="header-section-number">3.6</span> Tutorial 3: Evaluating multiple models with <code>tidymodels</code></h3>
<p>In the next example, we will take advantage of <code>tidymodels</code> framework to fit, evaluate and compare several models. In most practical cases, we will need to estimate several models, evaluate them, compare them and choose the one that performs better.</p>
<p>In the next example, we will estimate several machine learning models using the <code>tidymodels</code> ecosystem to streamline the process. The aim —as we did before— is to classify students into high or low achievers based on their engagement indicators. The process will follow a systematic sequence: loading the packages and the data, preparing the data, splitting it into training and testing sets, creating a recipe, defining model specifications, creating workflows, fitting the models, making predictions, evaluating the models, and finally visualizing the results. Given that we are estimating 13 models, we will create functions to save time rather than repeating the same process 13 times in each step, these functions will help automate the repetitive tasks. The following code will explain these steps as follows:</p>
<section id="preparing-the-data-2" class="level4" data-number="3.6.1">
<h4 data-number="3.6.1" class="anchored" data-anchor-id="preparing-the-data-2"><span class="header-section-number">3.6.1</span> Preparing the data</h4>
<p>The first step, is similar in each code we discussed before, in which we load the required packages. Also, you may be prompted to install missing packages if some dependencies are not loaded. The required packages here are the packages that provide the <em>engines</em> for the algorithms we are estimating e.g., (<code>ranger</code>, <code>xgboost</code>, <code>kernlab</code>, <code>glmnet</code>, <code>nnet</code>, <code>discrim</code>, <code>naivebayes</code>, <code>randomForest</code>, <code>baguette</code>), and modeling and evaluation tools (<code>yardstick</code>, <code>tidymodels</code>). The engines are the software implementations of the algorithms we are estimating. Then we import the student data which includes the engagement indicators and the final grade and prepare it for analysis (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–B). Given that we are doing a classification task, we need a binary outcome, as before, we add a new column to the data that divides the students into “High_Achievers” or “Low_Achievers” based on whether their final grade is above or below the median (top or bottom 50%).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Load and prepare the data</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming student_data is already loaded into the environment</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>student_data <span class="ot">&lt;-</span> raw_data <span class="sc">|&gt;</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Achievement =</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(Final_Grade <span class="sc">&gt;</span> <span class="fu">median</span>(Final_Grade), </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                                     <span class="st">"High_Achievers"</span>, <span class="st">"Low_Achievers"</span>),</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>                              <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"Low_Achievers"</span>, <span class="st">"High_Achievers"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="splitting-the-data-into-training-and-testing-sets-2" class="level4" data-number="3.6.2">
<h4 data-number="3.6.2" class="anchored" data-anchor-id="splitting-the-data-into-training-and-testing-sets-2"><span class="header-section-number">3.6.2</span> Splitting the data into training and testing sets</h4>
<p>Then, we split the data into training and testing sets (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–C). We use <code>initial_split</code> from <code>rsample</code> with the option <code>strata</code> to ensure an 80/20 split while stratifying by the <code>Achievement</code> column to maintain the proportion of high and low achievers in both sets. These steps are already familiar by now.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Split the data into training and testing sets</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(student_data, <span class="at">prop =</span> <span class="fl">0.8</span>, <span class="at">strata =</span> Achievement)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-a-recipe-1" class="level4" data-number="3.6.3">
<h4 data-number="3.6.3" class="anchored" data-anchor-id="creating-a-recipe-1"><span class="header-section-number">3.6.3</span> Creating a recipe</h4>
<p>In this step, we create a recipe that specifies the predictors (engagement indicators) and the target variable (achievement). The recipe also includes a step to normalize all predictor variables, so that they are measured on the same scale. This normalization step is particularly important for algorithms that are sensitive to the scale of the input features to ensure that features contribute equally to the model. Given that we will use identical recipe for all models, we won’t have to write multiple recipes, this is in fact, one of the powerful features of <code>tidymodels</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>model_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Achievement <span class="sc">~</span> Freq_Course_View <span class="sc">+</span> Freq_Lecture_View <span class="sc">+</span> </span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>                       Freq_Forum_Consume <span class="sc">+</span> Freq_Forum_Contribute <span class="sc">+</span> </span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>                       Regularity_Course_View <span class="sc">+</span> Regularity_Lecture_View <span class="sc">+</span> </span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                       Regularity_Forum_Consume <span class="sc">+</span> Regularity_Forum_Contribute <span class="sc">+</span> </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                       Session_Count <span class="sc">+</span> Total_Duration <span class="sc">+</span> Active_Days,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> train_data) <span class="sc">|&gt;</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_predictors</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-all-model-specifications" class="level4" data-number="3.6.4">
<h4 data-number="3.6.4" class="anchored" data-anchor-id="create-all-model-specifications"><span class="header-section-number">3.6.4</span> Create all model specifications</h4>
<p>In this step, we specify the machine learning models through the <code>parsnip</code> package interface <span class="citation" data-cites="parsnip">[<a href="#ref-parsnip" role="doc-biblioref">45</a>]</span>. This involves specifying each algorithm and setting the engine and the parameters. We selected some popular algorithms for demonstration purposes. However, for a full list of supported algorithms, please refer to the <code>parsnip</code> <span class="citation" data-cites="parsnip">[<a href="#ref-parsnip" role="doc-biblioref">45</a>]</span> documentation. Below is the list of algorithms we will demonstrate, along with their respective engines and packages:</p>
<ol type="1">
<li><p><strong>Random Forest</strong>: Random Forest is an ensemble learning method that builds multiple decision trees and merges their predictions by averaging for more accurate and stable results. It is implemented using two engines: <code>ranger</code> from the <code>ranger</code> package <span class="citation" data-cites="ranger">[<a href="#ref-ranger" role="doc-biblioref">48</a>]</span>, known for its speed and performance, and <code>randomForest</code> from the <code>randomForest</code> package, which is the original R implementation <span class="citation" data-cites="randomForest">[<a href="#ref-randomForest" role="doc-biblioref">3</a>]</span>.</p></li>
<li><p><strong>XGBoost (eXtreme Gradient Boosting)</strong>: XGBoost is an efficient and scalable implementation of the gradient boosting framework, optimizing performance by iteratively improving model accuracy. It is implemented using the <code>xgboost</code> engine from the <code>xgboost</code> package <span class="citation" data-cites="xgboost">[<a href="#ref-xgboost" role="doc-biblioref">49</a>]</span>.</p></li>
<li><p><strong>Support Vector Machines (SVM)</strong>: SVM is a powerful classification algorithm that finds the best boundary (hyperplane) to separate different classes in the data. It is implemented through the <code>kernlab</code> engine from the <code>kernlab</code> package <span class="citation" data-cites="kernlab">[<a href="#ref-kernlab" role="doc-biblioref">50</a>]</span>.</p></li>
<li><p><strong>Logistic Regression</strong>: Logistic Regression is a well-known classification algorithm that models the probability of a binary outcome. It uses the <code>glm</code> engine from base R.</p></li>
<li><p><strong>K-Nearest Neighbors (KNN)</strong>: KNN is a simple, non-parametric algorithm that classifies a data point based on the majority class of its nearest neighbors. It is implemented using the <code>kknn</code> engine from the <code>kknn</code> package <span class="citation" data-cites="kknn">[<a href="#ref-kknn" role="doc-biblioref">51</a>]</span>.</p></li>
<li><p><strong>Neural Networks</strong>: Neural Networks are computational models inspired by the human brain, capable of modeling complex patterns in data through layers of interconnected nodes. They are implemented using the <code>nnet</code> engine from the <code>nnet</code> package <span class="citation" data-cites="nnet">[<a href="#ref-nnet" role="doc-biblioref">52</a>]</span>.</p></li>
<li><p><strong>Decision Trees</strong>: Decision Trees split the data into branches to help make decisions based on the features of the data. They are implemented using the <code>rpart</code> engine from the <code>rpart</code> package <span class="citation" data-cites="rpart">[<a href="#ref-rpart" role="doc-biblioref">53</a>]</span>.</p></li>
<li><p><strong>Naive Bayes</strong>: Naive Bayes is a probabilistic algorithm based on Bayes’ theorem, assuming independence between features. It is implemented through the <code>naivebayes</code> engine from the <code>naivebayes</code> package <span class="citation" data-cites="naivebayes">[<a href="#ref-naivebayes" role="doc-biblioref">54</a>]</span>.</p></li>
<li><p><strong>Linear Discriminant Analysis (LDA)</strong>: LDA is used for classification, finding the linear combinations of features that best separate different classes. It uses the <code>MASS</code> engine from the <code>MASS</code> package <span class="citation" data-cites="MASS">[<a href="#ref-MASS" role="doc-biblioref">55</a>]</span>.</p></li>
<li><p><strong>Bagged Trees</strong>: Bagged Trees is an ensemble method that improves the stability and accuracy of machine learning algorithms by combining multiple models. It uses the <code>rpart</code> engine from the <code>rpart</code> package <span class="citation" data-cites="rpart">[<a href="#ref-rpart" role="doc-biblioref">53</a>]</span>.</p></li>
<li><p><strong>Multivariate Adaptive Regression Splines (MARS)</strong>: MARS is a non-linear regression technique that models relationships by fitting piecewise linear regressions. It is implemented using the <code>earth</code> engine from the <code>earth</code> package <span class="citation" data-cites="earth">[<a href="#ref-earth" role="doc-biblioref">56</a>]</span>.</p></li>
<li><p><strong>Bayesian Additive Regression Trees (BART)</strong>: BART is a Bayesian approach to machine learning that creates a sum-of-trees model for both regression and classification tasks. It is implemented using the <code>dbarts</code> engine from the <code>dbarts</code> package.</p></li>
</ol>
<p>These models cover a wide range of popular approaches, all implemented under the <code>parsnip</code> framework for consistent and streamlined usage.</p>
<p>Below is the code that loads the required packags and creates a function specifying each model and its engine, ensuring the full name of the algorithm is used for better display in later steps.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels) <span class="co"># laod the tidymodels framework and its packages</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the required packages for each algorithm</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger) <span class="co"># Engine: ranger, known for its speed and performance</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest) <span class="co"># Engine: randomForest, the original R implementation</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost (eXtreme Gradient Boosting)</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost) <span class="co"># Engine: xgboost, gradient boosting framework</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Support Vector Machines (SVM)</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kernlab) <span class="co"># Engine: kernlab, a powerful classification algorithm</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic Regression</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Base R includes glm, no additional package needed</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co"># K-Nearest Neighbors (KNN)</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kknn)  <span class="co"># Engine: kknn, a simple, non-parametric classification algorithm</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Networks</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet) <span class="co"># Engine: nnet, inspired by the human brain for complex patterns</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision Trees</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart) <span class="co"># Engine: rpart, recursive partitioning for classification trees</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Naive Bayes</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(discrim) <span class="co"># Engine: naivebayes, based on Bayes' theorem</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear Discriminant Analysis (LDA)</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)  <span class="co"># Engine: MASS, classification via linear combinations of features</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Bagged Trees</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Uses the same package as Decision Trees: rpart</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Multivariate Adaptive Regression Splines (MARS)</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(earth) <span class="co"># Engine: earth, non-linear regression with piecewise linear fits</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian Additive Regression Trees (BART)</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dbarts) <span class="co"># Engine: dbarts, Bayesian approach creating a sum-of-trees model</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(baguette)  <span class="co"># Engine: rpart, an ensemble of decision trees</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parsnip) <span class="co"># Interface for `tidymodels`</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>set_classification <span class="ot">&lt;-</span> <span class="cf">function</span>(x, engine) {</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>  x <span class="sc">|&gt;</span> <span class="fu">set_engine</span>(engine) <span class="sc">|&gt;</span> <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to specify each model and its engine</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>create_model_specs <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Random Forest (ranger)"</span> <span class="ot">=</span> <span class="fu">rand_forest</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"ranger"</span>),</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">"XGBoost"</span> <span class="ot">=</span> <span class="fu">boost_tree</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"xgboost"</span>),</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">"SVM (RBF)"</span> <span class="ot">=</span> <span class="fu">svm_rbf</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"kernlab"</span>),</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Logistic Regression"</span> <span class="ot">=</span> <span class="fu">logistic_reg</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"glm"</span>),</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    <span class="st">"K-Nearest Neighbors"</span> <span class="ot">=</span> <span class="fu">nearest_neighbor</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"kknn"</span>),</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Neural Network"</span> <span class="ot">=</span> <span class="fu">mlp</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"nnet"</span>),</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Decision Tree"</span> <span class="ot">=</span> <span class="fu">decision_tree</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"rpart"</span>),</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Naive Bayes"</span> <span class="ot">=</span> <span class="fu">naive_Bayes</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"naivebayes"</span>),</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Linear Discriminant Analysis"</span> <span class="ot">=</span> <span class="fu">discrim_linear</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"MASS"</span>),</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Bagged Tree"</span> <span class="ot">=</span> <span class="fu">bag_tree</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"rpart"</span>),</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Random Forest (randomForest)"</span> <span class="ot">=</span> <span class="fu">rand_forest</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"randomForest"</span>),</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MARS"</span> <span class="ot">=</span> <span class="fu">mars</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"earth"</span>),</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>    <span class="st">"BART"</span> <span class="ot">=</span> parsnip<span class="sc">::</span><span class="fu">bart</span>() <span class="sc">|&gt;</span> <span class="fu">set_classification</span>(<span class="st">"dbarts"</span>)</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the model specifications</span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>model_specs <span class="ot">&lt;-</span> <span class="fu">create_model_specs</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-the-workflows-and-fitting-the-data" class="level4" data-number="3.6.5">
<h4 data-number="3.6.5" class="anchored" data-anchor-id="creating-the-workflows-and-fitting-the-data"><span class="header-section-number">3.6.5</span> Creating the workflows and fitting the data</h4>
<p>Rather than creating a list of 13 workflows, we define a function that automates the process and we use <code>lapply</code> to apply this function to all list items. The function helps easy specification of the models with their respective engines and parameters and the results will be a list which we will also use in further analysis in the same way.</p>
<p>The code below has two key functions: <code>create_workflows</code> and <code>fit_models</code>. The <code>create_workflows</code> function builds a workflow for each model specification in the provided <code>model_specs</code> list, using the specified model recipe and <code>lapply</code> to iterate over the list items. This results in a list of workflows. Then, the <code>fit_models</code> function is used to fit each of these workflows to the training data (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–D), again using <code>lapply</code> to apply the function to every workflow in the list.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>create_workflows <span class="ot">&lt;-</span>  <span class="cf">function</span>(spec) {</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">|&gt;</span> <span class="fu">add_recipe</span>(model_recipe) <span class="sc">|&gt;</span> <span class="fu">add_model</span>(spec)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>model_workflows <span class="ot">&lt;-</span> <span class="fu">lapply</span>(model_specs, create_workflows)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="do">### Fitting the models</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>fit_model <span class="ot">&lt;-</span> <span class="cf">function</span>(workflow) {</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(workflow, <span class="at">data =</span> train_data)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>model_fits <span class="ot">&lt;-</span> <span class="fu">lapply</span>(model_workflows, fit_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluating-the-models" class="level4" data-number="3.6.6">
<h4 data-number="3.6.6" class="anchored" data-anchor-id="evaluating-the-models"><span class="header-section-number">3.6.6</span> Evaluating the models</h4>
<p>Once the models are trained, we can make predictions on the test data. Similar to the previous steps, we create a <code>make_predictions</code> function, and then apply this function to each element of the <code>model_fits</code> list (created in the previous step). The function uses <code>predict</code> to get both class predictions and probabilities, and bind them with the test data for late steps in the evaluation evaluation.</p>
<p>We then, evaluate the models (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–E) with a custom function <code>evaluate_model</code> using several metrics as before. Our evaluation will includes computing a confusion matrix, the evaluation metrics (accuracy, sensitivity, specificity, F1 score, balanced accuracy, positive predictive value (PPV), and negative predictive value (NPV)) as well as ROC curve for each algorithm. Given that the function creates several objects for all the model, the function is a but more sophisticated, and uses list lists.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>make_predictions <span class="ot">&lt;-</span> <span class="cf">function</span>(fit) {</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(fit, test_data) <span class="sc">|&gt;</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)) <span class="sc">|&gt;</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(test_data)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>model_preds <span class="ot">&lt;-</span> <span class="fu">lapply</span>(model_fits, make_predictions)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>evaluate_model <span class="ot">&lt;-</span> <span class="cf">function</span>(pred, model_name) {</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Confusion Matrix</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  conf_mat <span class="ot">&lt;-</span> <span class="fu">conf_mat</span>(pred, <span class="at">truth =</span> Achievement, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Other metrics (Class metrics only)</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>  metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(accuracy, sens, yardstick<span class="sc">::</span>specificity, </span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>                        f_meas, bal_accuracy, ppv, npv)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>  model_performance <span class="ot">&lt;-</span> <span class="fu">metrics</span>(pred, <span class="at">truth =</span> Achievement, </span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>                               <span class="at">estimate =</span> .pred_class)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># ROC Curve</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>  roc_curve <span class="ot">&lt;-</span> <span class="fu">roc_curve</span>(pred, <span class="at">truth =</span> Achievement, .pred_Low_Achievers) <span class="sc">|&gt;</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">model =</span> model_name)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">conf_mat =</span> conf_mat, <span class="at">performance =</span> model_performance, <span class="at">roc =</span> roc_curve)</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate each model and store results</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>evaluate_all_models <span class="ot">&lt;-</span> <span class="cf">function</span>(preds, model_names) {</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mapply</span>(evaluate_model, preds, model_names, <span class="at">SIMPLIFY =</span> <span class="cn">FALSE</span>)</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>evaluation_results <span class="ot">&lt;-</span> <span class="fu">evaluate_all_models</span>(model_preds, <span class="fu">names</span>(model_preds))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="combining-and-plotting-results" class="level5" data-number="3.6.6.1">
<h5 data-number="3.6.6.1" class="anchored" data-anchor-id="combining-and-plotting-results"><span class="header-section-number">3.6.6.1</span> Combining and Plotting Results</h5>
<p>We then combine the performance metrics and ROC curve data for all models into single data frames. These data frames will be used to generate visualizations and for comparison if needed.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>combine_performance_metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(evaluation_results) {</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  performance_df <span class="ot">&lt;-</span> <span class="fu">do.call</span>(rbind, <span class="fu">lapply</span>(evaluation_results, <span class="cf">function</span>(res) {</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    res<span class="sc">$</span>performance</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  }))</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  performance_df<span class="sc">$</span>model <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">names</span>(evaluation_results), </span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>                              <span class="at">times =</span> <span class="fu">sapply</span>(evaluation_results, <span class="cf">function</span>(res) {</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">nrow</span>(res<span class="sc">$</span>performance)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  }))</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  performance_df</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>performance_df <span class="ot">&lt;-</span> <span class="fu">combine_performance_metrics</span>(evaluation_results)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>combine_roc_curves <span class="ot">&lt;-</span> <span class="cf">function</span>(evaluation_results) {</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">do.call</span>(rbind, <span class="fu">lapply</span>(evaluation_results, <span class="cf">function</span>(res) {</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    res<span class="sc">$</span>roc</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  }))</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>roc_df <span class="ot">&lt;-</span> <span class="fu">combine_roc_curves</span>(evaluation_results)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>extract_confusion_matrices <span class="ot">&lt;-</span> <span class="cf">function</span>(evaluation_results) {</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(evaluation_results, <span class="cf">function</span>(res) {</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    res<span class="sc">$</span>conf_mat</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>conf_mat_list <span class="ot">&lt;-</span> <span class="fu">extract_confusion_matrices</span>(evaluation_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We define a color palette for plotting and then create plots for performance metrics and ROC curves.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>palette <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"darkgreen"</span>, <span class="st">"green"</span>, <span class="st">"cyan"</span>, <span class="st">"blue"</span>, <span class="st">"purple"</span>, <span class="st">"magenta"</span>, <span class="st">"pink"</span>,</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>             <span class="st">"red"</span>, <span class="st">"orange"</span>, <span class="st">"yellow"</span>, <span class="st">"darkgoldenrod4"</span>, <span class="st">"grey"</span>, <span class="st">"black"</span> )</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>performance_df <span class="sc">|&gt;</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(model, .metric, .estimate) <span class="sc">|&gt;</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> .estimate, <span class="at">names_to =</span> <span class="st">"metric"</span>, <span class="at">values_to =</span> <span class="st">"value"</span>) <span class="sc">|&gt;</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> .metric, <span class="at">x =</span> value, <span class="at">fill =</span> model)) <span class="sc">+</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">position =</span> <span class="st">"dodge"</span>) <span class="sc">+</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> palette, <span class="at">name =</span> <span class="st">"Metric"</span>) <span class="sc">+</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Model"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-mod-per-met" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-mod-per-met-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;7<strong>.</strong> Model Performance Metrics</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(roc_df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificity, <span class="at">y =</span> sensitivity, <span class="at">color =</span> model)) <span class="sc">+</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> palette, <span class="at">name =</span> <span class="st">"Metric"</span>) <span class="sc">+</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"1 - Specificity"</span>, <span class="at">y =</span> <span class="st">"Sensitivity"</span>) <span class="sc">+</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"right"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-roc-diff" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-roc-diff-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;8<strong>.</strong> ROC Curves for Different Models</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Finally, we plot the confusion matrices for each model using a heatmap.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix <span class="ot">&lt;-</span> <span class="cf">function</span>(conf_mat, model_name) {</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>(conf_mat, <span class="at">type =</span> <span class="st">"heatmap"</span>) <span class="sc">+</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_gradient</span>(<span class="at">low =</span> <span class="st">"white"</span>, <span class="at">high =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(model_name), <span class="at">fill =</span> <span class="st">"Count"</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># List to store ggplot objects</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>plot_list <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate and store each confusion matrix plot</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (model_name <span class="cf">in</span> <span class="fu">names</span>(conf_mat_list)) {</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>  conf_mat_plot <span class="ot">&lt;-</span> <span class="fu">plot_confusion_matrix</span>(conf_mat_list[[model_name]], model_name)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>  plot_list[[model_name]] <span class="ot">&lt;-</span> conf_mat_plot</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine all plots into one grid</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust ncol based on how many columns you want</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(<span class="at">grobs =</span> plot_list, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">nrow =</span> <span class="dv">5</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-conf-mats" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch04-classification_files/figure-html/fig-conf-mats-1.png" class="img-fluid figure-img" width="1152"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;9<strong>.</strong> Confusion matrices of each model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>You can compare the algorithms and evaluate which algorithm has better performance and choose the best model based on this analysis.</p>
</section>
</section>
</section>
</section>
<section id="discussion" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="discussion"><span class="header-section-number">4</span> Discussion</h2>
<p>This chapter explained the application of machine learning, specifically classification techniques, to identify at-risk students in educational settings. We transitioned from the regression-based prediction of student grades discussed in the previous chapter <span class="citation" data-cites="LABOOK2_Chapter_3">[<a href="#ref-LABOOK2_Chapter_3" role="doc-biblioref">1</a>]</span>, to a focus on identifying risky categories of academic performance namely low achievers.</p>
<p>The chapter demonstrated a detailed tutorial on using the Random Forest algorithm for classification. It covered the entire workflow, including data preparation—creating a binary target variable and splitting data into training and testing sets—model training, applying the model to new data, and evaluation using metrics like accuracy, precision, recall and sensitivity. Additionally, the importance of model interpretability was highlighted by showcasing how to extract and visualize variable importance in a Random Forest model. This helps in understanding which factors contribute most significantly to the classification, offering insights into student behaviors that correlate with success or failure. An alternative implementation using the <code>tidymodels</code> framework was presented. This modern approach provides a streamlined and consistent syntax for various machine learning tasks, making it easier to build, compare, and maintain models. Using <code>tidymodels</code>, we demonstrated how to automate the process of fitting, predicting, and evaluating thirteen different classification algorithms, including Random Forest, XGBoost, SVM, Logistic Regression, KNN, Neural Networks, Decision Trees, Naive Bayes, LDA, Bagged Trees, MARS, and BART.</p>
<p>If we can accurately early predict low achievers, we can identify those who are struggling early in the course. This allows for proactive interventions, preventing students from falling too far behind and potentially dropping out <span class="citation" data-cites="saqr2021 Jovanovic2021-et">[<a href="#ref-Jovanovic2021-et" role="doc-biblioref">17</a>, <a href="#ref-saqr2021" role="doc-biblioref">57</a>]</span>. Understanding the factors that contribute to a student being classified as “at-risk” can inform personalized support strategies <span class="citation" data-cites="LABOOK2_Chapter_6 Khosravi2022 LABOOK2_Chapter_7">[<a href="#ref-LABOOK2_Chapter_6" role="doc-biblioref">42</a>, <a href="#ref-LABOOK2_Chapter_7" role="doc-biblioref">43</a>, <a href="#ref-Khosravi2022" role="doc-biblioref">58</a>]</span>. For example, if low engagement with forum discussions is a significant predictor, educators can encourage participation or encourage students to interact with their peers. For teachers, they can use the classification models to identify struggling students before they fail a course, allowing them to reach out, offer additional support, and address any underlying issues that may be hindering progress. The insights gained from variable importance analysis can help teachers tailor their feedback and resources to address specific student needs. Furthermore, these models may help teachers allocate their time and resources more efficiently by focusing on students who need the most support—particularly valuable in large classes where providing individualized attention can be challenging. also, educators can use the data to initiate conversations about academic progress, identify areas where students are struggling, and collaboratively develop strategies for improvement.</p>
<p>However, it is important to acknowledge potential drawbacks associated with predictive modeling in education. One significant concern is the risk of profiling students and inaccurately labeling them as low achievers when they are not. Misclassifications can have detrimental effects on students’ self-esteem, motivation, and overall educational experience. False positives—students incorrectly identified as at-risk—may receive unnecessary interventions, which can lead to stigmatization or decreased expectations from teachers and peers.</p>
<p>Therefore, it is important to use predictive models as supportive tools rather than judgments. Integrating human insight with predictive analytics ensures a more nuanced understanding of each student’s needs. We can’t stress enoguh how ethical considerations must be at the forefront when implementing predictive analytics where transparency about how predictions are made, ensuring data privacy, and actively working to mitigate biases in the models are essential steps.</p>


</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-LABOOK2_Chapter_3" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Saqr M, Misiejuk K, Tikka S, López-Pernas S (2025) Artificial intelligence: Using machine learning to predict students’ performance. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-jovanovic2024predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Jovanovic J, López-Pernas S, Saqr M (2024) Predictive modelling in learning analytics: A machine learning approach in r. In: Learning analytics methods and tutorials: A practical guide using r. Springer Nature Switzerland Cham, pp 197–229</div>
</div>
<div id="ref-randomForest" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Liaw A, Wiener M (2002) <a href="https://CRAN.R-project.org/doc/Rnews/">Classification and regression by randomForest</a>. R News 2:18–22</div>
</div>
<div id="ref-na2017identifying" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Na KS, Tasir Z (2017) Identifying at-risk students in online learning by analysing learning behaviour: A systematic review. In: 2017 IEEE conference on big data and analytics (ICBDA). IEEE, pp 118–123</div>
</div>
<div id="ref-deoliveira2021does" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Oliveira CF de, Sobral SR, Ferreira MJ, Moreira F (2021) How does learning analytics contribute to prevent students’ dropout in higher education: A systematic literature review. Big Data and Cognitive Computing 5:64</div>
</div>
<div id="ref-saqr2017learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Saqr M, Fors U, Tedre M (2017) How learning analytics can early predict under-achieving students in a blended medical education course. Medical teacher 39:757–767</div>
</div>
<div id="ref-bayazit2022predicting" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Bayazit A, Apaydin N, Gonullu I (2022) Predicting at-risk students in an online flipped anatomy course using learning analytics. Education Sciences 12:581</div>
</div>
<div id="ref-queiroga2020learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Queiroga EM, Lopes JL, Kappel K, Aguiar M, Araújo RM, Munoz R, Villarroel R, Cechinel C (2020) A learning analytics approach to identify students at risk of dropout: A case study with a technical distance education course. Applied Sciences 10:3998</div>
</div>
<div id="ref-aljohani2019predicting" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Aljohani NR, Fayoumi A, Hassan S-U (2019) Predicting at-risk students using clickstream data in the virtual learning environment. Sustainability 11:7238</div>
</div>
<div id="ref-adnan2021predicting" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Adnan M, Habib A, Ashraf J, Mussadiq S, Raza AA, Abid M, Bashir M, Khan SU (2021) Predicting at-risk students at different percentages of course length for early intervention using machine learning models. IEEE Access 9:7519–7539</div>
</div>
<div id="ref-gonzalez2023predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Gonzalez-Nucamendi A, Noguez J, Neri L, Robledo-Rella V, García-Castelán RMG (2023) Predictive analytics study to determine undergraduate students at risk of dropout. In: Frontiers in education. p 1244686</div>
</div>
<div id="ref-jayaprakash2014early" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Jayaprakash SM, Moody EW, Lauría EJ, Regan JR, Baron JD (2014) Early alert of academically at-risk students: An open source analytics initiative. Journal of Learning Analytics 1:6–47</div>
</div>
<div id="ref-azcona2019detecting" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Azcona D, Hsiao I-H, Smeaton AF (2019) Detecting students-at-risk in computer programming classes with learning analytics from students’ digital footprints. User Modeling and User-Adapted Interaction 29:759–788</div>
</div>
<div id="ref-anagnostopoulos2020intelligent" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Anagnostopoulos T, Kytagias C, Xanthopoulos T, Georgakopoulos I, Salmon I, Psaromiligkos Y (2020) Intelligent predictive analytics for identifying students at risk of failure in moodle courses. In: Intelligent tutoring systems: 16th international conference, ITS 2020, athens, greece, june 8–12, 2020, proceedings 16. Springer, pp 152–162</div>
</div>
<div id="ref-mathrani2021perspectives" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">Mathrani A, Susnjak T, Ramaswami G, Barczak A (2021) Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics. Computers and Education Open 2:100060</div>
</div>
<div id="ref-saqr2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Saqr M, Jovanovic J, Viberg O, Gašević D (2022) Is there order in the mess? A single paper meta-analysis approach to identification of predictors of success in learning analytics. Studies in Higher Education 47:2370–2391. https://doi.org/<a href="https://doi.org/10.1080/03075079.2022.2061450">10.1080/03075079.2022.2061450</a></div>
</div>
<div id="ref-Jovanovic2021-et" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Jovanović J, Saqr M, Joksimović S, Gašević D (2021) Students matter the most in learning analytics: The effects of internal and instructional conditions in predicting academic success. Comput Educ 172:104251. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2021.104251">10.1016/j.compedu.2021.104251</a></div>
</div>
<div id="ref-foster2020effectiveness" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Foster E, Siddle R (2020) The effectiveness of learning analytics for identifying at-risk students in higher education. Assessment &amp; Evaluation in Higher Education 45:842–854</div>
</div>
<div id="ref-wolff2013improving" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">Wolff A, Zdrahal Z, Nikolov A, Pantucek M (2013) Improving retention: Predicting at-risk students by analysing clicking behaviour in a virtual learning environment. In: Proceedings of the third international conference on learning analytics and knowledge. pp 145–149</div>
</div>
<div id="ref-queiroga2022early" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Queiroga EM, Batista Machado MF, Paragarino VR, Primo TT, Cechinel C (2022) Early prediction of at-risk students in secondary education: A countrywide k-12 learning analytics initiative in uruguay. Information 13:401</div>
</div>
<div id="ref-choi2018learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Choi SP, Lam SS, Li KC, Wong BT (2018) Learning analytics at low cost: At-risk student prediction with clicker data and systematic proactive interventions. Journal of Educational Technology &amp; Society 21:273–290</div>
</div>
<div id="ref-hlosta2022predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline">Hlosta M, Herodotou C, Papathoma T, Gillespie A, Bergamin P (2022) Predictive learning analytics in online education: A deeper understanding through explaining algorithmic errors. Computers and Education: Artificial Intelligence 3:100108</div>
</div>
<div id="ref-gkontzis2022predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline">Gkontzis AF, Kotsiantis S, Panagiotakopoulos CT, Verykios VS (2022) A predictive analytics framework as a countermeasure for attrition of students. Interactive Learning Environments 30:1028–1043</div>
</div>
<div id="ref-cechinel2021learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline">Cechinel C, Dos Santos MDF, Barrozo C, Schardosim JE, Vila E de, Ramos V, Primo T, Munoz R, Queiroga EM (2021) A learning analytics dashboard for moodle: Implementing machine learning techniques to early detect students at risk of failure. In: 2021 XVI latin american conference on learning technologies (LACLO). IEEE, pp 130–136</div>
</div>
<div id="ref-saqr2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline">Saqr M, Nouri J (2020) High resolution temporal network analysis to understand and improve collaborative learning. Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge 314–319. https://doi.org/<a href="https://doi.org/10.1145/3375462.3375501">10.1145/3375462.3375501</a></div>
</div>
<div id="ref-saqr2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline">Saqr M, Cheng R, López-Pernas S, Beck ED (2024) Idiographic artificial intelligence to explain students’ self-regulation: Toward precision education. Learning and Individual Differences 114:102499. https://doi.org/<a href="https://doi.org/10.1016/j.lindif.2024.102499">10.1016/j.lindif.2024.102499</a></div>
</div>
<div id="ref-kaliisa2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline">Kaliisa R, Misiejuk K, López-Pernas S, Khalil M, Saqr M (2024) Have learning analytics dashboards lived up to the hype? A systematic review of impact on students’ achievement, motivation, participation and attitude. Proceedings of the 14th Learning Analytics and Knowledge Conference 295–304. https://doi.org/<a href="https://doi.org/10.1145/3636555.3636884">10.1145/3636555.3636884</a></div>
</div>
<div id="ref-paulsen2024learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline">Paulsen L, Lindsay E (2024) Learning analytics dashboards are increasingly becoming about learning and not just analytics-a systematic review. Education and Information Technologies 1–30</div>
</div>
<div id="ref-ramaswami2023use" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline">Ramaswami G, Susnjak T, Mathrani A, Umer R (2023) Use of predictive analytics within learning analytics dashboards: A review of case studies. Technology, Knowledge and Learning 28:959–980</div>
</div>
<div id="ref-saqr2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline">Saqr M, Fors U, Tedre M, Nouri J (2018) How social network analysis can be used to monitor online collaborative learning and guide an informed intervention. PLOS ONE 13:e0194777. https://doi.org/<a href="https://doi.org/10.1371/journal.pone.0194777">10.1371/journal.pone.0194777</a></div>
</div>
<div id="ref-rienties2017implementing" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline">Rienties B, Cross S, Zdrahal Z (2017) Implementing a learning analytics intervention and evaluation framework: What works? Big data and learning analytics in higher education: Current theory and practice 147–166</div>
</div>
<div id="ref-Tikka2024-ph" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline">Tikka S, Kopra J, Heinäniemi M, López-Pernas S, Saqr M (2024) Getting started with <span>R</span> for education research. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Kopra2024-fx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">33. </div><div class="csl-right-inline">Kopra J, Tikka S, Heinäniemi M, López-Pernas S, Saqr M (2024) An <span>R</span> approach to data cleaning and wrangling for education research. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Tikka2024-wl" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">34. </div><div class="csl-right-inline">Tikka S, Kopra J, Heinäniemi M, López-Pernas S, Saqr M (2024) Introductory statistics with <span>R</span> for educational researchers. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Lopez-Pernas2024-ge" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">35. </div><div class="csl-right-inline">López-Pernas S, Misiejuk K, Tikka S, Kopra J, Heinäniemi M, Saqr M (2024) <a href="https://doi.org/10.1007/978-3-031-54464-4\_6">Visualizing and reporting educational data with <span>R</span></a>. In: Learning analytics methods and tutorials. Springer Nature Switzerland, Cham, pp 151–194</div>
</div>
<div id="ref-tidyverse" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">36. </div><div class="csl-right-inline">Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019) Welcome to the <span class="nocase">tidyverse</span>. Journal of Open Source Software 4:1686. https://doi.org/<a href="https://doi.org/10.21105/joss.01686">10.21105/joss.01686</a></div>
</div>
<div id="ref-rsample" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">37. </div><div class="csl-right-inline">Frick H, Chow F, Kuhn M, Mahoney M, Silge J, Wickham H (2024) <a href="https://CRAN.R-project.org/package=rsample">Rsample: General resampling infrastructure</a></div>
</div>
<div id="ref-caret" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">38. </div><div class="csl-right-inline">Kuhn, Max (2008) Building predictive models in r using the caret package. Journal of Statistical Software 28:1–26. https://doi.org/<a href="https://doi.org/10.18637/jss.v028.i05">10.18637/jss.v028.i05</a></div>
</div>
<div id="ref-rio" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">39. </div><div class="csl-right-inline">Chan C, Leeper TJ, Becker J, Schoch D (2023) <a href="https://cran.r-project.org/package=rio">Rio: A swiss-army knife for data file i/o</a></div>
</div>
<div id="ref-Saqr2024-ie" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">40. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2024) Why explainable <span>AI</span> may not be enough: Predictions and mispredictions in decision making in education. Smart Learn Environ. <a href="https://doi.org/10.1186/s40561-024-00343-4">https://doi.org/10.1186/s40561-024-00343-4</a></div>
</div>
<div id="ref-LABOOK2_Chapter_2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">41. </div><div class="csl-right-inline">López-Pernas S, Oliveira E, Song Y, Saqr M (2025) AI, explainable AI and evaluative AI: An introduction to informed data-driven decision-making in education. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">42. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2025) Explainable artificial intelligence in education: A tutorial for identifying the variables that matter. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">43. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2025) Individualized explainable artificial intelligence: A tutorial for identifying local and individual predictions. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-tidymodels" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">44. </div><div class="csl-right-inline">Kuhn M, Wickham H (2020) <a href="https://www.tidymodels.org">Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles.</a></div>
</div>
<div id="ref-parsnip" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">45. </div><div class="csl-right-inline">Kuhn M, Vaughan D (2024) <a href="https://CRAN.R-project.org/package=parsnip">Parsnip: A common API to modeling and analysis functions</a></div>
</div>
<div id="ref-recipes" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">46. </div><div class="csl-right-inline">Kuhn M, Wickham H, Hvitfeldt E (2024) <a href="https://CRAN.R-project.org/package=recipes">Recipes: Preprocessing and feature engineering steps for modeling</a></div>
</div>
<div id="ref-yardstick" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">47. </div><div class="csl-right-inline">Kuhn M, Vaughan D, Hvitfeldt E (2024) <a href="https://CRAN.R-project.org/package=yardstick">Yardstick: Tidy characterizations of model performance</a></div>
</div>
<div id="ref-ranger" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">48. </div><div class="csl-right-inline">Wright MN, Ziegler A (2017) <span class="nocase">ranger</span>: A fast implementation of random forests for high dimensional data in <span>C++</span> and <span>R</span>. Journal of Statistical Software 77:1–17. https://doi.org/<a href="https://doi.org/10.18637/jss.v077.i01">10.18637/jss.v077.i01</a></div>
</div>
<div id="ref-xgboost" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">49. </div><div class="csl-right-inline">Chen T, He T, Benesty M, Khotilovich V, Tang Y, Cho H, Chen K, Mitchell R, Cano I, Zhou T, Li M, Xie J, Lin M, Geng Y, Li Y, Yuan J (2024) <a href="https://CRAN.R-project.org/package=xgboost">Xgboost: Extreme gradient boosting</a></div>
</div>
<div id="ref-kernlab" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">50. </div><div class="csl-right-inline">Karatzoglou A, Smola A, Hornik K, Zeileis A (2004) Kernlab – an <span>S4</span> package for kernel methods in <span>R</span>. Journal of Statistical Software 11:1–20. https://doi.org/<a href="https://doi.org/10.18637/jss.v011.i09">10.18637/jss.v011.i09</a></div>
</div>
<div id="ref-kknn" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">51. </div><div class="csl-right-inline">Schliep K, Hechenbichler K (2016) <a href="https://CRAN.R-project.org/package=kknn">Kknn: Weighted k-nearest neighbors</a></div>
</div>
<div id="ref-nnet" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">52. </div><div class="csl-right-inline">Venables WN, Ripley BD (2002) <a href="https://www.stats.ox.ac.uk/pub/MASS4/">Modern applied statistics with s</a>, Fourth. Springer, New York</div>
</div>
<div id="ref-rpart" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">53. </div><div class="csl-right-inline">Therneau T, Atkinson B (2022) <a href="https://CRAN.R-project.org/package=rpart">Rpart: Recursive partitioning and regression trees</a></div>
</div>
<div id="ref-naivebayes" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">54. </div><div class="csl-right-inline">Majka M (2024) <a href="https://CRAN.R-project.org/package=naivebayes">Naivebayes: High performance implementation of the naive bayes algorithm in r</a></div>
</div>
<div id="ref-MASS" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">55. </div><div class="csl-right-inline">Venables WN, Ripley BD (2002) <a href="https://www.stats.ox.ac.uk/pub/MASS4/">Modern applied statistics with s</a>, Fourth. Springer, New York</div>
</div>
<div id="ref-earth" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">56. </div><div class="csl-right-inline">Trevor Hastie SMilborrowD from mda:mars by, Thomas Lumley’s leaps wrapper. RTibshiraniUAMF utilities with (2024) <a href="https://CRAN.R-project.org/package=earth">Earth: Multivariate adaptive regression splines</a></div>
</div>
<div id="ref-saqr2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">57. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2021) The longitudinal trajectories of online engagement over a full program. Computers &amp; Education 175:104325. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2021.104325">10.1016/j.compedu.2021.104325</a></div>
</div>
<div id="ref-Khosravi2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">58. </div><div class="csl-right-inline">Khosravi H, Shum SB, Chen G, Conati C, Tsai Y-S, Kay J, Knight S, Martinez-Maldonado R, Sadiq S, Gašević D (2022) Explainable artificial intelligence in education. Computers and Education: Artificial Intelligence 3:100074</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/ch03-prediction/ch03-prediction.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Prediction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/ch05-regularization/ch05-regularization.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regularization</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
  </div>
</footer>
<script>
  document.querySelector(".quarto-title").innerHTML =  '<div class="badge bs-warning bg-warning text-dark" style="float:right;">Pre-print</div>' +  document.querySelector(".quarto-title").innerHTML
  var keywords = document.querySelector('meta[name="keywords"]')
  if (keywords && keywords.content) {
    document.getElementById("title-block-header").innerHTML = document.getElementById("title-block-header").innerHTML + 
      '<div class="abstract"><div class="abstract-title">Keywords</div><div class="quarto-title-meta-contents"><p>'+
      keywords.content +
      '</p></div></div>'
  }
  function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(newNode, referenceNode.nextSibling);
  }
  var authors = document.querySelectorAll('meta[name="author"]')
  if (authors) {
    var authorlist = Array.from(authors).map(e=>e.content).reduce((accum, curr) =>  accum + curr + ", ", "","").replace(/\,\s$/,"")
    var citt = `<div class="card border-primary mb-3" style=;">
      <div class="card-header bg-primary">To cite this chapter</div>
      <div class="card-body small">
        <p class="card-text">${authorlist} (2025).
        <b>${document.getElementsByClassName("chapter-title")[0].innerText}</b>. 
        In M. Saqr & S. López-Pernas (Eds.), <i>Advanced Learning Analytics Methods: AI, Precision and Complexity</i> 
        (in – press). Springer. <a href="${window.location.href}">${window.location.href}</a></p>
      </div>
    </div>`;
    insertAfter(document.getElementsByTagName("HEADER")[1],new DOMParser().parseFromString(citt, 'text/html').body.childNodes[0])
  }
</script>



</body></html>
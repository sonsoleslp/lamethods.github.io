<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mohammed Saqr">
<meta name="author" content="Kamila Misiejuk">
<meta name="author" content="Santtu Tikka">
<meta name="author" content="Sonsoles López-Pernas">
<meta name="keywords" content="learning analytics, predictive modeling, artificial intelligence, regression">

<title>Advanced learning analytics methods - 3&nbsp; Artificial Intelligence: Using Machine Learning to Predict Students’ Performance</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/ch04-classification/ch04-classification.html" rel="next">
<link href="../../chapters/ch02-AIxAI/ch02-aixai.html" rel="prev">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y4VBV3J9WD"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y4VBV3J9WD', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  

<link href="../../site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="../../site_libs/pagedtable-1.1/js/pagedtable.js"></script>


<meta name="twitter:title" content="Advanced learning analytics methods - 3&nbsp; Artificial Intelligence: Using Machine Learning to Predict Students’ Performance">
<meta name="twitter:description" content="Being able to predict students' performance has been a primary driver for the adoption of learning analytics and has attracted many scientists to the field.">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="[3]{.chapter-number}&nbsp; [Artificial Intelligence: Using Machine Learning to Predict Students&amp;amp;#039; Performance]{.chapter-title}">
<meta name="citation_abstract" content="Being able to predict students&amp;amp;#039; performance has been a primary driver for the adoption of learning analytics and has attracted many scientists to the field. Predictive modeling focuses on using students' data to forecast outcomes such as student grades, enabling teachers and administrators to offer just-in-time support to students at risk. This chapter uses advanced predictive methods, namely machine learning, where the goal is to predict continuous variables like grades. The chapter uses advanced and popular AI/machine learning algorithms like Random Forest, K-Nearest Neighbor, Linear Regression, Neural Networks, and Support Vector Machines. The chapter provides a practical guide to building and evaluating predictive models with R using two approaches: one is the classic approach for predictive modeling with R, and the other more modern approach using the `tidymodels` suite.">
<meta name="citation_keywords" content="learning analytics, predictive modeling, artificial intelligence, regression">
<meta name="citation_author" content="Mohammed Saqr">
<meta name="citation_author" content="Kamila Misiejuk">
<meta name="citation_author" content="Santtu Tikka">
<meta name="citation_author" content="Sonsoles López-Pernas">
<meta name="citation_fulltext_html_url" content="https://lamethods.github.io/ch03-prediction.html">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Students matter the most in learning analytics: The effects of internal and instructional conditions in predicting academic success;,citation_abstract=Predictive modelling of academic success and retention has been a key research theme in Learning Analytics. While the initial work on predictive model…;,citation_author=Jelena Jovanović;,citation_author=Mohammed Saqr;,citation_author=Srećko Joksimović;,citation_author=Dragan Gašević;,citation_publication_date=2021-10;,citation_cover_date=2021-10;,citation_year=2021;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.compedu.2021.104251;,citation_issue=104251;,citation_doi=10.1016/j.compedu.2021.104251;,citation_issn=0360-1315,1873-782X;,citation_volume=172;,citation_journal_title=Comput. Educ.;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=An r approach to data cleaning and wrangling for education research;,citation_author=Juho Kopra;,citation_author=Santtu Tikka;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Introductory statistics with r for educational researchers;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics;,citation_author=Anuradha Mathrani;,citation_author=Teo Susnjak;,citation_author=Gomathy Ramaswami;,citation_author=Andre Barczak;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=2;,citation_journal_title=Computers and Education Open;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Predictive modelling in learning analytics: A machine learning approach in r;,citation_author=Jelena Jovanovic;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Implementing a learning analytics intervention and evaluation framework: What works?;,citation_author=Bart Rienties;,citation_author=Simon Cross;,citation_author=Zdenek Zdrahal;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Big data and learning analytics in higher education: Current theory and practice;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Learning analytics dashboards are increasingly becoming about learning and not just analytics-a systematic review;,citation_author=Lucas Paulsen;,citation_author=Euan Lindsay;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_journal_title=Education and Information Technologies;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Use of predictive analytics within learning analytics dashboards: A review of case studies;,citation_author=Gomathy Ramaswami;,citation_author=Teo Susnjak;,citation_author=Anuradha Mathrani;,citation_author=Rahila Umer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=3;,citation_volume=28;,citation_journal_title=Technology, Knowledge and Learning;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Early alert of academically at-risk students: An open source analytics initiative;,citation_author=Sandeep M Jayaprakash;,citation_author=Erik W Moody;,citation_author=Eitel JM Lauría;,citation_author=James R Regan;,citation_author=Joshua D Baron;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=1;,citation_journal_title=Journal of Learning Analytics;">
<meta name="citation_reference" content="citation_title=Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics;,citation_author=Anuradha Mathrani;,citation_author=Teo Susnjak;,citation_author=Gomathy Ramaswami;,citation_author=Andre Barczak;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=2;,citation_journal_title=Computers and Education Open;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=A systematic review of learning analytics intervention contributing to student success in online learning;,citation_author=Kew Si Na;,citation_author=Zaidatun Tasir;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 international conference on learning and teaching in computing and engineering (LaTICE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Predicting at-risk students using clickstream data in the virtual learning environment;,citation_author=Naif Radi Aljohani;,citation_author=Ayman Fayoumi;,citation_author=Saeed-Ul Hassan;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=24;,citation_volume=11;,citation_journal_title=Sustainability;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Do predictive analytics dream of risk-free education? The politics of risk mitigation;,citation_author=Irina Zakharova;,citation_author=Juliane Jarke;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=1;,citation_volume=6;,citation_journal_title=Postdigital Science and Education;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=A predictive analytics framework as a countermeasure for attrition of students;,citation_author=Andreas F Gkontzis;,citation_author=Sotiris Kotsiantis;,citation_author=Christos T Panagiotakopoulos;,citation_author=Vassilios S Verykios;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=6;,citation_volume=30;,citation_journal_title=Interactive Learning Environments;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Elements of success: Supporting at-risk student resilience through learning analytics;,citation_author=Jae-Eun Russell;,citation_author=Anna Smith;,citation_author=Russell Larsen;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=152;,citation_journal_title=Computers &amp;amp;amp; Education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Improving retention: Predicting at-risk students by analysing clicking behaviour in a virtual learning environment;,citation_author=Annika Wolff;,citation_author=Zdenek Zdrahal;,citation_author=Andriy Nikolov;,citation_author=Michal Pantucek;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the third international conference on learning analytics and knowledge;">
<meta name="citation_reference" content="citation_title=From prediction to impact: Evaluation of a learning analytics retention program;,citation_author=Shane Dawson;,citation_author=Jelena Jovanovic;,citation_author=Dragan Gašević;,citation_author=Abelardo Pardo;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=Proceedings of the seventh international learning analytics &amp;amp;amp; knowledge conference;">
<meta name="citation_reference" content="citation_title=Predictive learning analytics in online education: A deeper understanding through explaining algorithmic errors;,citation_author=Martin Hlosta;,citation_author=Christothea Herodotou;,citation_author=Tina Papathoma;,citation_author=Anna Gillespie;,citation_author=Per Bergamin;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=3;,citation_journal_title=Computers and Education: Artificial Intelligence;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Detecting students-at-risk in computer programming classes with learning analytics from students’ digital footprints;,citation_author=David Azcona;,citation_author=I-Han Hsiao;,citation_author=Alan F Smeaton;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=29;,citation_journal_title=User Modeling and User-Adapted Interaction;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=The effectiveness of learning analytics for identifying at-risk students in higher education;,citation_author=Ed Foster;,citation_author=Rebecca Siddle;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=6;,citation_volume=45;,citation_journal_title=Assessment &amp;amp;amp; Evaluation in Higher Education;,citation_publisher=Taylor &amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Early prediction of at-risk students in secondary education: A countrywide k-12 learning analytics initiative in uruguay;,citation_author=Emanuel Marques Queiroga;,citation_author=Matheus Francisco Batista Machado;,citation_author=Virgı́nia Rodés Paragarino;,citation_author=Tiago Thompsen Primo;,citation_author=Cristian Cechinel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=9;,citation_volume=13;,citation_journal_title=Information;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Predicting at-risk students in an online flipped anatomy course using learning analytics;,citation_author=Alper Bayazit;,citation_author=Nihal Apaydin;,citation_author=Ipek Gonullu;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=9;,citation_volume=12;,citation_journal_title=Education Sciences;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=How learning analytics can early predict under-achieving students in a blended medical education course;,citation_author=Mohammed Saqr;,citation_author=Uno Fors;,citation_author=Matti Tedre;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=7;,citation_volume=39;,citation_journal_title=Medical teacher;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Predictive analytics study to determine undergraduate students at risk of dropout;,citation_author=Andres Gonzalez-Nucamendi;,citation_author=Julieta Noguez;,citation_author=Luis Neri;,citation_author=Víctor Robledo-Rella;,citation_author=Rosa María Guadalupe García-Castelán;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_volume=8;,citation_conference_title=Frontiers in education;">
<meta name="citation_reference" content="citation_title=A learning analytics dashboard for moodle: Implementing machine learning techniques to early detect students at risk of failure;,citation_author=Cristian Cechinel;,citation_author=Mateus De Freitas Dos Santos;,citation_author=Caio Barrozo;,citation_author=Jesiel Emerim Schardosim;,citation_author=Eduardo Vila;,citation_author=Vinicius Ramos;,citation_author=Tiago Primo;,citation_author=Roberto Munoz;,citation_author=Emanuel Marques Queiroga;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=2021 XVI latin american conference on learning technologies (LACLO);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Identifying at-risk students in online learning by analysing learning behaviour: A systematic review;,citation_author=Kew Si Na;,citation_author=Zaidatun Tasir;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE conference on big data and analytics (ICBDA);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Predicting at-risk students at different percentages of course length for early intervention using machine learning models;,citation_author=Muhammad Adnan;,citation_author=Asad Habib;,citation_author=Jawad Ashraf;,citation_author=Shafaq Mussadiq;,citation_author=Arsalan Ali Raza;,citation_author=Muhammad Abid;,citation_author=Maryam Bashir;,citation_author=Sana Ullah Khan;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=9;,citation_journal_title=IEEE Access;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=How does learning analytics contribute to prevent students’ dropout in higher education: A systematic literature review;,citation_author=Catarina Félix Oliveira;,citation_author=Sónia Rolland Sobral;,citation_author=Maria João Ferreira;,citation_author=Fernando Moreira;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=4;,citation_volume=5;,citation_journal_title=Big Data and Cognitive Computing;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Intelligent predictive analytics for identifying students at risk of failure in moodle courses;,citation_author=Theodoros Anagnostopoulos;,citation_author=Christos Kytagias;,citation_author=Theodoros Xanthopoulos;,citation_author=Ioannis Georgakopoulos;,citation_author=Ioannis Salmon;,citation_author=Yannis Psaromiligkos;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=Intelligent tutoring systems: 16th international conference, ITS 2020, athens, greece, june 8–12, 2020, proceedings 16;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=A learning analytics approach to identify students at risk of dropout: A case study with a technical distance education course;,citation_author=Emanuel Marques Queiroga;,citation_author=João Ladislau Lopes;,citation_author=Kristofer Kappel;,citation_author=Marilton Aguiar;,citation_author=Ricardo Matsumura Araújo;,citation_author=Roberto Munoz;,citation_author=Rodolfo Villarroel;,citation_author=Cristian Cechinel;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=11;,citation_volume=10;,citation_journal_title=Applied Sciences;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Learning analytics at low cost: At-risk student prediction with clicker data and systematic proactive interventions;,citation_author=Samuel PM Choi;,citation_author=Sze Sing Lam;,citation_author=Kam Cheong Li;,citation_author=Billy TM Wong;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=2;,citation_volume=21;,citation_journal_title=Journal of Educational Technology &amp;amp;amp; Society;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Recent advances in predictive learning analytics: A decade systematic review (2012–2022);,citation_author=Nabila Sghir;,citation_author=Amina Adadi;,citation_author=Mohammed Lahmer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=7;,citation_volume=28;,citation_journal_title=Education and information technologies;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Six practical recommendations enabling ethical use of predictive learning analytics in distance education.;,citation_author=Irina Rets;,citation_author=Christothea Herodotou;,citation_author=Anna Gillespie;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=1;,citation_volume=10;,citation_journal_title=Journal of Learning Analytics;,citation_publisher=ERIC;">
<meta name="citation_reference" content="citation_title=Learning analytics should not promote one size fits all: The effects of instructional conditions in predicting academic success;,citation_author=Dragan Gašević;,citation_author=Shane Dawson;,citation_author=Tim Rogers;,citation_author=Danijela Gasevic;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=28;,citation_journal_title=The Internet and Higher Education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Student performance prediction via online learning behavior analytics;,citation_author=Wei Zhang;,citation_author=Xujun Huang;,citation_author=Shengming Wang;,citation_author=Jiangbo Shu;,citation_author=Hai Liu;,citation_author=Hao Chen;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 international symposium on educational technology (ISET);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Relations between student online learning behavior and academic achievement in higher education: A learning analytics approach;,citation_author=Il-Hyun Jo;,citation_author=Taeho Yu;,citation_author=Hyeyun Lee;,citation_author=Yeonjoo Kim;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Emerging issues in smart learning;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Applying learning analytics to predict the student’s learning outcome based on online learning activities;,citation_author=Viet Anh Nguyen;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_conference_title=Proceedings of the 2024 10th international conference on frontiers of educational technologies;">
<meta name="citation_reference" content="citation_title=Educational data mining for predicting students’ academic performance using machine learning algorithms;,citation_author=Pranav Dabhade;,citation_author=Ravina Agarwal;,citation_author=KP Alameen;,citation_author=AT Fathima;,citation_author=R Sridharan;,citation_author=G Gopakumar;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=47;,citation_journal_title=Materials Today: Proceedings;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Predicting academic success in higher education: Literature review and best practices;,citation_author=Eyman Alyahyan;,citation_author=Dilek Düştegör;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=17;,citation_journal_title=International Journal of Educational Technology in Higher Education;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Resampling strategies for imbalanced regression: A survey and empirical analysis;,citation_author=Juscimara G Avelino;,citation_author=George DC Cavalcanti;,citation_author=Rafael MO Cruz;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=4;,citation_volume=57;,citation_journal_title=Artificial Intelligence Review;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Student performance prediction using support vector machine and k-nearest neighbor;,citation_author=Huda Al-Shehri;,citation_author=Amani Al-Qarni;,citation_author=Leena Al-Saati;,citation_author=Arwa Batoaq;,citation_author=Haifa Badukhen;,citation_author=Saleh Alrashed;,citation_author=Jamal Alhiyafi;,citation_author=Sunday O Olatunji;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE 30th canadian conference on electrical and computer engineering (CCECE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Contextualizing the current state of research on the use of machine learning for student performance prediction: A systematic literature review;,citation_author=Khalid Alalawi;,citation_author=Rukshan Athauda;,citation_author=Raymond Chiong;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=12;,citation_volume=5;,citation_journal_title=Engineering Reports;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Learning models for student performance prediction;,citation_author=Rafael Cavazos;,citation_author=Sara Elena Garza;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Advances in computational intelligence: 16th mexican international conference on artificial intelligence, MICAI 2017, enseneda, mexico, october 23-28, 2017, proceedings, part II 16;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=An overview and comparison of supervised data mining techniques for student exam performance prediction;,citation_author=Nikola Tomasevic;,citation_author=Nikola Gvozdenovic;,citation_author=Sanja Vranes;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=143;,citation_journal_title=Computers &amp;amp;amp; education;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Generating actionable predictive models of academic performance;,citation_author=Abelardo Pardo;,citation_author=Negin Mirriahi;,citation_author=Roberto Martinez-Maldonado;,citation_author=Jelena Jovanovic;,citation_author=Shane Dawson;,citation_author=Dragan Gašević;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the sixth international conference on learning analytics &amp;amp;amp; knowledge;">
<meta name="citation_reference" content="citation_title=Construct and consequential validity for learning analytics based on trace data;,citation_author=Philip H. Winne;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=112;,citation_journal_title=Computers in Human Behavior;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics;,citation_author=Anuradha Mathrani;,citation_author=Teo Susnjak;,citation_author=Gomathy Ramaswami;,citation_author=Andre Barczak;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_volume=2;,citation_journal_title=Computers and Education Open;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=A systematic meta-review and analysis of learning analytics research;,citation_author=Xu Du;,citation_author=Juan Yang;,citation_author=Brett E Shelton;,citation_author=Jui-Long Hung;,citation_author=Mingyan Zhang;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=1;,citation_volume=40;,citation_journal_title=Behaviour &amp;amp;amp; information technology;,citation_publisher=Taylor &amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Predicting student performance using data mining and learning analytics techniques: A systematic literature review;,citation_author=Abdallah Namoun;,citation_author=Abdullah Alshanqiti;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=11;,citation_journal_title=Applied Sciences;,citation_publisher=MDPI;">
<meta name="citation_reference" content="citation_title=Predictive modelling in teaching and learning;,citation_author=Christopher Brooks;,citation_author=Craig Thompson;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Handbook of learning analytics;,citation_publisher=Society for Learning Analytics Research Beaumont;">
<meta name="citation_reference" content="citation_title=Predictive analytics;,citation_author=Wayne W Eckerson;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=1;,citation_journal_title=Extending the Value of Your Data Warehousing Investment. TDWI Best Practices Report;">
<meta name="citation_reference" content="citation_title=Designing learning analytics experiences;,citation_author=Abelardo Pardo;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_inbook_title=Learning analytics: From research to practice;">
<meta name="citation_reference" content="citation_title=Random forests;,citation_abstract=Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund &amp;amp;amp; R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.;,citation_author=Leo Breiman;,citation_publication_date=2001-10;,citation_cover_date=2001-10;,citation_year=2001;,citation_fulltext_html_url=https://doi.org/10.1023/A:1010933404324;,citation_issue=1;,citation_doi=10.1023/A:1010933404324;,citation_issn=0885-6125,1573-0565;,citation_volume=45;,citation_journal_title=Mach. Learn.;">
<meta name="citation_reference" content="citation_title=The longitudinal association between engagement and achievement varies by time, students’ profiles, and achievement state: A full program study;,citation_abstract=There is a paucity of longitudinal studies in online learning across courses or throughout programs. Our study intends to add to this emerging body of research by analyzing the longitudinal trajectories of interaction between student engagement and achievement over a full four-year program. We use learning analytics and life-course methods to study how achievement and engagement are intertwined and how such relationship evolves over a full program for 106 students. Our findings have indicated that the association between engagement and achievement varies between students and progresses differently between such groups over time. Our results showed that online engagement at any single time-point is not a consistent indicator for high achievement. It takes more than a single point of time to reliably forecast high achievement throughout the program. Longitudinal high grades, or longitudinal high levels of engagement (either separately or combined) were indicators of a stable academic trajectory in which students remained engaged —at least on average— and had a higher level of achievement. On the other hand, disengagement at any time point was consistently associated with lower achievement among low-engaged students. Improving to a higher level of engagement was associated with —at least— acceptable achievement levels and rare dropouts. Lack of improvement or “catching up” may be a more ominous sign that should be proactively addressed.;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Satu Helske;,citation_author=Stefan Hrastinski;,citation_publication_date=2023-07;,citation_cover_date=2023-07;,citation_year=2023;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S0360131523000647;,citation_doi=10.1016/j.compedu.2023.104787;,citation_issn=0360-1315;,citation_volume=199;,citation_journal_title=Comput. Educ.;">
<meta name="citation_reference" content="citation_title=Visualizing and reporting educational data with R;,citation_abstract=AbstractVisualizing data is central in learning analytics research, underpins learning dashboards, and is a prime method for reporting results and insights to stakeholders. In this chapter, the reader will be guided through the process of generating meaningful and aesthetically pleasing visualizations of different types of student data using well-known R packages. The main visualization types will be demonstrated with an explanation of their usage and use cases. Furthermore, learning-related examples will be discussed in detail. For instance, readers will learn how to visualize learners’ logs extracted from learning management systems to show how trace data can be used to track students’ learning activities. In addition to creating compelling plots, readers will also be able to generate professional-looking tables with summary statistics.;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://link.springer.com/chapter/10.1007/978-3-031-54464-4_6;,citation_doi=10.1007/978-3-031-54464-4\_6;,citation_isbn=9783031544637,9783031544644;,citation_inbook_title=Learning analytics methods and tutorials;">
<meta name="citation_reference" content="citation_title=Welcome to the tidyverse;,citation_author=Hadley Wickham;,citation_author=Mara Averick;,citation_author=Jennifer Bryan;,citation_author=Winston Chang;,citation_author=Lucy D’Agostino McGowan;,citation_author=Romain François;,citation_author=Garrett Grolemund;,citation_author=Alex Hayes;,citation_author=Lionel Henry;,citation_author=Jim Hester;,citation_author=Max Kuhn;,citation_author=Thomas Lin Pedersen;,citation_author=Evan Miller;,citation_author=Stephan Milton Bache;,citation_author=Kirill Müller;,citation_author=Jeroen Ooms;,citation_author=David Robinson;,citation_author=Dana Paige Seidel;,citation_author=Vitalie Spinu;,citation_author=Kohske Takahashi;,citation_author=Davis Vaughan;,citation_author=Claus Wilke;,citation_author=Kara Woo;,citation_author=Hiroaki Yutani;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=43;,citation_doi=10.21105/joss.01686;,citation_volume=4;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=Methods and algorithms for correlation analysis in R;,citation_author=Dominique Makowski;,citation_author=Mattan Ben-Shachar;,citation_author=Indrajeet Patil;,citation_author=Daniel Lüdecke;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_fulltext_html_url=https://joss.theoj.org/papers/10.21105/joss.02306;,citation_issue=51;,citation_doi=10.21105/joss.02306;,citation_issn=2475-9066;,citation_volume=5;,citation_journal_title=J. Open Source Softw.;,citation_publisher=The Open Journal;">
<meta name="citation_reference" content="citation_title=Skimr: Compact and flexible summaries of data;,citation_author=Elin Waring;,citation_author=Michael Quinn;,citation_author=Amelia McNamara;,citation_author=Eduardo Arino de la Rubia;,citation_author=Hao Zhu;,citation_author=Shannon Ellis;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=skimr;">
<meta name="citation_reference" content="citation_title=Rio: A swiss-army knife for data file i/o;,citation_author=Chung-hong Chan;,citation_author=Thomas J. Leeper;,citation_author=Jason Becker;,citation_author=David Schoch;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://cran.r-project.org/package=rio;">
<meta name="citation_reference" content="citation_title=Performance: An R package for assessment, comparison and testing of statistical models;,citation_author=Daniel Lüdecke;,citation_author=Mattan Ben-Shachar;,citation_author=Indrajeet Patil;,citation_author=Philip Waggoner;,citation_author=Dominique Makowski;,citation_publication_date=2021-04;,citation_cover_date=2021-04;,citation_year=2021;,citation_fulltext_html_url=https://joss.theoj.org/papers/10.21105/joss.03139;,citation_issue=60;,citation_doi=10.21105/joss.03139;,citation_issn=2475-9066;,citation_volume=6;,citation_journal_title=J. Open Source Softw.;,citation_publisher=The Open Journal;">
<meta name="citation_reference" content="citation_title=Classification and regression by randomForest;,citation_author=Andy Liaw;,citation_author=Matthew Wiener;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://CRAN.R-project.org/doc/Rnews/;,citation_issue=3;,citation_volume=2;,citation_journal_title=R News;">
<meta name="citation_reference" content="citation_title=Building predictive models in r using the caret package;,citation_author=Kuhn;,citation_author=Max;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_fulltext_html_url=https://www.jstatsoft.org/index.php/jss/article/view/v028i05;,citation_issue=5;,citation_doi=10.18637/jss.v028.i05;,citation_volume=28;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Rsample: General resampling infrastructure;,citation_author=Hannah Frick;,citation_author=Fanny Chow;,citation_author=Max Kuhn;,citation_author=Michael Mahoney;,citation_author=Julia Silge;,citation_author=Hadley Wickham;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=rsample;">
<meta name="citation_reference" content="citation_title=Yardstick: Tidy characterizations of model performance;,citation_author=Max Kuhn;,citation_author=Davis Vaughan;,citation_author=Emil Hvitfeldt;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=yardstick;">
<meta name="citation_reference" content="citation_title=Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles.;,citation_author=Max Kuhn;,citation_author=Hadley Wickham;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://www.tidymodels.org;">
<meta name="citation_reference" content="citation_title=pROC: An open-source package for r and s+ to analyze and compare ROC curves;,citation_author=Xavier Robin;,citation_author=Natacha Turck;,citation_author=Alexandre Hainard;,citation_author=Natalia Tiberti;,citation_author=Frédérique Lisacek;,citation_author=Jean-Charles Sanchez;,citation_author=Markus Müller;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=BMC Bioinformatics;">
<meta name="citation_reference" content="citation_title=Xgboost: Extreme gradient boosting;,citation_author=Tianqi Chen;,citation_author=Tong He;,citation_author=Michael Benesty;,citation_author=Vadim Khotilovich;,citation_author=Yuan Tang;,citation_author=Hyunsu Cho;,citation_author=Kailong Chen;,citation_author=Rory Mitchell;,citation_author=Ignacio Cano;,citation_author=Tianyi Zhou;,citation_author=Mu Li;,citation_author=Junyuan Xie;,citation_author=Min Lin;,citation_author=Yifeng Geng;,citation_author=Yutian Li;,citation_author=Jiaming Yuan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=xgboost;">
<meta name="citation_reference" content="citation_title=Kernlab – an S4 package for kernel methods in R;,citation_author=Alexandros Karatzoglou;,citation_author=Alex Smola;,citation_author=Kurt Hornik;,citation_author=Achim Zeileis;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=9;,citation_doi=10.18637/jss.v011.i09;,citation_volume=11;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Kknn: Weighted k-nearest neighbors;,citation_author=Klaus Schliep;,citation_author=Klaus Hechenbichler;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=https://CRAN.R-project.org/package=kknn;">
<meta name="citation_reference" content="citation_title=Modern applied statistics with s;,citation_author=W. N. Venables;,citation_author=B. D. Ripley;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://www.stats.ox.ac.uk/pub/MASS4/;">
<meta name="citation_reference" content="citation_title=Rpart: Recursive partitioning and regression trees;,citation_author=Terry Therneau;,citation_author=Beth Atkinson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://CRAN.R-project.org/package=rpart;">
<meta name="citation_reference" content="citation_title=Naivebayes: High performance implementation of the naive bayes algorithm in r;,citation_author=Michal Majka;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=naivebayes;">
<meta name="citation_reference" content="citation_title=Modern applied statistics with s;,citation_author=W. N. Venables;,citation_author=B. D. Ripley;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_fulltext_html_url=https://www.stats.ox.ac.uk/pub/MASS4/;">
<meta name="citation_reference" content="citation_title=Earth: Multivariate adaptive regression splines;,citation_author=Stephen Milborrow. Derived Trevor Hastie;,citation_author=Rob Tibshirani. Uses Alan Miller’s Fortran Thomas Lumley’s leaps wrapper.;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=earth;">
<meta name="citation_reference" content="citation_title=Dbarts: Discrete bayesian additive regression trees sampler;,citation_author=Vincent Dorie;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=dbarts;">
<meta name="citation_reference" content="citation_title=ranger: A fast implementation of random forests for high dimensional data in C++ and R;,citation_author=Marvin N. Wright;,citation_author=Andreas Ziegler;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_doi=10.18637/jss.v077.i01;,citation_volume=77;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Gbm: Generalized boosted regression models;,citation_author=Greg Ridgeway;,citation_author=GBM Developers;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=gbm;">
<meta name="citation_reference" content="citation_title=e1071: Misc functions of the department of statistics, probability theory group (formerly: E1071), TU wien;,citation_author=David Meyer;,citation_author=Evgenia Dimitriadou;,citation_author=Kurt Hornik;,citation_author=Andreas Weingessel;,citation_author=Friedrich Leisch;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://CRAN.R-project.org/package=e1071;">
<meta name="citation_reference" content="citation_title=Earliest possible global and local interpretation of students’ performance in virtual learning environment by leveraging explainable AI;,citation_author=Muhammad Adnan;,citation_author=M. Irfan Uddin;,citation_author=Emel Khan;,citation_author=Fahd S. Alharithi;,citation_author=Samina Amin;,citation_author=Ahmad A. Alzahrani;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issn=2169-3536;,citation_volume=10;,citation_journal_title=IEEE Access;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Practical early prediction of students’ performance using machine learning and eXplainable AI;,citation_author=Yeonju Jang;,citation_author=Seongyune Choi;,citation_author=Heeseok Jung;,citation_author=Hyeoncheol Kim;,citation_publication_date=2022-11;,citation_cover_date=2022-11;,citation_year=2022;,citation_issue=9;,citation_issn=1360-2357;,citation_volume=27;,citation_journal_title=Education and information technologies;,citation_publisher=Springer Science; Business Media LLC;">
<meta name="citation_reference" content="citation_title=Explainable artificial intelligence in education;,citation_author=Hassan Khosravi;,citation_author=Simon Buckingham Shum;,citation_author=Guanliang Chen;,citation_author=Cristina Conati;,citation_author=Yi-Shan Tsai;,citation_author=Judy Kay;,citation_author=Simon Knight;,citation_author=Roberto Martinez-Maldonado;,citation_author=Shazia Sadiq;,citation_author=Dragan Gašević;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issn=2666-920X;,citation_volume=3;,citation_journal_title=Computers and Education: Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Learner-centred analytics of feedback content in higher education;,citation_author=Jionghao Lin;,citation_author=Wei Dai;,citation_author=Lisa-Angelique Lim;,citation_author=Yi-Shan Tsai;,citation_author=Rafael Ferreira Mello;,citation_author=Hassan Khosravi;,citation_author=Dragan Gasevic;,citation_author=Guanliang Chen;,citation_publication_date=2023-03;,citation_cover_date=2023-03;,citation_year=2023;,citation_isbn=9781450398657;,citation_conference_title=LAK23: 13th international learning analytics and knowledge conference;,citation_conference=Association for Computing Machinery;,citation_series_title=LAK2023;">
<meta name="citation_reference" content="citation_title=Early detection of dropout factors in vocational education: A large-scale case study from finland;,citation_author=Sonsoles López-Pernas;,citation_author=Riina Kleimola;,citation_author=Sanna Väisänen;,citation_author=Laura Hirsto;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the 1st finnish learning analytics and artificial intelligence in education conference (FLAIEC22);">
<meta name="citation_reference" content="citation_title=Interpretable dropout prediction: Towards XAI-based personalized intervention;,citation_author=Marcell Nagy;,citation_author=Roland Molontay;,citation_publication_date=2023-03;,citation_cover_date=2023-03;,citation_year=2023;,citation_fulltext_html_url=https://doi.org/10.1007/s40593-023-00331-8;,citation_doi=10.1007/s40593-023-00331-8;,citation_issn=1560-4306;,citation_journal_title=International Journal of Artificial Intelligence in Education;">
<meta name="citation_reference" content="citation_title=Generalized mixed‐effects random forest: A flexible approach to predict university student dropout;,citation_author=Massimo Pellagatti;,citation_author=Chiara Masci;,citation_author=Francesca Ieva;,citation_author=Anna M. Paganoni;,citation_publication_date=2021-06;,citation_cover_date=2021-06;,citation_year=2021;,citation_issue=3;,citation_issn=1932-1872;,citation_volume=14;,citation_journal_title=Statistical analysis and data mining;,citation_publisher=Wiley;">
<meta name="citation_reference" content="citation_title=Explainable learning analytics: Assessing the stability of student success prediction models by means of explainable AI;,citation_author=Elena Tiukhova;,citation_author=Pavani Vemuri;,citation_author=Nidia López Flores;,citation_author=Anna Sigridur Islind;,citation_author=María Óskarsdóttir;,citation_author=Stephan Poelmans;,citation_author=Bart Baesens;,citation_author=Monique Snoeck;,citation_publication_date=2024-07;,citation_cover_date=2024-07;,citation_year=2024;,citation_issue=114229;,citation_issn=0167-9236;,citation_volume=182;,citation_journal_title=Decision support systems;,citation_publisher=Elsevier BV;">
<meta name="citation_reference" content="citation_title=Why explainable AI may not be enough: Predictions and mispredictions in decision making in education;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1186/s40561-024-00343-4;,citation_issue=in-press;,citation_doi=10.1186/s40561-024-00343-4;,citation_issn=2196-7091;,citation_journal_title=Smart Learn. Environ.;">
<meta name="citation_reference" content="citation_title=Prospects in the field of learning and individual differences: Examining the past to forecast the future using bibliometrics;,citation_abstract=Over two centuries, research has delved into individual differences in learning across educational and professional contexts. This commentary conducts a bibliometric analysis of 6556 articles, identifying key research keywords, topics and themes, and their historical evolution. The findings revealed a longstanding emphasis on educational psychology, particularly motivation and achievement, rather than cross-curricular competencies and learner’s well-being and socio-economic background. Notably, self-regulated learning (SRL) emerged as an overarching research subject in terms of motivation and achievement, but, surprisingly, not (meta)cognition. Prospects for the field build on cross-disciplinary research, theoretical refinement, and methodological advances. Further, the field is expected to maintain academic rigor, address diversity among learners, foster global collaboration, and focus on underprivileged populations.;,citation_author=Katarzyna Bobrowicz;,citation_author=Sonsoles López-Pernas;,citation_author=Ziwen Teuber;,citation_author=Mohammed Saqr;,citation_author=Samuel Greiff;,citation_publication_date=2024-01;,citation_cover_date=2024-01;,citation_year=2024;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S1041608023001437;,citation_doi=10.1016/j.lindif.2023.102399;,citation_issn=1041-6080;,citation_volume=109;,citation_journal_title=Learn. Individ. Differ.;">
<meta name="citation_reference" content="citation_title=The 2011 horizon report;,citation_abstract=The internationally recognized series of;,citation_author=L Johnson;,citation_author=R Smith;,citation_author=H Willis;,citation_author=A Levine;,citation_author=K Haywood;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=http://files.eric.ed.gov/fulltext/ED515956.pdf;,citation_isbn=9780982829059;,citation_inbook_title=New media consortium;">
<meta name="citation_reference" content="citation_title=Explanatory model analysis: Explore, explain, and examine predictive models;,citation_abstract=Explanatory Model Analysis Explore, Explain and Examine Predictive Models is a set of methods and tools designed to build better predictive models and to monitor their behaviour in a changing environment. Today, the true bottleneck in predictive modelling is neither the lack of data, nor the lack of computational power, nor inadequate algorithms, nor the lack of flexible models. It is the lack of tools for model exploration (extraction of relationships learned by the model), model explanation (u;,citation_author=Przemyslaw Biecek;,citation_author=Tomasz Burzykowski;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_fulltext_html_url=https://www.routledge.com/Explanatory-Model-Analysis-Explore-Explain-and-Examine-Predictive-Models/Biecek-Burzykowski/p/book/9780367693923;,citation_isbn=9780367693923;,citation_series_title=Chapman &amp;amp;amp; hall/CRC data science series;">
<meta name="citation_reference" content="citation_title=17. A value for n-person games;,citation_abstract=17. A Value for n-Person Games was published in Contributions to the Theory of Games, Volume II on page 307.;,citation_author=L S Shapley;,citation_editor=Harold William Kuhn;,citation_editor=Albert William Tucker;,citation_publication_date=1953-12;,citation_cover_date=1953-12;,citation_year=1953;,citation_fulltext_html_url=https://www.degruyter.com/document/doi/10.1515/9781400881970-018/html?srsltid=AfmBOorG_5LaIyv5mGEqzs3IceyrU2CT3X910-__bMT6ZxIMydFWmZls;,citation_doi=10.1515/9781400881970-018;,citation_isbn=9781400881970;,citation_inbook_title=Contributions to the theory of games (AM-28), volume II;">
<meta name="citation_reference" content="citation_title=Why should I trust you?: Explaining the predictions of any classifier;,citation_author=Marco Tulio Ribeiro;,citation_author=Sameer Singh;,citation_author=Carlos Guestrin;,citation_publication_date=2016-08;,citation_cover_date=2016-08;,citation_year=2016;,citation_fulltext_html_url=https://dl.acm.org/doi/10.1145/2939672.2939778;,citation_doi=10.1145/2939672.2939778;,citation_isbn=9781450342322;,citation_conference_title=Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=DALEX: Explainers for complex predictive models in r;,citation_author=Przemyslaw Biecek;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://jmlr.org/papers/v19/18-416.html;,citation_issue=84;,citation_volume=19;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Parsnip: A common API to modeling and analysis functions;,citation_author=Max Kuhn;,citation_author=Davis Vaughan;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=parsnip;">
<meta name="citation_reference" content="citation_title=Recipes: Preprocessing and feature engineering steps for modeling;,citation_author=Max Kuhn;,citation_author=Hadley Wickham;,citation_author=Emil Hvitfeldt;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://CRAN.R-project.org/package=recipes;">
<meta name="citation_reference" content="citation_title=Unpacking learning in the age of AI: Bridging AI, complexity, and precision education;,citation_author=Sonsoles López-Pernas;,citation_author=Ahmed Tlili;,citation_author=Rwitajit Majumdar;,citation_author=Sami Heikkinen;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=AI, explainable AI and evaluative AI: An introduction to informed data-driven decision-making in education;,citation_author=Sonsoles López-Pernas;,citation_author=Eduardo Oliveira;,citation_author=Yige Song;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Artificial intelligence: Using machine learning to predict students’ performance;,citation_author=Mohammed Saqr;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Artificial intelligence: Using machine learning to classify students and predict low achievers;,citation_author=Mohammed Saqr;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Comparative analysis of regularization methods for predicting student certification in online courses;,citation_author=Tian Li;,citation_author=Feifei Han;,citation_author=Jiesi Guo;,citation_author=Jinran Wu;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Explainable artificial intelligence in education: A tutorial for identifying the variables that matter;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Individualized explainable artificial intelligence: A tutorial for identifying local and individual predictions;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=An introduction to large language models in education;,citation_author=Eduardo Oliveira;,citation_author=Yige Song;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The use of natural language processing in learning analytics;,citation_author=Tarid Wongvorachan;,citation_author=Okan Bulut;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Using language models for automated discourse coding: A primer and tutorial;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=LLMs for explainable artificial intelligence: Automating natural language explanations of predictive analytics models;,citation_author=Sonsoles López-Pernas;,citation_author=Yige Song;,citation_author=Eduardo Oliveira;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Complex dynamic systems in education: Beyond the static, the linear and the causal reductionism;,citation_author=Mohammed Saqr;,citation_author=Daryn Dever;,citation_author=Sonsoles López-Pernas;,citation_author=Christophe Gernigon;,citation_author=Gwen Marchand;,citation_author=Avi Kaplan;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The advanced applications of psychological networks with EGA;,citation_author=Tarid Wongvorachan;,citation_author=Okan Bulut;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Detecting nonlinear patterns in education research: A tutorial on recurrence quantification analysis;,citation_author=Daryn Dever;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Mapping relational dynamics with transition network analysis: A primer and tutorial;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Capturing the breadth and dynamics of the temporal processes with frequency transition network analysis: A primer and tutorial;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Mining patterns and clusters with transition network analysis: A heterogeneity approach;,citation_author=Sonsoles López-Pernas;,citation_author=Santtu Tikka;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=A comprehensive introduction to idiographic and within-person analytics;,citation_author=Mohammed Saqr;,citation_author=Hibiki Ito;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=The three levels of analysis: Variable-centered, person-centered and person-specific analysis in education;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Idiographic networks: A tutorial on graphical vector autoregression and unified structural equation modeling;,citation_author=Mohammed Saqr;,citation_author=Daryn Dever;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Detecting long-memory psychological processes in academic settings using whittle’s maximum likelihood estimator: An application with r;,citation_author=Rémi Altamore;,citation_author=Clément Roume;,citation_author=Anne Teboul;,citation_author=Christophe Gernigon;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Automating individualized machine learning and AI prediction using AutoML: The case of idiographic predictions;,citation_author=Mohammed Saqr;,citation_author=Ahmed Tlili;,citation_author=Sonsoles López-Pernas;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_inbook_title=Advanced learning analytics methods: AI, precision and complexity;">
<meta name="citation_reference" content="citation_title=Getting started with R for education research;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Introductory statistics with R for educational researchers;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=An R approach to data cleaning and wrangling for education research;,citation_author=Juho Kopra;,citation_author=Santtu Tikka;,citation_author=Merja Heinäniemi;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_editor=Mohammed Saqr;,citation_editor=Sonsoles López-Pernas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=Learning analytics methods and tutorials: A practical guide using r;">
<meta name="citation_reference" content="citation_title=Visualizing and reporting educational data with R;,citation_abstract=AbstractVisualizing data is central in learning analytics research, underpins learning dashboards, and is a prime method for reporting results and insights to stakeholders. In this chapter, the reader will be guided through the process of generating meaningful and aesthetically pleasing visualizations of different types of student data using well-known R packages. The main visualization types will be demonstrated with an explanation of their usage and use cases. Furthermore, learning-related examples will be discussed in detail. For instance, readers will learn how to visualize learners’ logs extracted from learning management systems to show how trace data can be used to track students’ learning activities. In addition to creating compelling plots, readers will also be able to generate professional-looking tables with summary statistics.;,citation_author=Sonsoles López-Pernas;,citation_author=Kamila Misiejuk;,citation_author=Santtu Tikka;,citation_author=Juho Kopra;,citation_author=Merja Heinäniemi;,citation_author=Mohammed Saqr;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://link.springer.com/chapter/10.1007/978-3-031-54464-4_6;,citation_doi=10.1007/978-3-031-54464-4\_6;,citation_isbn=9783031544637,9783031544644;,citation_inbook_title=Learning analytics methods and tutorials;">
<meta name="citation_reference" content="citation_title=Is there order in the mess? A single paper meta-analysis approach to identification of predictors of success in learning analytics;,citation_author=Mohammed Saqr;,citation_author=Jelena Jovanovic;,citation_author=Olga Viberg;,citation_author=Dragan Gašević;,citation_publication_date=2022-04-11;,citation_cover_date=2022-04-11;,citation_year=2022;,citation_fulltext_html_url=http://dx.doi.org/10.1080/03075079.2022.2061450;,citation_issue=12;,citation_doi=10.1080/03075079.2022.2061450;,citation_volume=47;,citation_language=en;,citation_journal_title=Studies in Higher Education;">
<meta name="citation_reference" content="citation_title=High resolution temporal network analysis to understand and improve collaborative learning;,citation_author=Mohammed Saqr;,citation_author=Jalal Nouri;,citation_publication_date=2020-03-23;,citation_cover_date=2020-03-23;,citation_year=2020;,citation_fulltext_html_url=http://dx.doi.org/10.1145/3375462.3375501;,citation_doi=10.1145/3375462.3375501;,citation_journal_title=Proceedings of the Tenth International Conference on Learning Analytics &amp;amp;amp; Knowledge;">
<meta name="citation_reference" content="citation_title=Big data and the emerging ethical challenges;,citation_author=Mohammed Saqr;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=4;,citation_volume=11;,citation_journal_title=International journal of health sciences;,citation_publisher=Qassim University;">
<meta name="citation_reference" content="citation_title=Predicting student performance from LMS data: A comparison of 17 blended courses using moodle LMS;,citation_author=Rianne Conijn;,citation_author=Chris Snijders;,citation_author=Ad Kleingeld;,citation_author=Uwe Matzat;,citation_publication_date=2017-01-01;,citation_cover_date=2017-01-01;,citation_year=2017;,citation_fulltext_html_url=http://dx.doi.org/10.1109/tlt.2016.2616312;,citation_issue=1;,citation_doi=10.1109/tlt.2016.2616312;,citation_volume=10;,citation_journal_title=IEEE Transactions on Learning Technologies;">
<meta name="citation_reference" content="citation_title=A systematic review of literature reviews on artificial intelligence in education (AIED): a roadmap to a future research agenda;,citation_author=Muhammad Yasir Mustafa;,citation_author=Ahmed Tlili;,citation_author=Georgios Lampropoulos;,citation_author=Ronghuai Huang;,citation_author=Petar Jandrić;,citation_author=Jialu Zhao;,citation_author=Soheil Salha;,citation_author=Lin Xu;,citation_author=Santosh Panda;,citation_author=undefined Kinshuk;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammed Saqr;,citation_publication_date=2024-12-09;,citation_cover_date=2024-12-09;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1186/s40561-024-00350-5;,citation_issue=1;,citation_doi=10.1186/s40561-024-00350-5;,citation_volume=11;,citation_language=en;,citation_journal_title=Smart Learning Environments;">
<meta name="citation_reference" content="citation_title=Idiographic artificial intelligence to explain students’ self-regulation: Toward precision education;,citation_author=Mohammed Saqr;,citation_author=Rongxin Cheng;,citation_author=Sonsoles López-Pernas;,citation_author=Emorie D Beck;,citation_publication_date=2024-08;,citation_cover_date=2024-08;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.lindif.2024.102499;,citation_doi=10.1016/j.lindif.2024.102499;,citation_volume=114;,citation_language=en;,citation_journal_title=Learning and Individual Differences;">
<meta name="citation_reference" content="citation_title=Have learning analytics dashboards lived up to the hype? A systematic review of impact on students’ achievement, motivation, participation and attitude;,citation_author=Rogers Kaliisa;,citation_author=Kamila Misiejuk;,citation_author=Sonsoles López-Pernas;,citation_author=Mohammad Khalil;,citation_author=Mohammed Saqr;,citation_publication_date=2024-03-18;,citation_cover_date=2024-03-18;,citation_year=2024;,citation_fulltext_html_url=http://dx.doi.org/10.1145/3636555.3636884;,citation_doi=10.1145/3636555.3636884;,citation_journal_title=Proceedings of the 14th Learning Analytics and Knowledge Conference;">
<meta name="citation_reference" content="citation_title=How social network analysis can be used to monitor online collaborative learning and guide an informed intervention;,citation_author=Mohammed Saqr;,citation_author=Uno Fors;,citation_author=Matti Tedre;,citation_author=Jalal Nouri;,citation_editor=Petter Holme;,citation_publication_date=2018-03-22;,citation_cover_date=2018-03-22;,citation_year=2018;,citation_fulltext_html_url=http://dx.doi.org/10.1371/journal.pone.0194777;,citation_issue=3;,citation_doi=10.1371/journal.pone.0194777;,citation_volume=13;,citation_language=en;,citation_journal_title=PLOS ONE;">
<meta name="citation_reference" content="citation_title=The longitudinal trajectories of online engagement over a full program;,citation_author=Mohammed Saqr;,citation_author=Sonsoles López-Pernas;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_fulltext_html_url=http://dx.doi.org/10.1016/j.compedu.2021.104325;,citation_doi=10.1016/j.compedu.2021.104325;,citation_volume=175;,citation_language=en;,citation_journal_title=Computers &amp;amp;amp; Education;">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">LA Methods</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../book1/index.html">
 <span class="menu-text">Learning Analytics Methods and Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../book2/index.html">
 <span class="menu-text">Advanced Learning Analytics Methods</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/lamethods/code2/"><i class="bi bi-github" role="img" aria-label="Source Code">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Artificial Intelligence: Using Machine Learning to Predict Students’ Performance</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contributors.html" class="sidebar-item-text sidebar-link">Contributors</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch01-intro/ch01-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Artificial Intelligence</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch02-AIxAI/ch02-aixai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI and XAI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch03-prediction/ch03-prediction.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Prediction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch04-classification/ch04-classification.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch05-regularization/ch05-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regularization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch06-xai-global/ch06-xai-global.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Global XAI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch07-xai-local/ch07-xai-local.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Local XAI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Large Language Models</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch08-llms/ch08-llms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Large Language Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch09-nlp/ch09-nlp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Natural Language Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch10-bert/ch10-bert.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Classification with BERT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch11-llmsxai/ch11-llmsxai.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Automated feedback with XAI and LLMs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Complex Systems</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch12-cds/ch12-cds.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Complex Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch13-ega/ch13-ega.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Exploratory Graph Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch14-rqa/ch14-rqa.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Recurrent Quantification Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch15-tna/ch15-tna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Transition Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch16-ftna/ch16-ftna.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Frequency-based Transition Network Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch17-tna-clusters/ch17-tna-clusters.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Transition Network Analysis Clusters</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Idiographic</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch18-idio/ch18-idio.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Within-person analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch19-three-levels/ch19-three-levels.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Heterogeneity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch20-var/ch20-var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Vector Autoregression and uSEM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch21-mle/ch21-mle.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/ch22-automl/ch22-automl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Automated Machine Learning</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="toc-section-number">1</span>  Introduction</a></li>
  <li><a href="#previous-research-on-student-performance-prediction" id="toc-previous-research-on-student-performance-prediction" class="nav-link" data-scroll-target="#previous-research-on-student-performance-prediction"><span class="toc-section-number">2</span>  Previous research on student performance prediction</a></li>
  <li><a href="#performance-prediction-with-r" id="toc-performance-prediction-with-r" class="nav-link" data-scroll-target="#performance-prediction-with-r"><span class="toc-section-number">3</span>  Performance prediction with R</a>
  <ul class="collapse">
  <li><a href="#the-dataset-used-in-this-chapter" id="toc-the-dataset-used-in-this-chapter" class="nav-link" data-scroll-target="#the-dataset-used-in-this-chapter"><span class="toc-section-number">3.1</span>  The dataset used in this chapter</a></li>
  </ul></li>
  <li><a href="#tutorial-1-a-classic-approach-to-predictive-modeling" id="toc-tutorial-1-a-classic-approach-to-predictive-modeling" class="nav-link" data-scroll-target="#tutorial-1-a-classic-approach-to-predictive-modeling"><span class="toc-section-number">4</span>  Tutorial 1: A Classic Approach to Predictive Modeling</a>
  <ul class="collapse">
  <li><a href="#loading-the-necessary-libraries" id="toc-loading-the-necessary-libraries" class="nav-link" data-scroll-target="#loading-the-necessary-libraries"><span class="toc-section-number">4.1</span>  Loading the necessary libraries</a></li>
  <li><a href="#splitting-the-dataset" id="toc-splitting-the-dataset" class="nav-link" data-scroll-target="#splitting-the-dataset"><span class="toc-section-number">4.2</span>  Splitting the dataset</a></li>
  <li><a href="#creating-and-fitting-the-model" id="toc-creating-and-fitting-the-model" class="nav-link" data-scroll-target="#creating-and-fitting-the-model"><span class="toc-section-number">4.3</span>  Creating and fitting the model</a></li>
  <li><a href="#evaluating-the-models-performance" id="toc-evaluating-the-models-performance" class="nav-link" data-scroll-target="#evaluating-the-models-performance"><span class="toc-section-number">4.4</span>  Evaluating the model’s performance</a></li>
  <li><a href="#other-algorithms" id="toc-other-algorithms" class="nav-link" data-scroll-target="#other-algorithms"><span class="toc-section-number">4.5</span>  Other algorithms</a></li>
  </ul></li>
  <li><a href="#tutorial-2-a-modern-approach-to-predictive-modelling-using-tidymodels" id="toc-tutorial-2-a-modern-approach-to-predictive-modelling-using-tidymodels" class="nav-link" data-scroll-target="#tutorial-2-a-modern-approach-to-predictive-modelling-using-tidymodels"><span class="toc-section-number">5</span>  Tutorial 2: A Modern Approach to Predictive Modelling using <code>tidymodels</code></a>
  <ul class="collapse">
  <li><a href="#load-the-necessary-libraries" id="toc-load-the-necessary-libraries" class="nav-link" data-scroll-target="#load-the-necessary-libraries"><span class="toc-section-number">5.1</span>  Load the necessary libraries</a></li>
  <li><a href="#select-the-predictor-and-target-variables" id="toc-select-the-predictor-and-target-variables" class="nav-link" data-scroll-target="#select-the-predictor-and-target-variables"><span class="toc-section-number">5.2</span>  Select the predictor and target variables</a></li>
  <li><a href="#define-the-random-forest-model-specification" id="toc-define-the-random-forest-model-specification" class="nav-link" data-scroll-target="#define-the-random-forest-model-specification"><span class="toc-section-number">5.3</span>  Define the Random Forest Model Specification</a></li>
  <li><a href="#multiple-algorithms" id="toc-multiple-algorithms" class="nav-link" data-scroll-target="#multiple-algorithms"><span class="toc-section-number">5.4</span>  Multiple algorithms</a></li>
  </ul></li>
  <li><a href="#discussion-and-conclusions" id="toc-discussion-and-conclusions" class="nav-link" data-scroll-target="#discussion-and-conclusions"><span class="toc-section-number">6</span>  Discussion and conclusions</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">References</a></li>
  </ul>
</nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<a href="https://github.com/lamethods/code2" target="_blank"> <button class="btn btn-outline-dark"> <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 496 512" style="width: 22px;vertical-align: text-top;margin-right: 9px;"> <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" style="width: 24px;"> </path> </svg>Download code </button> </a>
<div style="padding: 10px;">
Check out our previous book! <br> <a href="../../../book1/index.html"><img src="../../../book1/1712067211600.jpeg" style="
     width: 70%;
 "></a>
</div>
<p><br> <small>© 2025 The authors</small></p>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Artificial Intelligence: Using Machine Learning to Predict Students’ Performance</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Mohammed Saqr </p>
             <p>Kamila Misiejuk </p>
             <p>Santtu Tikka </p>
             <p>Sonsoles López-Pernas </p>
          </div>
  </div>
    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    Being able to predict students’ performance has been a primary driver for the adoption of learning analytics and has attracted many scientists to the field. Predictive modeling focuses on using students’ data to forecast outcomes such as student grades, enabling teachers and administrators to offer just-in-time support to students at risk. This chapter uses advanced predictive methods, namely machine learning, where the goal is to predict continuous variables like grades. The chapter uses advanced and popular AI/machine learning algorithms like Random Forest, K-Nearest Neighbor, Linear Regression, Neural Networks, and Support Vector Machines. The chapter provides a practical guide to building and evaluating predictive models with R using two approaches: one is the classic approach for predictive modeling with R, and the other more modern approach using the <code>tidymodels</code> suite.
  </div>
</div>

</header>

<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction</h2>
<p>Predicting student performance is one of the most common tasks in learning analytics <span class="citation" data-cites="LABOOK2_Chapter_2">[<a href="#ref-LABOOK2_Chapter_2" role="doc-biblioref">1</a>]</span>. Typically, student grades are used as an outcome variable of such modeling. Predicting a continuous variable like grades is called a regression problem, in contrast with classification that deals with nominal outcomes such as high and low achievers <span class="citation" data-cites="LABOOK2_Chapter_4">[<a href="#ref-LABOOK2_Chapter_4" role="doc-biblioref">2</a>]</span>. When we do predictive modeling, we assume that historical data can be used to build a model to predict the future using new data. In doing so, prediction goes beyond reporting what has happened but attempts to explain why an event happened, monitor what is currently happening and also attempts to foresee future developments <span class="citation" data-cites="eckerson2007predictive">[<a href="#ref-eckerson2007predictive" role="doc-biblioref">3</a>]</span>. As such, it provides a basis for actionable insights based on data or what we call data-informed decision making. This is particularly relevant for scaling up learning analytics applications. As such prediction has become a core step within the learning analytics process that aims to improve teaching or learning <span class="citation" data-cites="pardo2014designing">[<a href="#ref-pardo2014designing" role="doc-biblioref">4</a>]</span>.</p>
<p>There are six main steps in predictive analytics <span class="citation" data-cites="brooks2017predictive">[<a href="#ref-brooks2017predictive" role="doc-biblioref">5</a>]</span>. First, the problem needs to be specified (e.g., improving student performance). Second, an outcome variable is defined (e.g., student grades), and data that can potentially predict the outcome variable is collected. Several types of data can be collected: prior academic data (e.g., student admission information), demographic data (e.g., student’s socio-economic status), academic data (e.g., results of formative assessment), behavioral data (e.g., student log data), and psychological data (e.g., a survey on student motivation) <span class="citation" data-cites="sghir2023recent">[<a href="#ref-sghir2023recent" role="doc-biblioref">6</a>]</span>. Third, raw data needs to be pre-processed to become suitable for modeling. This can include formatting the data or deriving features from raw data (e.g., calculating time spent in an online system by subtracting log-out time from log-in time) (see <span class="citation" data-cites="kopra2024r">[<a href="#ref-kopra2024r" role="doc-biblioref">7</a>]</span> for more details on data cleaning and wrangling). In order to choose the appropriate predictors for the predictive model, an exploratory analysis is conducted (see <span class="citation" data-cites="tikka2024introductory">[<a href="#ref-tikka2024introductory" role="doc-biblioref">8</a>]</span> for a tutorial in exploratory methods). Once the relevant indicators are selected, a predictive model can be built using one or more algorithms. The selection of an appropriate algorithm is determined by “the problem type, the nature of the outcome to be predicted, and the variables employed in the prediction” <span class="citation" data-cites="sghir2023recent">[<a href="#ref-sghir2023recent" role="doc-biblioref">6</a>]</span>. Typically, several algorithms would be compared to choose the method that models the data most accurately. The results from a predictive analysis can be used to develop preventive measures and interventions. Depending on the timing of the analysis, these interventions can be implemented on the current cohort of students, or the insights from the analytics can be used to shape future teaching and learning. Finally, it is important to build explainable prediction models —i.e., that provide an explanation for how a prediction was calculated— in order to increase the trust of the stakeholders in the model and increase awareness of what the model is actually predicting. In addition, explainable models can help validate model accuracy <span class="citation" data-cites="dabhade2021educational">[<a href="#ref-dabhade2021educational" role="doc-biblioref">9</a>]</span>. An example of an explainable predictive model is <span class="citation" data-cites="pardo2016generating">[<a href="#ref-pardo2016generating" role="doc-biblioref">10</a>]</span>, who used data from formative assessment activities (e.g., the number of correct or incorrect answers to a question) to generate two predictions: of a grade in the midterm exam (on a scale of 0–20) and of a final grade (on a scale 0–40). The predictive model used the decision tree (DT) algorithm that supports the instructor’s sense-making and helps identify student groups in need of additional support.</p>
<p>The goal of this chapter is to explore advanced techniques of predictive analytics to model regression problems (see <span class="citation" data-cites="jovanovic2024predictive">[<a href="#ref-jovanovic2024predictive" role="doc-biblioref">11</a>]</span> for an introductory tutorial in predictive analytics). It is assumed that the reader is familiar with the R programming language. If that is not the case, it is recommended to refer to previous tutorials on the basics of R <span class="citation" data-cites="Tikka2024-ph">[<a href="#ref-Tikka2024-ph" role="doc-biblioref">12</a>]</span>, data cleaning <span class="citation" data-cites="Kopra2024-fx">[<a href="#ref-Kopra2024-fx" role="doc-biblioref">13</a>]</span>, basic statistics <span class="citation" data-cites="Tikka2024-wl">[<a href="#ref-Tikka2024-wl" role="doc-biblioref">14</a>]</span>, and visualization <span class="citation" data-cites="Lopez-Pernas2024-ge">[<a href="#ref-Lopez-Pernas2024-ge" role="doc-biblioref">15</a>]</span>. The following section presents an overview of learning analytics research concerned with regression. Next, a synthetic dataset used in this tutorial is presented based on data of this study <span class="citation" data-cites="saqr2022">[<a href="#ref-saqr2022" role="doc-biblioref">16</a>]</span>. The tutorial section starts with an exploratory data analysis, including visualizing variable distribution and calculating correlations. It is followed by a description of the steps needed to create a predictive model. This tutorial explores the following predictive methods: Random Forest (RF), K-Nearest Neighbor (KNN), Linear Regression (LR), Neural Networks (NN), and Support Vector Machine (SVM). In addition, techniques to determine predictive model performance, such as Mean Absolute Error (MAE), Root-mean-square deviation (RMSE), and R-squared (RSQ), are presented and explained. The final part of this chapter shows how to create workflows to use multiple predictive algorithms.</p>
</section>
<section id="previous-research-on-student-performance-prediction" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="previous-research-on-student-performance-prediction"><span class="header-section-number">2</span> Previous research on student performance prediction</h2>
<p><span class="citation" data-cites="tomasevic2020overview">[<a href="#ref-tomasevic2020overview" role="doc-biblioref">17</a>]</span> described three categories of regression techniques: 1) similarity-based approaches that are built upon identifying similar patterns in a dataset (e.g., KNN), 2) model-based approaches are developed by estimating implicit correlation among data samples and predictors (e.g., SVM, NN, DT, LR), 3) probabilistic approaches focus on examining probability distributions in the input dataset (e.g., Bayesian LR). Regression is the most commonly applied method in predictive analysis, while predicting student performance is one of the main regression problems prevalent in learning analytics research <span class="citation" data-cites="du2021systematic">[<a href="#ref-du2021systematic" role="doc-biblioref">18</a>]</span>. The vast majority of learning analytics papers focus on predicting student final grades <span class="citation" data-cites="du2021systematic">[<a href="#ref-du2021systematic" role="doc-biblioref">18</a>]</span>. Predictions in learning analytics are conducted in two main ways: 1) formative prediction examines student features at several points in the duration of the learning activity to provide several predictions over time, and 2) summative prediction aggregates data from the whole learning activity to predict the final outcome <span class="citation" data-cites="namoun2020predicting saqr2017learning Saqr2024-ie">[<a href="#ref-namoun2020predicting" role="doc-biblioref">19</a>–<a href="#ref-Saqr2024-ie" role="doc-biblioref">21</a>]</span>. In addition, different levels of learning activity can be specified, e.g., degree, year, course, or exam level <span class="citation" data-cites="alyahyan2020predicting">[<a href="#ref-alyahyan2020predicting" role="doc-biblioref">22</a>]</span>. Log activity data is typically combined with other data sources, such as demographic or self-reported data <span class="citation" data-cites="du2021systematic">[<a href="#ref-du2021systematic" role="doc-biblioref">18</a>]</span>. Current evidence suggests that engagement level expressed through participation frequencies has a positive effect on performance <span class="citation" data-cites="du2021systematic">[<a href="#ref-du2021systematic" role="doc-biblioref">18</a>]</span>. Prior academic data, such as grades achieved in previous courses, was found to be the most influential factor in predicting student performance. An interesting meta-analytics study conducted by <span class="citation" data-cites="saqr2022">[<a href="#ref-saqr2022" role="doc-biblioref">16</a>]</span> to examine the reliability of predictors across courses found that overall engagement with online tasks and collaborative learning activities (measured by total activity and forum indicators) showed the highest prediction ranges, indicating their reliability as metrics. Lecture reading frequency had insignificant prediction ranges, suggesting limited applicability across courses.</p>
<p>Predictive modeling can be challenging sometimes, specially when using low quality data for analysis or having a shallow understanding of the nature of the data and therefore can lead to untrustworthy findings. As learning processes are dynamic, using results from historical data to model current learners can be inaccurate and lead to the over-fitting or under-fitting of statistical models <span class="citation" data-cites="mathrani2021perspectives">[<a href="#ref-mathrani2021perspectives" role="doc-biblioref">23</a>]</span>. These issues can be mitigated by applying methods such as cross-validation or bootstrapping <span class="citation" data-cites="pardo2014designing mathrani2021perspectives winne2020construct">[<a href="#ref-pardo2014designing" role="doc-biblioref">4</a>, <a href="#ref-mathrani2021perspectives" role="doc-biblioref">23</a>, <a href="#ref-winne2020construct" role="doc-biblioref">24</a>]</span>. Another problem in predictive analytics is imbalanced datasets, where specific important values are not sufficiently represented in a dataset. This issue can be mitigated by over- or undersampling (for more details, see <span class="citation" data-cites="avelino2024resampling">[<a href="#ref-avelino2024resampling" role="doc-biblioref">25</a>]</span>). In addition, it is crucial to approach the findings from a point-in-time perspective that takes into consideration the temporality aspect of the findings’ accuracy <span class="citation" data-cites="winne2020construct saqr2020">[<a href="#ref-winne2020construct" role="doc-biblioref">24</a>, <a href="#ref-saqr2020" role="doc-biblioref">26</a>]</span>. Also, it is important to consider the ethical implications of implementing predictive learning analytics so as not to cause harm to students or contribute to perpetuating social injustices <span class="citation" data-cites="rets2023six saqr2017big">[<a href="#ref-rets2023six" role="doc-biblioref">27</a>, <a href="#ref-saqr2017big" role="doc-biblioref">28</a>]</span>. <span class="citation" data-cites="tomasevic2020overview">[<a href="#ref-tomasevic2020overview" role="doc-biblioref">17</a>]</span> identified three main issues with implementing predictive learning analytics. First, the issue of a cold start relates to the lack of data at the early stages of learning analytics deployment. This challenge can be mitigated by including demographic data or previous academic data. Second, the issue of scalability is connected to the increasing number of students, the complexity of algorithms used, and the computational requirements necessary to perform analytics. To address this issue, time constraints on the analysis or algorithm optimization need to be performed. Third, the issue of data sparsity refers to the lack of sufficient data about student activities, which can be caused by offline learning activities or passive interactions with available online learning systems. In order to increase available data, online learning activities can be made mandatory and embedded into a course design.</p>
<p>Decisions regarding which data to collect, which features to select, which algorithm to use to build a predictive model, or how to evaluate model performance depend on the available data, dataset size, and study context <span class="citation" data-cites="saqr2022">[<a href="#ref-saqr2022" role="doc-biblioref">16</a>]</span>. A substantial body of research compares the performance of different predictive algorithms. For example, <span class="citation" data-cites="alshehri2017student">[<a href="#ref-alshehri2017student" role="doc-biblioref">29</a>]</span> collected student demographic and socio-economic data, self-reported motivation level, and assessment data from two evaluations during a semester. The authors predicted the student’s final grade (on a scale of 0–20) using the KNN and SVM algorithms. The performance of both algorithms was evaluated using 10-fold cross-validation and direct partition in the ratio methods, and it was found that SVM outperformed KNN. In another example, <span class="citation" data-cites="nguyen2024applying">[<a href="#ref-nguyen2024applying" role="doc-biblioref">30</a>]</span> collected student log data from a learning management system, such as the number of system logins the number of posts, or quiz grades, to model final exam grades using SVM and LR algorithms. The predictions were made multiple times during a semester and shown to the teacher. In this study, LR performed better than SVM, and the goodness-of-fit measure, R-squared, increased with each prediction in the semester. In addition, feature selection decreased model performance. <span class="citation" data-cites="tomasevic2020overview">[<a href="#ref-tomasevic2020overview" role="doc-biblioref">17</a>]</span> predicted student scores on the final exam (on a scale of 0–110) using KNN, SVM, Artificial NN, DT, Bayesian Regression, and LR. The dataset includes demographic data (e.g., gender, age), engagement data (sum of clicks), and performance data (e.g., scores per assessment). Artificial NN using engagement data and performance data had the highest precision out of all models. Including demographic data did not improve model precision significantly.</p>
<p>Other papers focused on determining the most important features that predict the outcome variable. For example, <span class="citation" data-cites="jo2015relations">[<a href="#ref-jo2015relations" role="doc-biblioref">31</a>]</span> collected LMS activity data, such as login frequency or number of student posts, and student assignment and assessment grades to predict student final grades using multiple linear regression. The results showed that total login frequency in LMS, regularity of learning interval in LMS, and total assignments and assessment composites predicted the final grades. <span class="citation" data-cites="cavazos2018learning">[<a href="#ref-cavazos2018learning" role="doc-biblioref">32</a>]</span> collected two datasets: 1) where historical academic grades were available and limited demographic data was used; 2) where historical academic grades were not available, while demographic and socioeconomic data were extensively used. The SVM algorithm was applied to predict students’ high school final grades using both datasets. The authors reported greater errors in the case of the dataset without historical academic grades than in the dataset with historical academic grades.</p>
<p>Finally, the issue of transferring predictive models within the same learning context and across different learning contexts was explored in the learning analytics research <span class="citation" data-cites="saqr2022 Jovanovic2021-et conijn2017">[<a href="#ref-saqr2022" role="doc-biblioref">16</a>, <a href="#ref-Jovanovic2021-et" role="doc-biblioref">33</a>, <a href="#ref-conijn2017" role="doc-biblioref">34</a>]</span>. For example, <span class="citation" data-cites="gavsevic2016learning">[<a href="#ref-gavsevic2016learning" role="doc-biblioref">35</a>]</span> examined the relationship between LMS log data and final grade (on a scale of 0–100%) after adjusting to student characteristics. In addition, separate multiple linear regression models were developed to compare different courses. The study found that the impact of LMS features varied significantly on student performance across courses. The work by <span class="citation" data-cites="Jovanovic2021-et">[<a href="#ref-Jovanovic2021-et" role="doc-biblioref">33</a>]</span> applied mixed effect linear regression models to analyze a sample of data from log data from 15 courses that were homogeneous regarding the institutional settings, discipline, nominal learning design, and course size. The results highlighted that the same pedagogical model and study setting did not guarantee the same predictive power among courses, as there may be differences in the practical implementation of specific pedagogical models. In addition, it was found that the overall time spent in an LMS, regular discussion forum posts, and accessing course materials regularly were significant predictors of student final course grades across all courses.</p>
</section>
<section id="performance-prediction-with-r" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="performance-prediction-with-r"><span class="header-section-number">3</span> Performance prediction with R</h2>
<p>In this section we present two approaches to implement performance prediction in R: one following a more classic procedure, and the second one following a more updated procedure based on <code>tidymodels</code>. Broadly, the workflow followed is depicted in <a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>, aligned with the common steps that are performed in any ML pipeline. First, we explore the data to gain an idea of the magnitude, format and content of the data, explore the relationships between the different variables, etc. This step is called exploratory data analysis. Next, we prepare the data (B) for subsequent steps. This might include removing or fixing incomplete records, converting data to different types, unifying values that are close to one another, or rescaling the data. The transformations that we need to do are commonly dictated by the type of data and the ML models that we will be using in subsequent steps. After data preparation, the next step is data splitting (C). Here, the dataset is divided into training and testing sets. The training set is used to fit the model, while the testing set is reserved for evaluating its performance. It is crucial to ensure that the testing set remains untouched until the evaluation stage to provide an unbiased estimate of the model’s generalization ability. Once the data is split, the process moves to model fitting (D). During this stage, the training data is used to train the selected machine learning models. This involves finding the optimal parameters that minimize error or maximize predictive accuracy for the given task. Depending on the algorithm, the model may identify different patterns, such as decision boundaries or relationships between features and the target variable. Finally, in the model evaluation step (E), the trained model is tested on the unseen testing data. Performance metrics that quantify the degree of error in the numeric predictions are computed to determine how well the model performs on new data. This step ensures that the model is not overfitting the training data and can generalize well to other datasets. We can repeat this process for several models with different underlying ML algorithms, or using only a subset of features of the data and compare the performance metrics among different models to select the one with the best fit.</p>
<div id="fig-workflow" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/workflow.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;1<strong>.</strong> ML workflow implemented in the tutorial</figcaption><p></p>
</figure>
</div>
<section id="the-dataset-used-in-this-chapter" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="the-dataset-used-in-this-chapter"><span class="header-section-number">3.1</span> The dataset used in this chapter</h3>
<p>The dataset we are using to illustrate the methods in this tutorial is a synthetic dataset based on the study by Jovanović et al. <span class="citation" data-cites="Jovanovic2021-et">[<a href="#ref-Jovanovic2021-et" role="doc-biblioref">33</a>]</span> and consists mostly of behavioral engagement indicators that can be obtained from learning management system (LMS) trace-log data. These variables capture both the engagement behavior of students (e.g., frequency and regularity of course and forum activities) and their participatory and time investment in the course (e.g., total duration, active days, session count) as well as the regularity of participation. Both time and regularity may be considered proxy indicators of cognitive engagement. We can also consider forum contributions as indicators of cognitive engagement since the context is problem-based learning, and student contributions require students to read, synthesize, critique, and formulate arguments <span class="citation" data-cites="Saqr2023-vs">[<a href="#ref-Saqr2023-vs" role="doc-biblioref">36</a>]</span>.</p>
<p>The dataset has the following variables:</p>
<ul>
<li><strong>Frequency Variables</strong>
<ul>
<li><strong>Freq_Course_View</strong>: The frequency of course page views by the student.</li>
<li><strong>Freq_Forum_Consume</strong>: The frequency with which the student consumes content in the forum (i.e., reads forum posts).</li>
<li><strong>Freq_Forum_Contribute</strong>: The frequency with which the student contributes to the forum (i.e., posts in the forum).</li>
<li><strong>Freq_Lecture_View</strong>: The frequency of lecture video views by the student.</li>
</ul></li>
<li><strong>Regularity Variables</strong>
<ul>
<li><strong>Regularity_Course_View</strong>: The consistency of the student’s course page views.</li>
<li><strong>Regularity_Lecture_View</strong>: The consistency of the student’s lecture video views.</li>
<li><strong>Regularity_Forum_Consume</strong>: The consistency of the student’s forum content consumption.</li>
<li><strong>Regularity_Forum_Contribute</strong>: The consistency of the student’s forum contributions.</li>
</ul></li>
<li><strong>Time Variables</strong>
<ul>
<li><strong>Session_Count</strong>: The total number of sessions the student has participated in.</li>
<li><strong>Total_Duration</strong>: The total duration (in seconds) of all sessions participated by the student.</li>
<li><strong>Active_Days</strong>: The number of days the student was active in the course.</li>
</ul></li>
<li><strong>Outcome Variables</strong>
<ul>
<li><strong>Final_Grade</strong>: The final grade of the student in the course.</li>
</ul></li>
</ul>
<section id="exploratory-data-analysis" class="level4" data-number="3.1.1">
<h4 data-number="3.1.1" class="anchored" data-anchor-id="exploratory-data-analysis"><span class="header-section-number">3.1.1</span> Exploratory Data Analysis</h4>
<p>Exploratory data analysis (EDA) is usually performed before doing the actual machine learning tasks (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–A). EDA includes examining the characteristics of the dataset to understand the distribution of the variables, and identify patterns and inconsistencies, if they may arise. Exploring the distribution and variance of each variable helps us identify any skewness, outliers, or anomalies in the data. Furthermore, EDA also allows us to examine the presence of missing values —or lack thereof—, handle distribution inconsistencies, and transform variables to balance their characteristics if needed. For instance, if we find that our variables have different measurement scales (one is measured in large numbers with vast variance and another in proportions and ranges between 0 and 1), we may need to transform or normalize the data to ensure that the two variables are not largely different. This process is particularly needed in some algorithms that are sensitive to discrepancies between variables. Additionally, we may have variables that are highly correlated (e.g., each is more or less a copy of the other), we may need to discard one of these similar variables as they do not offer any added information to the model and may bias the estimates. It should be mentioned that standardization will often result in less (direct) interpretability of the model, for example, when predicting final grade, there will be negative grades (below average) which might be hard to interpret, and also regression coefficients may be tricky to interpret. If standardization is carried out, the results may be presented on the original scales for better interpretation.</p>
<p>The first step in EDA is to load the R packages and use them to explore the data. We will need several R packages. Firstly, we will need <code>tidyverse</code>: a set of R packages designed to make it easy to read, edit, manipulate and visualize data through a large collection of functions for filtering, selecting and modifying the data <span class="citation" data-cites="tidyverse">[<a href="#ref-tidyverse" role="doc-biblioref">37</a>]</span>. As a collection of packages, <code>tidyverse</code> includes packages such as <code>dplyr</code> and <code>tidyr</code> for data manipulation and <code>ggplot2</code> for data visualization, among others. The <code>skimr</code> package provides an easy, yet comprehensive, summary of a dataset with more detail than most R built-in summary functions <span class="citation" data-cites="skimr">[<a href="#ref-skimr" role="doc-biblioref">38</a>]</span>. The <code>skimr</code> package offers central tendency statistics like mean and median as well as the number and proportion of missing values for each variable, making it easy to get an overview of the data and detect any anomalies or patterns quickly. Besides, <code>skimr</code> calculates variance measures, maximum, minimum and displays a miniature histogram for each variable. The <code>correlation</code> package is an easy-to-use package for estimating and visualizing several types of correlations. We will need the package <code>correlation</code> to visualize the correlation between variables. In particular, it will be used to create a heatmap to understand relationships between variables <span class="citation" data-cites="correlation">[<a href="#ref-correlation" role="doc-biblioref">39</a>]</span>. We will also use the package <code>rio</code> to import the data into our code <span class="citation" data-cites="rio">[<a href="#ref-rio" role="doc-biblioref">40</a>]</span>. Lastly, we will use the <code>performance</code> package to evaluate our predictive models <span class="citation" data-cites="Ludecke2021-li">[<a href="#ref-Ludecke2021-li" role="doc-biblioref">41</a>]</span>.</p>
<p>The next code starts by loading the R packages and reading the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(correlation)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(skimr)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rio)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(performance)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>student_data <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">"https://github.com/lamethods/data2/raw/main/lms/lms.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The previous R code imports student data from a CSV file. Next, the following EDA tasks will be performed: 1) provide a detailed summary of the data using <code>skimr</code>, 2) create histograms for all variables to examine their distribution, 3) calculate and visualize correlations between variables, and 4) extract and display correlations with the final grade of the course (<code>Final_Grade</code>).</p>
<p>In our EDA, first, we get a quick and comprehensive overview of the dataset using the <code>skim</code> function from the <code>skimr</code> package. The function provides detailed information such as the number of rows, number of columns, type of variables, and most importantly, the number of missing values (<code>n_missing</code>). <code>skimr</code> also provides basic statistics for each variable like mean, standard deviation (sd), minimum (p0) and maximum (p100), first quartile (p25), median (p50), third quartile (p75), and a small histogram of the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. A detailed summary using skimr</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(student_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">Name</td>
<td style="text-align: left;">student_data</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of rows</td>
<td style="text-align: left;">285</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of columns</td>
<td style="text-align: left;">12</td>
</tr>
<tr class="even">
<td style="text-align: left;">_______________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Column type frequency:</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">12</td>
</tr>
<tr class="odd">
<td style="text-align: left;">________________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Group variables</td>
<td style="text-align: left;">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 22%">
<col style="width: 8%">
<col style="width: 11%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 4%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">sd</th>
<th style="text-align: right;">p0</th>
<th style="text-align: right;">p25</th>
<th style="text-align: right;">p50</th>
<th style="text-align: right;">p75</th>
<th style="text-align: right;">p100</th>
<th style="text-align: left;">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Freq_Course_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">223.79</td>
<td style="text-align: right;">59.33</td>
<td style="text-align: right;">51.00</td>
<td style="text-align: right;">187.00</td>
<td style="text-align: right;">222.00</td>
<td style="text-align: right;">264.00</td>
<td style="text-align: right;">356.00</td>
<td style="text-align: left;">▁▃▇▇▂</td>
</tr>
<tr class="even">
<td style="text-align: left;">Freq_Forum_Consume</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">582.55</td>
<td style="text-align: right;">175.55</td>
<td style="text-align: right;">84.00</td>
<td style="text-align: right;">465.00</td>
<td style="text-align: right;">589.00</td>
<td style="text-align: right;">703.00</td>
<td style="text-align: right;">991.00</td>
<td style="text-align: left;">▁▅▇▇▂</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Freq_Forum_Contribute</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">178.07</td>
<td style="text-align: right;">55.57</td>
<td style="text-align: right;">17.00</td>
<td style="text-align: right;">144.00</td>
<td style="text-align: right;">175.00</td>
<td style="text-align: right;">213.00</td>
<td style="text-align: right;">347.00</td>
<td style="text-align: left;">▁▅▇▃▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Freq_Lecture_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">201.87</td>
<td style="text-align: right;">56.68</td>
<td style="text-align: right;">32.00</td>
<td style="text-align: right;">162.00</td>
<td style="text-align: right;">202.00</td>
<td style="text-align: right;">247.00</td>
<td style="text-align: right;">346.00</td>
<td style="text-align: left;">▁▃▇▆▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Regularity_Course_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.51</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: right;">0.15</td>
<td style="text-align: right;">0.42</td>
<td style="text-align: right;">0.52</td>
<td style="text-align: right;">0.61</td>
<td style="text-align: right;">0.90</td>
<td style="text-align: left;">▂▅▇▅▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Regularity_Lecture_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: right;">0.15</td>
<td style="text-align: right;">0.07</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">0.49</td>
<td style="text-align: right;">0.57</td>
<td style="text-align: right;">0.80</td>
<td style="text-align: left;">▁▅▇▇▃</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Regularity_Forum_Consume</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.49</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: right;">0.41</td>
<td style="text-align: right;">0.50</td>
<td style="text-align: right;">0.58</td>
<td style="text-align: right;">0.95</td>
<td style="text-align: left;">▁▅▇▂▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Regularity_Forum_Contribute</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: right;">0.16</td>
<td style="text-align: right;">0.03</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">0.47</td>
<td style="text-align: right;">0.59</td>
<td style="text-align: right;">0.90</td>
<td style="text-align: left;">▁▃▇▅▂</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Session_Count</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">189.54</td>
<td style="text-align: right;">52.83</td>
<td style="text-align: right;">53.00</td>
<td style="text-align: right;">151.00</td>
<td style="text-align: right;">191.00</td>
<td style="text-align: right;">229.00</td>
<td style="text-align: right;">306.00</td>
<td style="text-align: left;">▂▅▇▇▂</td>
</tr>
<tr class="even">
<td style="text-align: left;">Total_Duration</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">83150.98</td>
<td style="text-align: right;">23818.16</td>
<td style="text-align: right;">25055.00</td>
<td style="text-align: right;">68632.00</td>
<td style="text-align: right;">83667.00</td>
<td style="text-align: right;">98373.00</td>
<td style="text-align: right;">147827.00</td>
<td style="text-align: left;">▂▆▇▅▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Active_Days</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">16.06</td>
<td style="text-align: right;">4.15</td>
<td style="text-align: right;">5.00</td>
<td style="text-align: right;">14.00</td>
<td style="text-align: right;">16.00</td>
<td style="text-align: right;">19.00</td>
<td style="text-align: right;">31.00</td>
<td style="text-align: left;">▂▆▇▂▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Final_Grade</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">68.62</td>
<td style="text-align: right;">8.86</td>
<td style="text-align: right;">44.73</td>
<td style="text-align: right;">62.42</td>
<td style="text-align: right;">68.66</td>
<td style="text-align: right;">75.26</td>
<td style="text-align: right;">90.89</td>
<td style="text-align: left;">▁▆▇▇▁</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The results of the <code>skim(student_data)</code> command show that the data has 285 observations and no missing data in any variable. However, the variables have large differences in variance. For instance, the frequency variables are different from the regularity variables which are all below 1 and even more different if we compared them to the duration which has a mean of 83150.98 (SD = 23818.16). This information tells us that data may need to be normalized if the algorithm that we choose is sensitive to differences in variance.</p>
<p>The second step is to inspect the distribution of all variables (<a href="#fig-histall">Figure&nbsp;<span>3.2</span></a>) using the following code, which starts by using <code>pivot_longer(everything())</code> to reshape our data, putting all variables into a single column. This makes it easier to create a faceted plot (multiple plots). We use <code>ggplot2</code> to create histograms for each variable. The <code>facet_wrap(~ name, scales = "free")</code> line creates a separate plot for each variable, and <code>scales = "free"</code> allows each plot to have its own horizontal and vertical scales, which is often necessary when dealing with variables of different types or ranges and scales of measurement. For a tutorial about data visualization with R, refer to <span class="citation" data-cites="Lopez-Pernas2024-ge">[<a href="#ref-Lopez-Pernas2024-ge" role="doc-biblioref">15</a>]</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Histograms of all variables</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>student_data <span class="sc">|&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>()) <span class="sc">|&gt;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> value)) <span class="sc">+</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">25</span>, <span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> name, <span class="at">scales =</span> <span class="st">"free"</span>) <span class="sc">+</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-histall" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-histall-1.png" class="img-fluid figure-img" width="960"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;2<strong>.</strong> Histograms of all variables</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The third step is to look at the correlations between variables (<a href="#fig-corr">Figure&nbsp;<span>3.3</span></a>). This allows us to see if there are any variables that are highly correlated to each other. If there are variables that are perfectly or almost perfectly correlated, they might be redundant or linear combinations of one another and therefore, do not add much to the model. The heatmap shows that most variables have correlations below the 0.8 level, and only a few cross this level. We may also examine the correlation with the final grade (our outcome variable that we want to predict) to explore variable importance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Relationship between Variables and `Final_Grade`</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate correlations with `Final_Grade`</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>correlations <span class="ot">&lt;-</span> <span class="fu">correlation</span>(student_data, <span class="at">method =</span> <span class="st">"pearson"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>correlations <span class="sc">|&gt;</span> <span class="fu">summary</span>() <span class="sc">|&gt;</span> <span class="fu">plot</span>() <span class="sc">+</span> </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">vjust =</span> <span class="dv">1</span>, <span class="at">hjust =</span> <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-corr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-corr-1.png" class="img-fluid figure-img" width="864"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;3<strong>.</strong> Correlations between Variables and <code>Final_Grade</code></figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and display correlations with `Final_Grade`</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>final_grade_correlations <span class="ot">&lt;-</span> correlations <span class="sc">|&gt;</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Parameter2 <span class="sc">==</span> <span class="st">"Final_Grade"</span>) <span class="sc">|&gt;</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(r))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the correlations with `Final_Grade`</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>final_grade_correlations</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["Parameter1"],"name":[1],"type":["chr"],"align":["left"]},{"label":["Parameter2"],"name":[2],"type":["chr"],"align":["left"]},{"label":["r"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["CI"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["CI_low"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["CI_high"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["t"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["df_error"],"name":[8],"type":["int"],"align":["right"]},{"label":["p"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["Method"],"name":[10],"type":["chr"],"align":["left"]},{"label":["n_Obs"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"Freq_Forum_Contribute","2":"Final_Grade","3":"0.58","4":"0.95","5":"0.50","6":"0.65","7":"12.0","8":"283","9":"0.00000000000000000000000019","10":"Pearson correlation","11":"285"},{"1":"Freq_Forum_Consume","2":"Final_Grade","3":"0.51","4":"0.95","5":"0.42","6":"0.59","7":"10.0","8":"283","9":"0.00000000000000000066613921","10":"Pearson correlation","11":"285"},{"1":"Session_Count","2":"Final_Grade","3":"0.51","4":"0.95","5":"0.42","6":"0.59","7":"10.0","8":"283","9":"0.00000000000000000086312557","10":"Pearson correlation","11":"285"},{"1":"Total_Duration","2":"Final_Grade","3":"0.47","4":"0.95","5":"0.38","6":"0.56","7":"9.1","8":"283","9":"0.00000000000000063999009220","10":"Pearson correlation","11":"285"},{"1":"Regularity_Course_View","2":"Final_Grade","3":"0.45","4":"0.95","5":"0.35","6":"0.54","7":"8.5","8":"283","9":"0.00000000000004001787832721","10":"Pearson correlation","11":"285"},{"1":"Active_Days","2":"Final_Grade","3":"0.42","4":"0.95","5":"0.32","6":"0.51","7":"7.8","8":"283","9":"0.00000000000324249753863009","10":"Pearson correlation","11":"285"},{"1":"Freq_Course_View","2":"Final_Grade","3":"0.40","4":"0.95","5":"0.30","6":"0.50","7":"7.4","8":"283","9":"0.00000000002385564255088207","10":"Pearson correlation","11":"285"},{"1":"Regularity_Lecture_View","2":"Final_Grade","3":"0.39","4":"0.95","5":"0.29","6":"0.48","7":"7.1","8":"283","9":"0.00000000011395287939365397","10":"Pearson correlation","11":"285"},{"1":"Regularity_Forum_Consume","2":"Final_Grade","3":"0.38","4":"0.95","5":"0.28","6":"0.48","7":"7.0","8":"283","9":"0.00000000024412682323026614","10":"Pearson correlation","11":"285"},{"1":"Regularity_Forum_Contribute","2":"Final_Grade","3":"0.36","4":"0.95","5":"0.25","6":"0.45","7":"6.4","8":"283","9":"0.00000000524931925887681388","10":"Pearson correlation","11":"285"},{"1":"Freq_Lecture_View","2":"Final_Grade","3":"0.26","4":"0.95","5":"0.15","6":"0.37","7":"4.5","8":"283","9":"0.00004128706419879164097285","10":"Pearson correlation","11":"285"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
</section>
<section id="data-preparation" class="level4" data-number="3.1.2">
<h4 data-number="3.1.2" class="anchored" data-anchor-id="data-preparation"><span class="header-section-number">3.1.2</span> Data preparation</h4>
<p>The next stage in our workflow is data preparation (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–B), where we clean and transform our data to fix any problems and inconsistencies and to get it ready for subsequent steps. We can see two potential issues with our data: data with large differences in variance (e.g., duration and regularity) as well as potential high collinearity in some variables. We may need to standardize the data (subtract the mean and divide by the standard deviation) to make all variables have a comparable scale. The code in the next chunk does exactly that: it simply scales all numeric variables. You may need to re-run the EDA code again to verify:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize numeric columns in the student_data data frame</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>student_data_standardized <span class="ot">&lt;-</span> student_data <span class="sc">|&gt;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">where</span>(is.numeric),  <span class="co"># Select all numeric columns</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span><span class="fu">scale</span>(.) <span class="sc">|&gt;</span> <span class="co"># Standardize each column (M=0, SD=1) </span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">as.vector</span>() <span class="co"># Convert to vector</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  ))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Use skimr package to get a summary of the standardized data</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(student_data_standardized)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">Name</td>
<td style="text-align: left;">student_data_standardized</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of rows</td>
<td style="text-align: left;">285</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of columns</td>
<td style="text-align: left;">12</td>
</tr>
<tr class="even">
<td style="text-align: left;">_______________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Column type frequency:</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">12</td>
</tr>
<tr class="odd">
<td style="text-align: left;">________________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Group variables</td>
<td style="text-align: left;">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 30%">
<col style="width: 10%">
<col style="width: 15%">
<col style="width: 5%">
<col style="width: 3%">
<col style="width: 5%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">sd</th>
<th style="text-align: right;">p0</th>
<th style="text-align: right;">p25</th>
<th style="text-align: right;">p50</th>
<th style="text-align: right;">p75</th>
<th style="text-align: right;">p100</th>
<th style="text-align: left;">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Freq_Course_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.9</td>
<td style="text-align: right;">-0.62</td>
<td style="text-align: right;">-0.03</td>
<td style="text-align: right;">0.68</td>
<td style="text-align: right;">2.2</td>
<td style="text-align: left;">▁▃▇▆▂</td>
</tr>
<tr class="even">
<td style="text-align: left;">Freq_Forum_Consume</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.8</td>
<td style="text-align: right;">-0.67</td>
<td style="text-align: right;">0.04</td>
<td style="text-align: right;">0.69</td>
<td style="text-align: right;">2.3</td>
<td style="text-align: left;">▁▅▇▇▂</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Freq_Forum_Contribute</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.9</td>
<td style="text-align: right;">-0.61</td>
<td style="text-align: right;">-0.06</td>
<td style="text-align: right;">0.63</td>
<td style="text-align: right;">3.0</td>
<td style="text-align: left;">▁▅▇▃▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Freq_Lecture_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-3.0</td>
<td style="text-align: right;">-0.70</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.80</td>
<td style="text-align: right;">2.5</td>
<td style="text-align: left;">▁▃▇▆▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Regularity_Course_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.5</td>
<td style="text-align: right;">-0.62</td>
<td style="text-align: right;">0.09</td>
<td style="text-align: right;">0.73</td>
<td style="text-align: right;">2.8</td>
<td style="text-align: left;">▂▅▇▅▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Regularity_Lecture_View</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.8</td>
<td style="text-align: right;">-0.66</td>
<td style="text-align: right;">0.09</td>
<td style="text-align: right;">0.63</td>
<td style="text-align: right;">2.2</td>
<td style="text-align: left;">▁▅▇▇▃</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Regularity_Forum_Consume</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.6</td>
<td style="text-align: right;">-0.60</td>
<td style="text-align: right;">0.05</td>
<td style="text-align: right;">0.62</td>
<td style="text-align: right;">3.3</td>
<td style="text-align: left;">▁▅▇▂▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Regularity_Forum_Contribute</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.8</td>
<td style="text-align: right;">-0.64</td>
<td style="text-align: right;">-0.08</td>
<td style="text-align: right;">0.66</td>
<td style="text-align: right;">2.6</td>
<td style="text-align: left;">▁▃▇▅▂</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Session_Count</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.6</td>
<td style="text-align: right;">-0.73</td>
<td style="text-align: right;">0.03</td>
<td style="text-align: right;">0.75</td>
<td style="text-align: right;">2.2</td>
<td style="text-align: left;">▂▅▇▇▂</td>
</tr>
<tr class="even">
<td style="text-align: left;">Total_Duration</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.4</td>
<td style="text-align: right;">-0.61</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: right;">0.64</td>
<td style="text-align: right;">2.7</td>
<td style="text-align: left;">▂▆▇▅▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Active_Days</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.7</td>
<td style="text-align: right;">-0.50</td>
<td style="text-align: right;">-0.02</td>
<td style="text-align: right;">0.71</td>
<td style="text-align: right;">3.6</td>
<td style="text-align: left;">▂▆▇▂▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">Final_Grade</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-2.7</td>
<td style="text-align: right;">-0.70</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.75</td>
<td style="text-align: right;">2.5</td>
<td style="text-align: left;">▁▆▇▇▁</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We may also need to investigate the multicollinearity issue further. While multicollinearity is not a commonly discussed problem in machine learning, it is particularly important in explainable AI. If present, multicollinearity can lead to unstable estimates of model coefficients and inflated standard errors. One way to detect multicollinearity is by calculating the variance inflation factor (VIF). VIF measures the amount of inflation in the variance of a coefficient due to its correlation with other predictors. A high VIF value indicates that a variable is highly correlated with one or more other variables, suggesting multicollinearity. While there is no consensus about the VIF cutoff, in practice, a VIF value greater than 5 or 10 is often used as a cutoff to indicate multicollinearity. VIF is commonly computed in regression models, so we fit a regression model in the following code and then estimate the VIF from it. The code fits a linear regression model to predict the outcome variable (<code>Final_Grade</code>) using student LMS indicators as predictors. After fitting the model, it pipes the result into the <code>check_collinearity()</code> function from the <code>performance</code> package. The results of the VIF show that we have only four variables with moderate VIF values, so we can proceed with the analysis with no exclusion of any variable, given that we do not have a considerable collinearity problem.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear regression model and check for multicollinearity</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(Final_Grade <span class="sc">~</span> Freq_Course_View <span class="sc">+</span> Freq_Lecture_View <span class="sc">+</span> Freq_Forum_Consume <span class="sc">+</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                 Freq_Forum_Contribute <span class="sc">+</span> Regularity_Course_View <span class="sc">+</span> </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                 Regularity_Lecture_View <span class="sc">+</span> Regularity_Forum_Consume <span class="sc">+</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                 Regularity_Forum_Contribute <span class="sc">+</span> Session_Count <span class="sc">+</span> </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                 Total_Duration <span class="sc">+</span> Active_Days,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> student_data_standardized) <span class="sc">|&gt;</span>  <span class="co"># Use standardized data for the model</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="fu">check_collinearity</span>()    <span class="co"># Check for multicollinearity among predictors</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["Term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["VIF"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["VIF_CI_low"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["VIF_CI_high"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["SE_factor"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["Tolerance"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["Tolerance_CI_low"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["Tolerance_CI_high"],"name":[8],"type":["dbl"],"align":["right"]}],"data":[{"1":"Freq_Course_View","2":"4.6","3":"3.8","4":"5.6","5":"2.1","6":"0.22","7":"0.18","8":"0.26"},{"1":"Freq_Lecture_View","2":"2.0","3":"1.7","4":"2.3","5":"1.4","6":"0.51","7":"0.43","8":"0.59"},{"1":"Freq_Forum_Consume","2":"6.6","3":"5.4","4":"8.1","5":"2.6","6":"0.15","7":"0.12","8":"0.19"},{"1":"Freq_Forum_Contribute","2":"3.7","3":"3.1","4":"4.6","5":"1.9","6":"0.27","7":"0.22","8":"0.32"},{"1":"Regularity_Course_View","2":"5.2","3":"4.3","4":"6.3","5":"2.3","6":"0.19","7":"0.16","8":"0.23"},{"1":"Regularity_Lecture_View","2":"3.1","3":"2.6","4":"3.8","5":"1.8","6":"0.32","7":"0.27","8":"0.39"},{"1":"Regularity_Forum_Consume","2":"2.1","3":"1.8","4":"2.5","5":"1.4","6":"0.49","7":"0.41","8":"0.57"},{"1":"Regularity_Forum_Contribute","2":"1.4","3":"1.3","4":"1.7","5":"1.2","6":"0.70","7":"0.59","8":"0.79"},{"1":"Session_Count","2":"7.3","3":"6.0","4":"9.0","5":"2.7","6":"0.14","7":"0.11","8":"0.17"},{"1":"Total_Duration","2":"4.7","3":"3.9","4":"5.8","5":"2.2","6":"0.21","7":"0.17","8":"0.26"},{"1":"Active_Days","2":"5.8","3":"4.8","4":"7.1","5":"2.4","6":"0.17","7":"0.14","8":"0.21"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="tutorial-1-a-classic-approach-to-predictive-modeling" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="tutorial-1-a-classic-approach-to-predictive-modeling"><span class="header-section-number">4</span> Tutorial 1: A Classic Approach to Predictive Modeling</h2>
<p>Having explored and prepared the data, we now proceed to the next step of predicting students’ performance using machine learning. We will predict the final grades using the variables that represent the students’ engagement. The steps include loading the necessary R packages, splitting the data, fitting the model, and evaluating the model’s performance. First, we load the required R packages: the <code>randomForest</code> package, which is used to build the random forest model, the <code>rsample</code> package, which will be used to split the data into training and testing sets, and the <code>yardstick</code> package to facilitate model evaluation by calculating performance metrics.</p>
<p>Second, we split the dataset into two parts: a <strong>training</strong> set, which is used to train the machine learning model (perform the prediction), and a <strong>testing</strong> set (a holdout set for evaluation). The main rationale for data splitting is to use it to assess the performance of the estimated machine learning model on new, unseen data (the testing dataset). When keeping a testing dataset aside, we can evaluate how well the trained model generalizes to new data instances and estimate its accuracy. After all, we are creating the model with the hope that the same results will be obtainable in the future with new data. Furthermore, if we perform the prediction on all of the data, the model may —and most probably will— overfit. Overfitting occurs when a model learns the training data too well, including noise or irrelevant features, resulting in poor performance on new data. By having a separate testing set held out, we are increasing the likelihood that the model is learning the relevant patterns within the data not the noise. In practice, if a good model performs well on both the training and testing datasets, it is a good indication that the model is not overfitting and is likely to perform well in other situations with new data. Lastly, having a separate testing data set is rather valuable when our goal is to compare multiple machine learning algorithms to determine which model performs better on new data.</p>
<p>The code below uses the function <code>initial_split</code> function from the <code>rsample</code> package to perform an 80/20 split, where 80% of the data is used to train the model (perform the prediction), and the remaining 20% is kept aside as a testing set. While there is no consensus on the split ratio with many others using 70/30 and closer values, 80/20 is a reasonable starting point as it provides sufficient data for training while reserving a reasonable amount for evaluation.</p>
<p>Third, we build the random forest model using the <code>randomForest</code> function from the <code>randomForest</code> package. The random forest algorithm is an ensemble learning method that creates multiple decision trees and combines their predictions to improve accuracy and control overfitting. This combination of multiple models helps reduce overfitting by averaging out the errors, resulting in an —arguably— more robust and generalizable model. More importantly, the random forest algorithm is an explainable model and provides feature importance scores, which can be used to identify the most relevant features for the problem at hand. In our case, it can help explain which variables help predict students’ performance. In this model, we predict the final grade (<code>Final_Grade</code>) based on the engagement variables such as the frequency and regularity of course views, lecture views, forum consumption and contributions, session count, total duration of activities, and the number of active days. We specify the number of trees (<code>ntree</code>) to be 1000, a parameter that controls the complexity and performance of the model.</p>
<p>After fitting the model, we print the model summary using the functions <code>print</code> and <code>importance</code> (which shows the explanatory variables). The summary provides the model call, insights into the model’s performance, including error rates and the proportion of variance explained. Variable importance shows how much each predictor has contributed to the prediction accuracy of students’ performance. In doing so, it allows us to understand which features are more associated with higher grades. More accurately, which features the random forest algorithm associated with higher grades. Learning the important variables allows us to gain insights of what can help in improving teaching and learning based on the results of our model.</p>
<p>Fourth, we use the trained model with new unseen data instances that we held out (the testing dataset) to perform predictions. In other words, the already trained model will estimate the final grades in the testing data. In this step, we use the <code>predict</code> function to apply the model to the test dataset to generate predictions of final grades. These predictions will be compared against the actual grades to evaluate how close or far the algorithm was able to predict the grades and by that we evaluate the model’s performance. The closer the predictions are to the actual grade values, the better the performance of the algorithm. If the predicted grades differ considerably from the actual grades, it is an indication that the model is not good enough. It might be that we do not have enough data to make reliable predictions or, on the contrary, that our model is overfitted to the training data.</p>
<p>In the fifth step, we evaluate the model performance, given that there are multiple ways to assess performance, we will use different indicators, each of them provides different insights. Among the most common metrics when evaluating a regression machine learning model are the root mean squared error (RMSE), R-squared (R²), and mean absolute error (MAE). RMSE is a measure of the differences between predicted and actual values. It is calculated as the square root of the average of the squared differences between predicted and actual values. RMSE is always a positive value (because the errors are squared), where lower RMSE values indicate a better fit of the model to the data. Further, RMSE is sensitive to outliers because RMSE squares the errors, inflating the weight of larger errors.</p>
<p>R-squared (R² or rsq) measures the proportion of variance in the dependent variable (the final grade in our case) that is explained by the independent variables. R² values range from 0 to 1, where values of 1 indicate that the model explains all the variability and R² of 0 indicates that the model explains none (bad model). However, although R² is popular, it can be misleading, pointing to erroneous conclusions. A high R² does not necessarily mean that the model is good; it only means that the model explains a large portion of the variance in the dependent variable. A major issue is that R² only measures the goodness of fit between the model and the data, but it does not account for the complexity or interpretability of the model. Adding more independent variables to a model, regardless of their relevance, will always increase or at least not decrease the R² value, leading to a more complex model that may be hard to interpret. As such, high R² values may give a false impression of a model’s predictive power. Furthermore, a high R² does not guarantee that the model will perform well on new, unseen data. Other metrics such as RMSE or MAE, are more useful in this regard. MAE measures the absolute average magnitude of the errors in a set of predictions (i.e., without considering the direction of the difference). It is calculated as the average of the absolute differences between predicted and actual values. Unlike RMSE, MAE is not sensitive to outliers (since no squaring is performed).</p>
<p>The sixth step in our analysis is creating better and enhanced model performance evaluation. In that, we visualize the predicted versus actual grades to see how the model fared. We also plot the variable importance in a better way using the <code>ggplot2</code> package as well as the residuals. Here are the steps of the tutorial in detail:</p>
<section id="loading-the-necessary-libraries" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="loading-the-necessary-libraries"><span class="header-section-number">4.1</span> Loading the necessary libraries</h3>
<p>The code below starts by loading the necessary libraries. The <code>randomForest</code> <span class="citation" data-cites="randomForest">[<a href="#ref-randomForest" role="doc-biblioref">42</a>]</span> library is used to build and work with random forest models, while <code>rsample</code> <span class="citation" data-cites="rsample">[<a href="#ref-rsample" role="doc-biblioref">43</a>]</span> aids in splitting the dataset into training and testing subsets. The <code>yardstick</code> <span class="citation" data-cites="yardstick">[<a href="#ref-yardstick" role="doc-biblioref">44</a>]</span> package is used for evaluating the performance of the model, and <code>ggplot2</code> is employed for creating visualizations, although the latter is not explicitly mentioned in the code given that it is part of <code>tidyverse</code> <span class="citation" data-cites="tidyverse">[<a href="#ref-tidyverse" role="doc-biblioref">37</a>]</span> that we loaded before. Next, we set the seed function to a number <code>set.seed(256)</code> to ensure that our results would repeat in a similar way when re-running the code, e.g., data splitting would be consistent across different runs of the code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Load necessary libraries</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)  <span class="co"># For building the Random Forest model</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)       <span class="co"># For data splitting</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(yardstick)     <span class="co"># For model evaluation</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="splitting-the-dataset" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="splitting-the-dataset"><span class="header-section-number">4.2</span> Splitting the dataset</h3>
<p>Then, in the second step, we split the dataset (<code>student_data_standardized</code>) into training and testing sets (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–C). This is done using the <code>initial_split</code> function from the <code>rsample</code> package, which divides the data into an 80% training set and a 20% testing set. The <code>training</code> function extracts the training subset, while the <code>testing</code> function retrieves the testing subset and they are both assigned to two data frames <code>train_data</code> and <code>test_data</code> respectively.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Split the data into training and testing sets</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Using initial_split from rsample package for an 80/20 split</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(student_data_standardized, <span class="at">prop =</span> <span class="fl">0.8</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-and-fitting-the-model" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="creating-and-fitting-the-model"><span class="header-section-number">4.3</span> Creating and fitting the model</h3>
<p>In the third step, we build and fit the random forest model (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–D). The <code>randomForest</code> function is used to create this model, where <code>Final_Grade</code> is predicted based on the engagement predictor variables such as <code>Freq_Course_View</code>, <code>Freq_Lecture_View</code>, and <code>Session_Count</code>. The model is configured to use 1000 trees, which is specified by the <code>ntree</code> parameter. In Random Forest models, specifying a large number of trees enhances performance by reducing variance and improving stability through the aggregation of predictions from 1000 diverse trees. Each tree provides a unique perspective due to its training on random data subsets, and averaging their predictions minimizes overfitting. Yet, whereas more trees may improve model performance, balancing the number of trees is important, as performance gains diminish —or disappear— beyond a certain point. Also, setting a very high number of trees incurs computational costs, increases the risk of overfitting, and training time.</p>
<p>After fitting the model, the code prints a summary of the random forest model using <code>print(rf_model)</code>. This summary provides insights into the model’s performance and structure. Additionally, <code>importance(rf_model)</code> is called to extract and display the importance of each variable in the model, helping to identify which predictors contribute most to the model’s predictions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Create and fit a Random Forest model</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Building the Random Forest model with 1000 trees</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Final_Grade <span class="sc">~</span> </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                           Freq_Course_View <span class="sc">+</span> Freq_Lecture_View <span class="sc">+</span> Freq_Forum_Consume <span class="sc">+</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>                           Freq_Forum_Contribute <span class="sc">+</span> Regularity_Course_View <span class="sc">+</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>                           Regularity_Lecture_View <span class="sc">+</span> Regularity_Forum_Consume <span class="sc">+</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>                           Regularity_Forum_Contribute <span class="sc">+</span> Session_Count <span class="sc">+</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>                           Total_Duration <span class="sc">+</span> Active_Days,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">data =</span> train_data, <span class="at">ntree =</span> <span class="dv">1000</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model summary and variable importance</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rf_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
 randomForest(formula = Final_Grade ~ Freq_Course_View + Freq_Lecture_View +      Freq_Forum_Consume + Freq_Forum_Contribute + Regularity_Course_View +      Regularity_Lecture_View + Regularity_Forum_Consume + Regularity_Forum_Contribute +      Session_Count + Total_Duration + Active_Days, data = train_data,      ntree = 1000) 
               Type of random forest: regression
                     Number of trees: 1000
No. of variables tried at each split: 3

          Mean of squared residuals: 0.7
                    % Var explained: 33</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing the model summary and variable importance</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            IncNodePurity
Freq_Course_View                     17.0
Freq_Lecture_View                    14.5
Freq_Forum_Consume                   24.0
Freq_Forum_Contribute                47.7
Regularity_Course_View               18.7
Regularity_Lecture_View              13.1
Regularity_Forum_Consume             13.7
Regularity_Forum_Contribute          23.7
Session_Count                        21.6
Total_Duration                       22.0
Active_Days                           8.9</code></pre>
</div>
</div>
</section>
<section id="evaluating-the-models-performance" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="evaluating-the-models-performance"><span class="header-section-number">4.4</span> Evaluating the model’s performance</h3>
<p>The next stage in our workflow is to evaluate how well our model predicts performance (<a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–E). In Step 4, we make predictions on the test data using our trained Random Forest model by using the <code>predict</code> function, which generates a set of predicted values based on the features in <code>test_data</code> and the algorithm estimated before.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Make predictions on the test data</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Making predictions based on the test data using the trained model</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, <span class="at">newdata =</span> test_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In Step 5, we add these predictions to the test dataset, creating a new data frame called <code>evaluation_data</code> that includes both the actual and predicted grades. We then use the <code>metrics</code> function from the yardstick <code>package</code> to evaluate our model’s performance by comparing the predicted grades with the actual ones, and we print the performance results to obtain performance metrics RMSE, MAE, and R-squared.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Evaluate the model's performance</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding predictions to the test data for evaluation</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>evaluation_data <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(test_data, <span class="at">Predicted_Grade =</span> predictions)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluating model performance</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>performance_metrics <span class="ot">&lt;-</span> evaluation_data <span class="sc">|&gt;</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Final_Grade, <span class="at">estimate =</span> Predicted_Grade)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the model performance metrics</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(performance_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 rmse    standard       0.631
2 rsq     standard       0.525
3 mae     standard       0.480</code></pre>
</div>
</div>
<p>In step 6, we produce two visualizations. The first visualization plots the actual versus predicted grades (<a href="#fig-scatter">Figure&nbsp;<span>3.4</span></a>). Examining the distance between the residual and the fitted line gives an idea about how the model fared. The other plot is an improved plot of the important variables (<a href="../ch04-classification/ch04-classification.html#fig-varimp">Figure&nbsp;<span>4.4</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Visualize predicted vs actual grades</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(evaluation_data, <span class="fu">aes</span>(<span class="at">x =</span> Final_Grade, <span class="at">y =</span> Predicted_Grade)) <span class="sc">+</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Actual Grade"</span>, <span class="at">y =</span> <span class="st">"Predicted Grade"</span>) <span class="sc">+</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-scatter" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-scatter-1.png" class="img-fluid figure-img" style="width:5in"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;4<strong>.</strong> Scatter plot comparing predicted vs.&nbsp;actual grades</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Enhanced variable importance plot</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Extracting variable importance from the Random Forest model</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>variable_importance <span class="ot">&lt;-</span> <span class="fu">importance</span>(rf_model)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>var_imp_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Variable =</span> <span class="fu">rownames</span>(variable_importance), </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">Importance =</span> variable_importance[, <span class="dv">1</span>])</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting variable importance</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(var_imp_df, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, Importance), <span class="at">y =</span> Importance)) <span class="sc">+</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"skyblue"</span>) <span class="sc">+</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Variable"</span>, <span class="at">y =</span> <span class="st">"Importance"</span>) <span class="sc">+</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-varimp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-varimp-1.png" class="img-fluid figure-img" style="width:5in"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;5<strong>.</strong> Variable importance</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>This code snippet demonstrates how to create and interpret residual plots for a random forest model. The process begins by calculating residuals, which are the differences between the actual <code>Final_Grade</code> and the <code>Predicted_Grade</code>. These residuals are then visualized in two separate plots using <code>ggplot2</code>. The first plot is a basic scatter plot of residuals against predicted grades, with each point representing a prediction (<a href="#fig-residuals">Figure&nbsp;<span>3.6</span></a>). A horizontal red dashed line at zero helps identify any systematic over- or under-prediction. The second plot builds upon the first by adding a green smoothed trend line, which can reveal non-linear patterns in the residuals. Ideally, the residuals should be randomly scattered around the zero line with no discernible pattern, indicating that the model’s errors are randomly distributed and there are no underlying biases or issues with the model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate residuals</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>evaluation_data<span class="sc">$</span>residuals <span class="ot">&lt;-</span> </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  evaluation_data<span class="sc">$</span>Final_Grade <span class="sc">-</span> evaluation_data<span class="sc">$</span>Predicted_Grade</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a smoothed line to show trends</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(evaluation_data, <span class="fu">aes</span>(<span class="at">x =</span> Predicted_Grade, <span class="at">y =</span> residuals)) <span class="sc">+</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">color =</span> <span class="st">"green"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Predicted Grade"</span>, <span class="at">y =</span> <span class="st">"Residuals"</span>) <span class="sc">+</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-residuals" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-residuals-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;6<strong>.</strong> Residual Plot for Random Forest Model with Trend Line.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="other-algorithms" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="other-algorithms"><span class="header-section-number">4.5</span> Other algorithms</h3>
<p>In the same way, we can execute other algorithms. Here we use a simpler algorithm (linear regression) given that it assumes that the relation between predictors and predicted grades is linear. Also, linear regression model does not need tuning (e.g., number of trees etc.). The way variable importance is calculated also differs: Random forest provides an inherent measure of feature importance, whereas for linear regression, we use the absolute values of the coefficients for importance. The evaluation metrics and visualization steps remain largely the same, although the results and interpretations would likely differ due to the fundamental differences in the models. Not also that the linear regression had lower R² but higher error measures RMSE and MAE. Please also note the differences and similarities in variable importance between the two algorithms.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Create and fit a Linear Regression model</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(Final_Grade <span class="sc">~</span> </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>               Freq_Course_View <span class="sc">+</span> Freq_Lecture_View <span class="sc">+</span> Freq_Forum_Consume <span class="sc">+</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>               Freq_Forum_Contribute <span class="sc">+</span> Regularity_Course_View <span class="sc">+</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>               Regularity_Lecture_View <span class="sc">+</span> Regularity_Forum_Consume <span class="sc">+</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>               Regularity_Forum_Contribute <span class="sc">+</span> Session_Count <span class="sc">+</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>               Total_Duration <span class="sc">+</span> Active_Days,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> student_data_standardized)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Print model summary</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">summary</span>(lm_model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Final_Grade ~ Freq_Course_View + Freq_Lecture_View + 
    Freq_Forum_Consume + Freq_Forum_Contribute + Regularity_Course_View + 
    Regularity_Lecture_View + Regularity_Forum_Consume + Regularity_Forum_Contribute + 
    Session_Count + Total_Duration + Active_Days, data = student_data_standardized)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.5669 -0.4984  0.0593  0.5060  1.9453 

Coefficients:
                                         Estimate            Std. Error t value    Pr(&gt;|t|)    
(Intercept)                  0.000000000000000747  0.046179132911298881    0.00       1.000    
Freq_Course_View            -0.004596244897394796  0.098861369352034281   -0.05       0.963    
Freq_Lecture_View           -0.019940653761920547  0.064689500916218223   -0.31       0.758    
Freq_Forum_Consume          -0.144808972991361057  0.118530889483868279   -1.22       0.223    
Freq_Forum_Contribute        0.523780479201737648  0.089481942137727782    5.85 0.000000014 ***
Regularity_Course_View       0.073043787722892314  0.105214018434519427    0.69       0.488    
Regularity_Lecture_View      0.031349755109250026  0.081356823049423099    0.39       0.700    
Regularity_Forum_Consume     0.050298824195160151  0.066285623420039699    0.76       0.449    
Regularity_Forum_Contribute  0.106781491699962761  0.055297248687460540    1.93       0.055 .  
Session_Count                0.278012448531555212  0.125078957967640347    2.22       0.027 *  
Total_Duration              -0.077927196019897907  0.100821687015266614   -0.77       0.440    
Active_Days                 -0.035067688196140728  0.111265764443180828   -0.32       0.753    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.78 on 273 degrees of freedom
Multiple R-squared:  0.416, Adjusted R-squared:  0.392 
F-statistic: 17.7 on 11 and 273 DF,  p-value: &lt;0.0000000000000002</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Make predictions on the data</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>predictions_lm <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_model, <span class="at">newdata =</span> student_data_standardized)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Evaluate the model's performance</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding predictions to the data for evaluation</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>evaluation_data_lm <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(student_data_standardized, </span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>                                <span class="at">Predicted_Grade_lm =</span> predictions_lm)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluating model performance</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>performance_metrics_lm <span class="ot">&lt;-</span> evaluation_data_lm <span class="sc">|&gt;</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Final_Grade, <span class="at">estimate =</span> Predicted_Grade_lm)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the model performance metrics</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(performance_metrics_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 rmse    standard       0.763
2 rsq     standard       0.416
3 mae     standard       0.602</code></pre>
</div>
</div>
<div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Visualize predicted vs actual grades</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(evaluation_data_lm, <span class="fu">aes</span>(<span class="at">x =</span> Final_Grade, <span class="at">y =</span> Predicted_Grade_lm)) <span class="sc">+</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Actual Grade"</span>, <span class="at">y =</span> <span class="st">"Predicted Grade"</span>) <span class="sc">+</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Variable importance plot</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Extracting variable importance from the Linear Regression model</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>variable_importance_lm <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">coef</span>(lm_model)[<span class="sc">-</span><span class="dv">1</span>])  <span class="co"># Exclude intercept</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>var_imp_df_lm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Variable =</span> <span class="fu">names</span>(variable_importance_lm), </span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>                            <span class="at">Importance =</span> variable_importance_lm)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting variable importance</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(var_imp_df_lm, <span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, Importance), <span class="at">y =</span> Importance)) <span class="sc">+</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">fill =</span> <span class="st">"skyblue"</span>) <span class="sc">+</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Variable"</span>, <span class="at">y =</span> <span class="st">"Absolute Coefficient Value"</span>) <span class="sc">+</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-linear-reg" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-linear-reg-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-linear-reg-1.png" class="img-fluid figure-img" data-ref-parent="fig-linear-reg" width="672"></p>
<p></p><figcaption class="figure-caption">(a) Scatter plot comparing actual grades to predicted grades.</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-linear-reg-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-linear-reg-2.png" class="img-fluid figure-img" data-ref-parent="fig-linear-reg" width="672"></p>
<p></p><figcaption class="figure-caption">(b) Variable importance.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;7<strong>.</strong> Linear regression plots</figcaption><p></p>
</figure>
</div>
</div>
</section>
</section>
<section id="tutorial-2-a-modern-approach-to-predictive-modelling-using-tidymodels" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="tutorial-2-a-modern-approach-to-predictive-modelling-using-tidymodels"><span class="header-section-number">5</span> Tutorial 2: A Modern Approach to Predictive Modelling using <code>tidymodels</code></h2>
<p>Having used the traditional way, now we introduce a more modern approach of doing machine learning in R using <code>tidymodels</code>. The <code>tidymodels</code> framework provides a consistent interface for modeling in R by integrating several packages that work together seamlessly throughout the modeling process. The <code>tidymodels</code> package eliminates the need to learn and remember the various syntax and functions required by different modeling packages. Instead of having to switch between different paradigms and approaches for each package, you can use the same set of tools and functions. This uniformity speeds up model development and enhances code readability and maintainability.</p>
<p>Additionally, <code>tidymodels</code> offers integrated tools for tasks like pre-processing, resampling, and performance evaluation, further simplifying and accelerating the entire modeling workflow. For instance, the <code>parsnip</code> package in <code>tidymodels</code> allows us to define models in a consistent manner, regardless of the underlying algorithm (e.g., <code>randomForest</code>, <code>ranger</code>, <code>xgboost</code>). It provides functions like <code>rand_forest()</code> to specify the model, <code>set_engine()</code> to choose the computational backend, and <code>set_mode()</code> to define whether the model is used for regression or classification.</p>
<p>This organization is achieved through the use of workflows, which combines the entire modeling process in a single, manageable object, ensuring that each component is handled systematically. The tidy approach includes several steps: 1) splitting the data into training and testing sets (as done before), 2) defining a model specification (we will do a Random Forest model) using the standard approach of <code>parsnip</code> package, 3) creating a workflow combining the model specifications, 4) fitting the model to the training data, 5) making predictions on the test data, and 6) evaluating the model’s performance and visualizing the results. This tutorial will guide you through these steps, using <code>parsnip</code> to create a random forest model, evaluate its performance, and visualize the results. Below, we describe each step in detail:</p>
<ol type="1">
<li><p><strong>Data Splitting</strong>: This step is done in the same way we did before.</p></li>
<li><p><strong>Selecting the predictor and target variables</strong>: The formula specifies the relationship between the target variable and the predictor variables. In regression tasks, this formula includes the dependent variable (e.g., <code>Final_Grade</code>) and the independent variables — in our case, engagement indicators— such as <code>Freq_Course_View</code> and <code>Total_Duration</code>. Defining the formula clearly outlines which variables are used to predict the outcome, ensuring that the model is correctly specified. We can also reuse the formula in other models without having to specify the arguments again.</p></li>
<li><p><strong>Model Specification with <code>parsnip</code></strong>: Using <code>parsnip</code>, we define our random forest model with specific parameters. The <code>rand_forest()</code> function allows us to set the models parameters. The most important parameters are number of trees and number of variables to try in each split. In our model, we set number of trees (<code>trees</code>) to 1000 and the number of variables to sample at each split (<code>mtry</code>) to 3. Setting the engine to <code>"randomForest"</code> and the mode to <code>"regression"</code>, we configure the model to perform regression tasks using the random forest algorithm.</p></li>
<li><p><strong>Creating the Workflow</strong>: A workflow is an object that combines together the model specification and the formula. This organized approach helps manage different components of the modeling process efficiently. Using the <code>workflow()</code> function, we add the random forest model specification and formula to create a complete modeling pipeline.</p></li>
<li><p><strong>Fitting the Model</strong>: The model is fitted to the training data using the <code>fit()</code> function.</p></li>
<li><p><strong>Making Predictions and Evaluating Performance</strong>: After fitting the model, we use it to make predictions on the test data as we did before. Similarly, for evaluation, these predictions are compared to the actual values. We calculate performance metrics such as R-squared (<code>rsq</code>), MAE (<code>mae</code>), and RMSE (<code>rmse</code>) using the <code>metrics()</code> function from the <code>yardstick</code> package. We will visually assess the model’s performance using plots as we have done before.</p></li>
</ol>
<section id="load-the-necessary-libraries" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="load-the-necessary-libraries"><span class="header-section-number">5.1</span> Load the necessary libraries</h3>
<p>First, we load the necessary libraries. The <code>tidymodels</code> package <span class="citation" data-cites="tidymodels">[<a href="#ref-tidymodels" role="doc-biblioref">45</a>]</span> is a meta-package (a collection of packages) that loads several other packages useful for modeling, including <code>parsnip</code>, <code>rsample</code>, <code>recipes</code>, and more. Note that we will not run the data splitting code since it was already split before.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels) <span class="co">#Loading tidymodels loads all the necessary packages for estimation.</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">256</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Split the data into training and testing sets, this step will not be</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># run as it is already done before. In case you are running this code only,</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># you may need to uncomment it.</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># data_split_tidy &lt;- initial_split(student_data_standardized, prop = 0.8)</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co"># train_data &lt;- training(data_split_tidy)</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># test_data &lt;- testing(data_split_tidy)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="select-the-predictor-and-target-variables" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="select-the-predictor-and-target-variables"><span class="header-section-number">5.2</span> Select the predictor and target variables</h3>
<p>In <code>tidymodels</code>, the models are specified using a formula that defines the target variable, and the predictors following a specific syntax: <code>target_variable \~ predictor_1 + predictor_2 + ... + predictor_n</code>, where <code>target_variable</code> is the variable we want to predict. In our case, it is <code>Final_Grade</code>. In turn, <code>predictor_1</code>, <code>predictor_2</code>, …, <code>predictor_n</code> are the predictor variables that will be used to make the prediction. In our case, these are the engagement indicators. See below how the formula is defined for our model in the same way.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Define the formula</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We define the formula to specify the relationship between the target variable </span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 'Final_Grade' and the predictor variables</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>formula_tidy <span class="ot">&lt;-</span> Final_Grade <span class="sc">~</span> Freq_Course_View <span class="sc">+</span> Freq_Lecture_View <span class="sc">+</span> </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                        Freq_Forum_Consume <span class="sc">+</span> Freq_Forum_Contribute <span class="sc">+</span> </span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>                        Regularity_Course_View <span class="sc">+</span> Regularity_Lecture_View <span class="sc">+</span> </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>                        Regularity_Forum_Consume <span class="sc">+</span> Regularity_Forum_Contribute <span class="sc">+</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>                        Session_Count <span class="sc">+</span> Total_Duration <span class="sc">+</span> Active_Days</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="define-the-random-forest-model-specification" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="define-the-random-forest-model-specification"><span class="header-section-number">5.3</span> Define the Random Forest Model Specification</h3>
<p>In this step, we specify the random forest model we plan to estimate by defining the type of model, the engine (the computational back-end), and the hyperparameters (the model configurations). This process enables the creation of straightforward and modular machine learning pipelines (we can change any of these components easily). The package <code>parsnip</code> encompassed within <code>tidymodels</code> ecosystem provides a unified interface for defining and fitting various statistical and machine learning models. To specify a random forest model in <code>parsnip</code>, we use the <code>rand_forest()</code> function. This function allows us to define the type of model and set hyperparameters without immediately fitting the model. This separation of concerns is beneficial for the reusability of the code. The <code>mode</code> argument is set to <code>"regression"</code> because we are predicting a continuous outcome (<code>Final_Grade</code>). The <code>trees = 1000</code> argument specifies the number of trees in the forest. The <code>mtry</code> argument represents the number of predictors in each split. Setting this to <code>tune()</code> indicates that we want to tune this hyperparameter, meaning we will search for the optimal value during the model training process. The <code>set_engine()</code> function specifies the computational backend to use for fitting the model. In this case, we use <code>"ranger"</code>, which is a fast implementation of random forests suitable for large datasets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Define a random forest model specification with `ntree` and `mtry` parameters</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We specify the random Forest model with 1000 trees and 3 variables randomly </span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># sampled at each split</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>rf_specification_tidy <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="dv">1000</span>, <span class="at">mtry =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"regression"</span>) <span class="sc">|&gt;</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"ranger"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the <code>tidymodels</code> framework, we integrate this formula into a workflow to streamline the modeling process. The <code>workflow()</code> function initializes a new workflow. The <code>add_model</code> function allows us to specify the model which is the random forest in our case. And <code>add_formula</code> function allows us to add the formula to the workflow, specifying the relationship between the target variable and predictor variables. The workflow helps ensure that all necessary components for training the model are combined in a single object. This makes it easier to apply or modify the model, and helps maintain a tidy, reproducible code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Create the workflow. We create a workflow that combines the model </span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># specification with the formula</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>rf_workflow_tidy <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_specification_tidy) <span class="sc">|&gt;</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(formula_tidy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The next steps are similar to our previous approach with small changes like using the pipe ‘|&gt;’ to enhance model readability. First, using the workflow, we fit the random forest model (corresponding to <a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–D) using the previously defined workflow and training data (step 5). Using the fitted model, we make predictions on the test data and combines these predictions with the original test data to evaluate the model performance (step 6, corresponding to <a href="../ch11-llmsxai/ch11-llmsxai.html#fig-workflow">Figure&nbsp;<span>11.4</span></a>–E). Next, we calculate performance metrics (R-squared, MAE, and RMSE) by comparing the predicted values to the actual values and then print the results. The last part of the code visualizes the predicted versus actual grades as before (<a href="#fig-predvsactualtidy">Figure&nbsp;<span>3.8</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Fit the random forest model</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We fit the random forest model to the training data using the workflow</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>rf_fitting_tidy <span class="ot">&lt;-</span> rf_workflow_tidy <span class="sc">|&gt;</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> train_data)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Make predictions on the test data and evaluate the model's performance</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># We make predictions on the test data, calculate performance metrics, and </span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the results</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>predictions_tidy <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitting_tidy, <span class="at">new_data =</span> test_data) <span class="sc">|&gt;</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate performance metrics: R-squared, MAE, and RMSE</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>performance_metrics_tidy <span class="ot">&lt;-</span> predictions_tidy <span class="sc">|&gt;</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Final_Grade, <span class="at">estimate =</span> .pred)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the model performance metrics</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(performance_metrics_tidy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 rmse    standard       0.705
2 rsq     standard       0.431
3 mae     standard       0.531</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot comparing actual grades to predicted grades</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(predictions_tidy, <span class="fu">aes</span>(<span class="at">x =</span> Final_Grade, <span class="at">y =</span> .pred)) <span class="sc">+</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Actual Grade"</span>, <span class="at">y =</span> <span class="st">"Predicted Grade"</span>) <span class="sc">+</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-predvsactualtidy" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-predvsactualtidy-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;8<strong>.</strong> Predicted vs.&nbsp;Actual Grades</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="multiple-algorithms" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="multiple-algorithms"><span class="header-section-number">5.4</span> Multiple algorithms</h3>
<p>The uniform framework of <code>tidymodels</code> enables easier estimation and comparison of multiple models and in fact several configurations of the same algorithm if needed. The next code uses <code>tidymodels</code> to build and evaluate five machine learning algorithms namely: linear regression, support vector machine (SVM), random forest, K-nearest neighbors (KNN), and a neural network. Using <code>tidymodels</code> saves a lot of time in working with diverse packages and interfaces for each algorithm. Given that we already used similar code before, and we already loaded and split the data, we briefly describe the code for the estimation.</p>
<section id="model-specification" class="level4" data-number="5.4.1">
<h4 data-number="5.4.1" class="anchored" data-anchor-id="model-specification"><span class="header-section-number">5.4.1</span> Model specification</h4>
<p>First, we define model specifications using the <code>parsnip</code> package. The <code>linear_reg</code> function is used to specify a linear regression model with the <code>lm</code> engine. For SVM , we use the <code>svm_rbf</code> function and set the engine to <code>kernlab</code>, specifying that it will be used for regression. The random forest model is specified using <code>rand_forest</code>, setting the number of trees to 1000 and allowing the number of variables randomly sampled at each split (<code>mtry</code>) to be tuned. The <code>nearest_neighbor</code> function specifies a KNN model with 5 neighbors, and the engine is set to <code>kknn</code>. Finally, for the neural network, the <code>mlp</code> function specifies a model with 10 hidden units and 100 epochs, using the <code>nnet</code> engine, set for regression.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear Regression specification</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>lr_specification <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">|&gt;</span> <span class="fu">set_engine</span>(<span class="st">"lm"</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM specification</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>svm_specification <span class="ot">&lt;-</span> <span class="fu">svm_rbf</span>() <span class="sc">|&gt;</span> <span class="fu">set_engine</span>(<span class="st">"kernlab"</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"regression"</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest specification with ntree and mtry parameters</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>rf_specification <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="dv">1000</span>, <span class="at">mtry =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"randomForest"</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"regression"</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co"># KNN specification</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>knn_specification <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="dv">5</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"kknn"</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"regression"</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network specification</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>nn_specification <span class="ot">&lt;-</span> <span class="fu">mlp</span>(<span class="at">hidden_units =</span> <span class="dv">10</span>, <span class="at">epochs =</span> <span class="dv">100</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"nnet"</span>) <span class="sc">|&gt;</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"regression"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="create-workflows" class="level4" data-number="5.4.2">
<h4 data-number="5.4.2" class="anchored" data-anchor-id="create-workflows"><span class="header-section-number">5.4.2</span> Create workflows</h4>
<p>Next, we create workflows for each model specification using the <code>workflow</code> function. This involves adding the model specification and the formula to the workflow. The formula defines the relationship between the predictors and the target variable <code>Final_Grade</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear Regression workflow</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>lr_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(lr_specification) <span class="sc">|&gt;</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(formula_tidy)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM workflow</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>svm_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(svm_specification) <span class="sc">|&gt;</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(formula_tidy)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest workflow</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>rf_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_specification) <span class="sc">|&gt;</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(formula_tidy)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co"># KNN workflow</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>knn_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_specification) <span class="sc">|&gt;</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(formula_tidy)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural Network workflow</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>nn_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(nn_specification) <span class="sc">|&gt;</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(formula_tidy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="fit-the-models" class="level4" data-number="5.4.3">
<h4 data-number="5.4.3" class="anchored" data-anchor-id="fit-the-models"><span class="header-section-number">5.4.3</span> Fit the models</h4>
<p>We then fit each model to the training data using the <code>fit</code> function. This step trains the models using the specified workflows and the training dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Linear Regression model</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>lr_fitting <span class="ot">&lt;-</span> lr_workflow <span class="sc">|&gt;</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> train_data)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the SVM model</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>svm_fitting <span class="ot">&lt;-</span> svm_workflow <span class="sc">|&gt;</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> train_data)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Random Forest model</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>rf_fitting <span class="ot">&lt;-</span> rf_workflow <span class="sc">|&gt;</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> train_data)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the KNN model</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>knn_fitting <span class="ot">&lt;-</span> knn_workflow <span class="sc">|&gt;</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> train_data)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the Neural Network model</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>nn_fitting <span class="ot">&lt;-</span> nn_workflow <span class="sc">|&gt;</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> train_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="calculate-fit-indices-and-residuals" class="level4" data-number="5.4.4">
<h4 data-number="5.4.4" class="anchored" data-anchor-id="calculate-fit-indices-and-residuals"><span class="header-section-number">5.4.4</span> Calculate Fit Indices and Residuals</h4>
<p>Lastly, we create <code>calculate_metrics</code> function to assess the performance of each fitted model. It takes the model fit object and test data as inputs, makes predictions on the test data, and binds these predictions to the test data (<a href="#tbl-performancemetrics">Table&nbsp;<span>3.1</span></a>). Performance metrics such as R-squared, mean absolute error (MAE), and root mean squared error (RMSE) are calculated using the <code>metrics</code> function from the <code>yardstick</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to calculate metrics and residuals</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>calculate_metrics <span class="ot">&lt;-</span> <span class="cf">function</span>(model_fitting, test_data, <span class="at">truth_col =</span> <span class="st">"Final_Grade"</span>) {</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Make predictions</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>  predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_fitting, <span class="at">new_data =</span> test_data) <span class="sc">|&gt;</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(test_data)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate residuals</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>  residuals <span class="ot">&lt;-</span> predictions <span class="sc">|&gt;</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">residuals =</span> <span class="sc">!!</span><span class="fu">sym</span>(truth_col) <span class="sc">-</span> .pred)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate performance metrics</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>  performance_metrics <span class="ot">&lt;-</span> residuals <span class="sc">|&gt;</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">metrics</span>(<span class="at">truth =</span> <span class="sc">!!</span><span class="fu">sym</span>(truth_col), <span class="at">estimate =</span> .pred)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">performance_metrics =</span> performance_metrics, <span class="at">residuals =</span> residuals)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate metrics and residuals for each model</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>lr_results <span class="ot">&lt;-</span> <span class="fu">calculate_metrics</span>(lr_fitting, test_data)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>svm_results <span class="ot">&lt;-</span> <span class="fu">calculate_metrics</span>(svm_fitting, test_data)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>rf_results <span class="ot">&lt;-</span> <span class="fu">calculate_metrics</span>(rf_fitting, test_data)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>knn_results <span class="ot">&lt;-</span> <span class="fu">calculate_metrics</span>(knn_fitting, test_data)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>nn_results <span class="ot">&lt;-</span> <span class="fu">calculate_metrics</span>(nn_fitting, test_data)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine predictions and residuals</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>lr_residuals <span class="ot">&lt;-</span> lr_results<span class="sc">$</span>residuals <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Linear Regression"</span>)</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>svm_residuals <span class="ot">&lt;-</span> svm_results<span class="sc">$</span>residuals <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"SVM"</span>)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>rf_residuals <span class="ot">&lt;-</span> rf_results<span class="sc">$</span>residuals <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Random Forest"</span>)</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>knn_residuals <span class="ot">&lt;-</span> knn_results<span class="sc">$</span>residuals <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"KNN"</span>)</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>nn_residuals <span class="ot">&lt;-</span> nn_results<span class="sc">$</span>residuals <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Neural Network"</span>)</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>combined_residuals <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(lr_residuals, svm_residuals, </span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>                                rf_residuals, knn_residuals, nn_residuals)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and combine performance metrics</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>performance_metrics <span class="ot">&lt;-</span> <span class="fu">bind_rows</span>(</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>  lr_results<span class="sc">$</span>performance_metrics <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Linear Regression"</span>),</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>  svm_results<span class="sc">$</span>performance_metrics <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"SVM"</span>),</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>  rf_results<span class="sc">$</span>performance_metrics <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Random Forest"</span>),</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>  knn_results<span class="sc">$</span>performance_metrics <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"KNN"</span>),</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>  nn_results<span class="sc">$</span>performance_metrics <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">"Neural Network"</span>)</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> <span class="fu">arrange</span>(.metric)</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Print performance metrics</span></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(performance_metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-performancemetrics" class="anchored">
<table class="table table-sm table-striped">
<caption>Table&nbsp;1<strong>.</strong> Performance metrics by model</caption>
<thead>
<tr class="header">
<th style="text-align: left;">.metric</th>
<th style="text-align: left;">.estimator</th>
<th style="text-align: right;">.estimate</th>
<th style="text-align: left;">model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">mae</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: left;">Linear Regression</td>
</tr>
<tr class="even">
<td style="text-align: left;">mae</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.51</td>
<td style="text-align: left;">SVM</td>
</tr>
<tr class="odd">
<td style="text-align: left;">mae</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.53</td>
<td style="text-align: left;">Random Forest</td>
</tr>
<tr class="even">
<td style="text-align: left;">mae</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.60</td>
<td style="text-align: left;">KNN</td>
</tr>
<tr class="odd">
<td style="text-align: left;">mae</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">1.11</td>
<td style="text-align: left;">Neural Network</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmse</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.62</td>
<td style="text-align: left;">Linear Regression</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rmse</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: left;">SVM</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmse</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.70</td>
<td style="text-align: left;">Random Forest</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rmse</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.75</td>
<td style="text-align: left;">KNN</td>
</tr>
<tr class="even">
<td style="text-align: left;">rmse</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">1.35</td>
<td style="text-align: left;">Neural Network</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rsq</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.52</td>
<td style="text-align: left;">Linear Regression</td>
</tr>
<tr class="even">
<td style="text-align: left;">rsq</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.45</td>
<td style="text-align: left;">SVM</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rsq</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.43</td>
<td style="text-align: left;">Random Forest</td>
</tr>
<tr class="even">
<td style="text-align: left;">rsq</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.35</td>
<td style="text-align: left;">KNN</td>
</tr>
<tr class="odd">
<td style="text-align: left;">rsq</td>
<td style="text-align: left;">standard</td>
<td style="text-align: right;">0.05</td>
<td style="text-align: left;">Neural Network</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Wen can plot the performance metrics to compare them across the models (<a href="#fig-comparing-models">Figure&nbsp;<span>3.9</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot performance metrics</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>performance_metrics <span class="sc">|&gt;</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> model, <span class="at">y =</span> .estimate, <span class="at">fill =</span> model)) <span class="sc">+</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">position =</span> <span class="st">"dodge"</span>) <span class="sc">+</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> .metric, <span class="at">scales =</span> <span class="st">"free"</span>) <span class="sc">+</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Model"</span>,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Metric Value"</span>) <span class="sc">+</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-comparing-models" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-comparing-models-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;9<strong>.</strong> Comparing performance metrics across models</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>We can also create a scatter plot comparing actual grades to predicted grades, providing a visual assessment of the model’s performance (<a href="#fig-scatter-actual">Figure&nbsp;<span>3.10</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>combined_residuals <span class="sc">|&gt;</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Final_Grade, <span class="at">y =</span> .pred, <span class="at">color =</span> model)) <span class="sc">+</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add a linear model fit line</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span>  </span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> model) <span class="sc">+</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Actual Final Grade"</span>,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Predicted Final Grade"</span>) <span class="sc">+</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-scatter-actual" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ch03-prediction_files/figure-html/fig-scatter-actual-1.png" class="img-fluid figure-img" width="604"></p>
<p></p><figcaption class="figure-caption"><strong>Figure</strong>&nbsp;10<strong>.</strong> Plot actual vs.&nbsp;predicted with a line matching the slope of actual vs.&nbsp;predicted</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>You can evaluate the results of each model by comparing it against the other models and choose the best performing model with lowest error rates.</p>
</section>
</section>
</section>
<section id="discussion-and-conclusions" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="discussion-and-conclusions"><span class="header-section-number">6</span> Discussion and conclusions</h2>
<p>This chapter has provided a comprehensive exploration of predictive modeling in the context of learning analytics, where we focus on the practical application of machine learning techniques to forecast student performance. We have systematically mapped the main steps of the predictive modeling process, from data preparation and exploratory analysis to the building, evaluation, and interpretation of various models. The chapter explored different traditions from traditional machine learning, to the modern tidy approach and comparison across several models (linear regression, random forests, support vector machines, K-nearest neighbors, and neural networks). Furthermore, we investigated the use of various evaluation metrics – RMSE, MAE, and R-squared – to estimate model accuracy, which can help us understand the trade-offs associated with each algorithm. We also shown how to visualize model predictions against actual outcomes and examine residual plots to assess the model fit and highlight areas that needed further consideration.</p>
<p>Several important points need to be emphasized here. First, the important of data and variable selection according to a predefined learning theory that can offer a platform for variable inclusion and model results interpretation for more discussion of this issue, please refer to the vast literature on theory and predictive analytics. Second, the significance of careful data preprocessing cannot be overstated; even the most advanced algorithms cannot compensate for poor-quality data. Third, the absence of a single “best” algorithm became apparent, highlighting how algorithm choice is always dataset-specific, goal-oriented, and depends on the desired interpretability of the model. Fourth, we recognized that predictive models are tools to enhance decision-making, but do not replace human judgment and expertise, particularly in educational contexts, which require ethical considerations.</p>
<p>Finally, this chapter has demonstrated that the practical application of data science techniques can help to inform and improve educational practices. However, it also highlighted the importance of understanding the limitations of predictive models and machine learning in general <span class="citation" data-cites="mustafa2024">[<a href="#ref-mustafa2024" role="doc-biblioref">46</a>]</span>. Worth also noting that while explanation and transparency of the machine learning models are useful, they still can do deliver results that are more data driven that plausible or aligned with theory <span class="citation" data-cites="Saqr2024-ie">[<a href="#ref-Saqr2024-ie" role="doc-biblioref">21</a>]</span>. Other Issues like overfitting, data quality, and ethical considerations need to be carefully addressed to ensure responsible and meaningful use of predictive analytics in education. Finally, the chapter emphasized that predictive modeling is not just about achieving high accuracy, but also about gaining actionable insights into factors influencing student success and informing interventions and improving learning outcomes. We also need to emphasize that these results are aggregates of the whole dataset and therefore, it can be misleading and lacks full representation of each and everyone <span class="citation" data-cites="saqr2024 LABOOK2_Chapter_22">[<a href="#ref-saqr2024" role="doc-biblioref">47</a>, <a href="#ref-LABOOK2_Chapter_22" role="doc-biblioref">48</a>]</span>.</p>


</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-LABOOK2_Chapter_2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">López-Pernas S, Oliveira E, Song Y, Saqr M (2025) AI, explainable AI and evaluative AI: An introduction to informed data-driven decision-making in education. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-LABOOK2_Chapter_4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Saqr M, Misiejuk K, Tikka S, López-Pernas S (2025) Artificial intelligence: Using machine learning to classify students and predict low achievers. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
<div id="ref-eckerson2007predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Eckerson WW (2007) Predictive analytics. Extending the Value of Your Data Warehousing Investment TDWI Best Practices Report 1:1–36</div>
</div>
<div id="ref-pardo2014designing" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Pardo A (2014) Designing learning analytics experiences. In: Learning analytics: From research to practice. Springer, pp 15–38</div>
</div>
<div id="ref-brooks2017predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Brooks C, Thompson C (2017) Predictive modelling in teaching and learning. Handbook of learning analytics 61–68</div>
</div>
<div id="ref-sghir2023recent" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Sghir N, Adadi A, Lahmer M (2023) Recent advances in predictive learning analytics: A decade systematic review (2012–2022). Education and information technologies 28:8299–8333</div>
</div>
<div id="ref-kopra2024r" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Kopra J, Tikka S, Heinäniemi M, López-Pernas S, Saqr M (2024) An r approach to data cleaning and wrangling for education research. In: Learning analytics methods and tutorials: A practical guide using r. Springer Nature Switzerland Cham, pp 95–119</div>
</div>
<div id="ref-tikka2024introductory" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Tikka S, Kopra J, Heinäniemi M, López-Pernas S, Saqr M (2024) Introductory statistics with r for educational researchers. In: Learning analytics methods and tutorials: A practical guide using r. Springer Nature Switzerland Cham, pp 121–150</div>
</div>
<div id="ref-dabhade2021educational" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Dabhade P, Agarwal R, Alameen K, Fathima A, Sridharan R, Gopakumar G (2021) Educational data mining for predicting students’ academic performance using machine learning algorithms. Materials Today: Proceedings 47:5260–5267</div>
</div>
<div id="ref-pardo2016generating" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Pardo A, Mirriahi N, Martinez-Maldonado R, Jovanovic J, Dawson S, Gašević D (2016) Generating actionable predictive models of academic performance. In: Proceedings of the sixth international conference on learning analytics &amp; knowledge. pp 474–478</div>
</div>
<div id="ref-jovanovic2024predictive" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Jovanovic J, López-Pernas S, Saqr M (2024) Predictive modelling in learning analytics: A machine learning approach in r. In: Learning analytics methods and tutorials: A practical guide using r. Springer Nature Switzerland Cham, pp 197–229</div>
</div>
<div id="ref-Tikka2024-ph" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Tikka S, Kopra J, Heinäniemi M, López-Pernas S, Saqr M (2024) Getting started with <span>R</span> for education research. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Kopra2024-fx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">Kopra J, Tikka S, Heinäniemi M, López-Pernas S, Saqr M (2024) An <span>R</span> approach to data cleaning and wrangling for education research. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Tikka2024-wl" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Tikka S, Kopra J, Heinäniemi M, López-Pernas S, Saqr M (2024) Introductory statistics with <span>R</span> for educational researchers. In: Saqr M, López-Pernas S (eds) Learning analytics methods and tutorials: A practical guide using r. Springer, pp in–press</div>
</div>
<div id="ref-Lopez-Pernas2024-ge" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">López-Pernas S, Misiejuk K, Tikka S, Kopra J, Heinäniemi M, Saqr M (2024) <a href="https://doi.org/10.1007/978-3-031-54464-4\_6">Visualizing and reporting educational data with <span>R</span></a>. In: Learning analytics methods and tutorials. Springer Nature Switzerland, Cham, pp 151–194</div>
</div>
<div id="ref-saqr2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Saqr M, Jovanovic J, Viberg O, Gašević D (2022) Is there order in the mess? A single paper meta-analysis approach to identification of predictors of success in learning analytics. Studies in Higher Education 47:2370–2391. https://doi.org/<a href="https://doi.org/10.1080/03075079.2022.2061450">10.1080/03075079.2022.2061450</a></div>
</div>
<div id="ref-tomasevic2020overview" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Tomasevic N, Gvozdenovic N, Vranes S (2020) An overview and comparison of supervised data mining techniques for student exam performance prediction. Computers &amp; education 143:103676</div>
</div>
<div id="ref-du2021systematic" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Du X, Yang J, Shelton BE, Hung J-L, Zhang M (2021) A systematic meta-review and analysis of learning analytics research. Behaviour &amp; information technology 40:49–62</div>
</div>
<div id="ref-namoun2020predicting" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">Namoun A, Alshanqiti A (2020) Predicting student performance using data mining and learning analytics techniques: A systematic literature review. Applied Sciences 11:237</div>
</div>
<div id="ref-saqr2017learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Saqr M, Fors U, Tedre M (2017) How learning analytics can early predict under-achieving students in a blended medical education course. Medical teacher 39:757–767</div>
</div>
<div id="ref-Saqr2024-ie" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Saqr M, López-Pernas S (2024) Why explainable <span>AI</span> may not be enough: Predictions and mispredictions in decision making in education. Smart Learn Environ. <a href="https://doi.org/10.1186/s40561-024-00343-4">https://doi.org/10.1186/s40561-024-00343-4</a></div>
</div>
<div id="ref-alyahyan2020predicting" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline">Alyahyan E, Düştegör D (2020) Predicting academic success in higher education: Literature review and best practices. International Journal of Educational Technology in Higher Education 17:3</div>
</div>
<div id="ref-mathrani2021perspectives" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline">Mathrani A, Susnjak T, Ramaswami G, Barczak A (2021) Perspectives on the challenges of generalizability, transparency and ethics in predictive learning analytics. Computers and Education Open 2:100060</div>
</div>
<div id="ref-winne2020construct" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline">Winne PH (2020) Construct and consequential validity for learning analytics based on trace data. Computers in Human Behavior 112:106457</div>
</div>
<div id="ref-avelino2024resampling" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline">Avelino JG, Cavalcanti GD, Cruz RM (2024) Resampling strategies for imbalanced regression: A survey and empirical analysis. Artificial Intelligence Review 57:82</div>
</div>
<div id="ref-saqr2020" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline">Saqr M, Nouri J (2020) High resolution temporal network analysis to understand and improve collaborative learning. Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge 314–319. https://doi.org/<a href="https://doi.org/10.1145/3375462.3375501">10.1145/3375462.3375501</a></div>
</div>
<div id="ref-rets2023six" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline">Rets I, Herodotou C, Gillespie A (2023) Six practical recommendations enabling ethical use of predictive learning analytics in distance education. Journal of Learning Analytics 10:149–167</div>
</div>
<div id="ref-saqr2017big" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline">Saqr M (2017) Big data and the emerging ethical challenges. International journal of health sciences 11:1</div>
</div>
<div id="ref-alshehri2017student" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline">Al-Shehri H, Al-Qarni A, Al-Saati L, Batoaq A, Badukhen H, Alrashed S, Alhiyafi J, Olatunji SO (2017) Student performance prediction using support vector machine and k-nearest neighbor. In: 2017 IEEE 30th canadian conference on electrical and computer engineering (CCECE). IEEE, pp 1–4</div>
</div>
<div id="ref-nguyen2024applying" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline">Nguyen VA (2024) Applying learning analytics to predict the student’s learning outcome based on online learning activities. In: Proceedings of the 2024 10th international conference on frontiers of educational technologies. pp 140–146</div>
</div>
<div id="ref-jo2015relations" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline">Jo I-H, Yu T, Lee H, Kim Y (2015) Relations between student online learning behavior and academic achievement in higher education: A learning analytics approach. In: Emerging issues in smart learning. Springer, pp 275–287</div>
</div>
<div id="ref-cavazos2018learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline">Cavazos R, Garza SE (2018) Learning models for student performance prediction. In: Advances in computational intelligence: 16th mexican international conference on artificial intelligence, MICAI 2017, enseneda, mexico, october 23-28, 2017, proceedings, part II 16. Springer, pp 171–182</div>
</div>
<div id="ref-Jovanovic2021-et" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">33. </div><div class="csl-right-inline">Jovanović J, Saqr M, Joksimović S, Gašević D (2021) Students matter the most in learning analytics: The effects of internal and instructional conditions in predicting academic success. Comput Educ 172:104251. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2021.104251">10.1016/j.compedu.2021.104251</a></div>
</div>
<div id="ref-conijn2017" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">34. </div><div class="csl-right-inline">Conijn R, Snijders C, Kleingeld A, Matzat U (2017) Predicting student performance from LMS data: A comparison of 17 blended courses using moodle LMS. IEEE Transactions on Learning Technologies 10:17–29. https://doi.org/<a href="https://doi.org/10.1109/tlt.2016.2616312">10.1109/tlt.2016.2616312</a></div>
</div>
<div id="ref-gavsevic2016learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">35. </div><div class="csl-right-inline">Gašević D, Dawson S, Rogers T, Gasevic D (2016) Learning analytics should not promote one size fits all: The effects of instructional conditions in predicting academic success. The Internet and Higher Education 28:68–84</div>
</div>
<div id="ref-Saqr2023-vs" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">36. </div><div class="csl-right-inline">Saqr M, López-Pernas S, Helske S, Hrastinski S (2023) The longitudinal association between engagement and achievement varies by time, students’ profiles, and achievement state: A full program study. Comput Educ 199:104787. https://doi.org/<a href="https://doi.org/10.1016/j.compedu.2023.104787">10.1016/j.compedu.2023.104787</a></div>
</div>
<div id="ref-tidyverse" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">37. </div><div class="csl-right-inline">Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019) Welcome to the <span class="nocase">tidyverse</span>. Journal of Open Source Software 4:1686. https://doi.org/<a href="https://doi.org/10.21105/joss.01686">10.21105/joss.01686</a></div>
</div>
<div id="ref-skimr" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">38. </div><div class="csl-right-inline">Waring E, Quinn M, McNamara A, Arino de la Rubia E, Zhu H, Ellis S (2022) <a href="https://CRAN.R-project.org/package=skimr">Skimr: Compact and flexible summaries of data</a></div>
</div>
<div id="ref-correlation" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">39. </div><div class="csl-right-inline">Makowski D, Ben-Shachar M, Patil I, Lüdecke D (2020) Methods and algorithms for correlation analysis in <span>R</span>. J Open Source Softw 5:2306. https://doi.org/<a href="https://doi.org/10.21105/joss.02306">10.21105/joss.02306</a></div>
</div>
<div id="ref-rio" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">40. </div><div class="csl-right-inline">Chan C, Leeper TJ, Becker J, Schoch D (2023) <a href="https://cran.r-project.org/package=rio">Rio: A swiss-army knife for data file i/o</a></div>
</div>
<div id="ref-Ludecke2021-li" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">41. </div><div class="csl-right-inline">Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021) Performance: An <span>R</span> package for assessment, comparison and testing of statistical models. J Open Source Softw 6:3139. https://doi.org/<a href="https://doi.org/10.21105/joss.03139">10.21105/joss.03139</a></div>
</div>
<div id="ref-randomForest" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">42. </div><div class="csl-right-inline">Liaw A, Wiener M (2002) <a href="https://CRAN.R-project.org/doc/Rnews/">Classification and regression by randomForest</a>. R News 2:18–22</div>
</div>
<div id="ref-rsample" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">43. </div><div class="csl-right-inline">Frick H, Chow F, Kuhn M, Mahoney M, Silge J, Wickham H (2024) <a href="https://CRAN.R-project.org/package=rsample">Rsample: General resampling infrastructure</a></div>
</div>
<div id="ref-yardstick" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">44. </div><div class="csl-right-inline">Kuhn M, Vaughan D, Hvitfeldt E (2024) <a href="https://CRAN.R-project.org/package=yardstick">Yardstick: Tidy characterizations of model performance</a></div>
</div>
<div id="ref-tidymodels" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">45. </div><div class="csl-right-inline">Kuhn M, Wickham H (2020) <a href="https://www.tidymodels.org">Tidymodels: A collection of packages for modeling and machine learning using tidyverse principles.</a></div>
</div>
<div id="ref-mustafa2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">46. </div><div class="csl-right-inline">Mustafa MY, Tlili A, Lampropoulos G, Huang R, Jandrić P, Zhao J, Salha S, Xu L, Panda S, Kinshuk, López-Pernas S, Saqr M (2024) A systematic review of literature reviews on artificial intelligence in education (AIED): a roadmap to a future research agenda. Smart Learning Environments 11: https://doi.org/<a href="https://doi.org/10.1186/s40561-024-00350-5">10.1186/s40561-024-00350-5</a></div>
</div>
<div id="ref-saqr2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">47. </div><div class="csl-right-inline">Saqr M, Cheng R, López-Pernas S, Beck ED (2024) Idiographic artificial intelligence to explain students’ self-regulation: Toward precision education. Learning and Individual Differences 114:102499. https://doi.org/<a href="https://doi.org/10.1016/j.lindif.2024.102499">10.1016/j.lindif.2024.102499</a></div>
</div>
<div id="ref-LABOOK2_Chapter_22" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">48. </div><div class="csl-right-inline">Saqr M, Tlili A, López-Pernas S (2025) Automating individualized machine learning and AI prediction using AutoML: The case of idiographic predictions. In: Saqr M, López-Pernas S (eds) Advanced learning analytics methods: AI, precision and complexity. Springer Nature Switzerland, Cham</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapters/ch02-AIxAI/ch02-aixai.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI and XAI</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/ch04-classification/ch04-classification.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Classification</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
  </div>
</footer>
<script>
  document.querySelector(".quarto-title").innerHTML =  '<div class="badge bs-warning bg-warning text-dark" style="float:right;">Pre-print</div>' +  document.querySelector(".quarto-title").innerHTML
  var keywords = document.querySelector('meta[name="keywords"]')
  if (keywords && keywords.content) {
    document.getElementById("title-block-header").innerHTML = document.getElementById("title-block-header").innerHTML + 
      '<div class="abstract"><div class="abstract-title">Keywords</div><div class="quarto-title-meta-contents"><p>'+
      keywords.content +
      '</p></div></div>'
  }
  function insertAfter(referenceNode, newNode) {
      referenceNode.parentNode.insertBefore(newNode, referenceNode.nextSibling);
  }
  var authors = document.querySelectorAll('meta[name="author"]')
  if (authors) {
    var authorlist = Array.from(authors).map(e=>e.content).reduce((accum, curr) =>  accum + curr + ", ", "","").replace(/\,\s$/,"")
    var citt = `<div class="card border-primary mb-3" style=;">
      <div class="card-header bg-primary">To cite this chapter</div>
      <div class="card-body small">
        <p class="card-text">${authorlist} (2025).
        <b>${document.getElementsByClassName("chapter-title")[0].innerText}</b>. 
        In M. Saqr & S. López-Pernas (Eds.), <i>Advanced Learning Analytics Methods: AI, Precision and Complexity</i> 
        (in – press). Springer. <a href="${window.location.href}">${window.location.href}</a></p>
      </div>
    </div>`;
    insertAfter(document.getElementsByTagName("HEADER")[1],new DOMParser().parseFromString(citt, 'text/html').body.childNodes[0])
  }
</script>



</body></html>